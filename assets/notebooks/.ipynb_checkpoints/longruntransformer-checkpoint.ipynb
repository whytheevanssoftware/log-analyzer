{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejXAKpdM7vpW"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZmbFWc97xsl"
   },
   "source": [
    "Feel free to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QLnvgfRy2U1H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# -- Base -- #\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import io\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import sys, getopt\n",
    "import json\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil\n",
    "import csv\n",
    "from typing import (\n",
    "    List,\n",
    "    Dict\n",
    ")\n",
    "\n",
    "# -- Tokenizer -- #\n",
    "import tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers import normalizers\n",
    "\n",
    "from tokenizers.normalizers import (\n",
    "    Lowercase,\n",
    "    NFD,\n",
    "    StripAccents\n",
    ")\n",
    "\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers import decoders\n",
    "\n",
    "# -- Metrics -- #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import tensorboard\n",
    "\n",
    "# -- Tensorflow -- #\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Softmax,\n",
    "    Dense,\n",
    "    AdditiveAttention,\n",
    "    MultiHeadAttention,\n",
    "    Layer\n",
    ")\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    LayerNormalization,\n",
    "    Dropout,\n",
    "    Embedding\n",
    ")\n",
    "\n",
    "from tensorflow.keras import (\n",
    "    Sequential,\n",
    "    Model\n",
    ")\n",
    "from tensorflow.train import Checkpoint, CheckpointManager\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# -- Misc Models -- #\n",
    "import drain3\n",
    "from gensim.models.phrases import Phrases\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# -- Dash -- #\n",
    "import dash\n",
    "import dash_table\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "from dash.dependencies import (\n",
    "    Input,\n",
    "    Output,\n",
    "    State\n",
    ")\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from dash import no_update\n",
    "from flask_caching import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sqlite_to_csv(inputFolder, ext, tableName):\n",
    "    \"\"\" inputFolder - Folder where sqlite files are located. \n",
    "        ext - Extension of your sqlite file (eg. db, sqlite, sqlite3 etc.)\n",
    "        tableName - table name from which you want to select the data.\n",
    "    \"\"\"\n",
    "    csvWriter = csv.writer(open(inputFolder+'/output.csv', 'w', newline=''))\n",
    "    for file1 in os.listdir(inputFolder):\n",
    "        if file1.endswith('.'+ext):\n",
    "            conn = sql.connect(inputFolder+'/'+file1)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT * FROM \"+tableName)\n",
    "            rows = cursor.fetchall()\n",
    "            for row in rows:\n",
    "                csvWriter.writerow(row)\n",
    "            continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L19JQx8YwmH"
   },
   "source": [
    "Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N_5Z7Gg4Jl5"
   },
   "source": [
    "## Environmental Variables\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xvZC0zAR4NUe"
   },
   "outputs": [],
   "source": [
    "SOURCE = '/home/' + os.environ['USER']\n",
    "CONTAINER = 'core.soaesb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8EnuKFhAuER",
    "tags": []
   },
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GUivYRdyAstr"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s | %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITSJA5hWASDn",
    "tags": []
   },
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnCJ678Ka-T1"
   },
   "source": [
    "## Define Database Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Gwi7HlrBkwwl"
   },
   "outputs": [],
   "source": [
    "def database_builder(path: str) -> pd.DataFrame():\n",
    "    logger.info('Building DataFrame ...')\n",
    "    (_, _, files) = next(os.walk(path))\n",
    "    sql_query = 'SELECT * FROM logs'\n",
    "    data = []\n",
    "    for f in files:\n",
    "        if '.db' in f:\n",
    "            conn = create_connection(path + f)\n",
    "            d = pd.read_sql_query(sql_query, conn)\n",
    "            data.append(d)\n",
    "    logger.info('...complete!')\n",
    "    return pd.concat(data)\n",
    "\n",
    "\n",
    "def create_connection(path: str) -> sql.Connection:\n",
    "    \"\"\"\n",
    "    Creates a database connection\n",
    "    :param path: str\n",
    "        path to database object\n",
    "    :return sql.Connection\n",
    "        a connection to the database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sql.connect(path)\n",
    "        logger.info('Connected to database ' + path)\n",
    "        return conn\n",
    "    except sql.Error as e:\n",
    "        logger.warning(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekFXItHibG7r"
   },
   "source": [
    "## Define Dataset Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50ge2uap_kTN",
    "outputId": "af603cfd-5c79-4772-b0d7-9ab271eb4f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:51:06,186 INFO | Building DataFrame ...\n",
      "2021-05-27 16:51:06,188 INFO | Connected to database /home/jovyan/data/tanner_logs.db\n",
      "2021-05-27 16:51:06,994 INFO | Connected to database /home/jovyan/data/elastic_logs.db\n",
      "2021-05-27 16:51:07,909 INFO | ...complete!\n"
     ]
    }
   ],
   "source": [
    "dataset = database_builder(SOURCE + '/data/')\n",
    "container_dataset = dataset[dataset['container_name'] == CONTAINER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkC2MdmCBR7C"
   },
   "source": [
    "# W2V Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wFAAOw-q3w5",
    "tags": []
   },
   "source": [
    "## Pipeline Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_attributes(self, config: dict):\n",
    "    try:\n",
    "        config = config[self.__class__.__name__]\n",
    "    except Exception as e:\n",
    "        logger.warning(e)\n",
    "        logger.warning('No configuration found for ' +\n",
    "                       self.__class__.__name__)\n",
    "\n",
    "    for attr in config.keys():\n",
    "        setattr(self, attr, config[attr])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PreprocessingGlobalConfig:\n",
    "    embed_size: int = 512\n",
    "    max_vocab_size: int = 2000\n",
    "    buffer_size: int = 10000\n",
    "    global_training: bool = True\n",
    "    path: str = '/results/'\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PhraseCaptureLayerConfig:\n",
    "    min_count: int = 5\n",
    "    threshold: float = 7\n",
    "    load_model: bool = True\n",
    "    save_model: bool = False\n",
    "    training: bool = True\n",
    "    model_name: str = 'phrase_model.joblib'\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TextClusteringLayerConfig:\n",
    "    load_model: bool = True\n",
    "    save_model: bool = False\n",
    "    training: bool = True\n",
    "    model_name: str = 'template_miner.joblib'\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NegativeSkipgramLayerConfig:\n",
    "    window_size: int = 2\n",
    "    num_neg_sampling: int = 10\n",
    "    load_model: bool = True\n",
    "    save_model: bool = False\n",
    "    training: bool = True\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class W2VLayerConfig:\n",
    "    epochs: int = 25\n",
    "    batch_size: int = 2048\n",
    "    load_model: bool = True\n",
    "    save_model: bool = False\n",
    "    training: bool = True\n",
    "    model_name: bool = 'word2vec'\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "class PreprocessingPipelineConfig:\n",
    "    def __init__(self):\n",
    "        self.PreprocessingGlobalConfig = PreprocessingGlobalConfig()\n",
    "        self.PhraseCaptureLayerConfig = PhraseCaptureLayerConfig()\n",
    "        self.TextClusteringLayerConfig = TextClusteringLayerConfig()\n",
    "        self.NegativeSkipgrameLayerConfig = NegativeSkipgramLayerConfig()\n",
    "        self.W2VLayerConfig = W2VLayerConfig()\n",
    "\n",
    "    def load(self, path):\n",
    "        try:\n",
    "            with open(path) as f:\n",
    "                preprocessing_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        except FileNotFoundError as e:\n",
    "            logger.warning(e)\n",
    "            return None\n",
    "\n",
    "        self.PreprocessingGlobalConfig.load(preprocessing_config)\n",
    "        self.PhraseCaptureLayerConfig.load(preprocessing_config)\n",
    "        self.TextClusteringLayerConfig.load(preprocessing_config)\n",
    "        self.NegativeSkipgrameLayerConfig.load(preprocessing_config)\n",
    "        self.W2VLayerConfig.load(preprocessing_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimeTokenizer:\n",
    "    def __init__(self):\n",
    "        self.prime_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "\n",
    "        self.prime_tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])\n",
    "\n",
    "        self.prime_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "        self.prime_tokenizer.post_processor = TemplateProcessing(\n",
    "            single=\"[CLS] $A [SEP]\",\n",
    "            pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "            special_tokens=[\n",
    "                (\"[CLS]\", 1),\n",
    "                (\"[SEP]\", 2),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        self.trainer = WordPieceTrainer(\n",
    "            vocab_size=153411, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    "        )\n",
    "\n",
    "        self.prime_tokenizer.decoder = decoders.WordPiece()\n",
    "        self.prime_tokenizer.enable_padding(length=200)\n",
    "        self.prime_tokenizer.enable_truncation(200)\n",
    "\n",
    "    def text_to_sequence(self, input_) -> List[tokenizers.Encoding]:\n",
    "        if type(input_) is list:\n",
    "            return self.prime_tokenizer.encode_batch(input_)\n",
    "        return self.prime_tokenizer.encode(input_)\n",
    "\n",
    "    def sequence_to_text(self, input_) -> List[str]:\n",
    "        if type(input_) is list:\n",
    "            return self.prime_tokenizer.decode_batch(batch)\n",
    "        return self.prime_tokenizer.decode(input_)\n",
    "\n",
    "    def train(self, data):\n",
    "        log_itr = iter(data)\n",
    "        tqdm_log_itr = tqdm(iterable=log_itr)\n",
    "#         self.prime_tokenizer.train()\n",
    "#         for _ in tqdm(range(len(data))):\n",
    "#             log = log_itr.__next__()\n",
    "        self.prime_tokenizer.train_from_iterator(tqdm_log_itr.__iter__(), self.trainer)\n",
    "#         self.prime_tokenizer.train_from_iterator(log_itr, self.trainer)\n",
    "        self.prime_tokenizer.save(SOURCE + \"/results/prime_tokenizer.json\")\n",
    "\n",
    "    def get_tokenizer(self) -> Tokenizer:\n",
    "        return self.prime_tokenizer\n",
    "\n",
    "    def get_vocab(self) -> Dict[str, int]:\n",
    "        return self.prime_tokenizer.get_vocab()\n",
    "    \n",
    "    def get_vocab_size(self) -> int:\n",
    "        return self.prime_tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "#     if not os.path.exists(path):\n",
    "#         return\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "#     elif os.path.isdir(path):\n",
    "#         shutil.rmtree(path)\n",
    "#         return\n",
    "\n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxst8UQeq8sL"
   },
   "source": [
    "### Standardize Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FIbxj60aLAfC"
   },
   "outputs": [],
   "source": [
    "def standardize_logs(logs: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # remove timestamps\n",
    "    logs['log'] = logs['log'].replace(\n",
    "        to_replace=r'(?:\\d{4}-\\d{2}-\\d{2}[\\sT]\\d{2}:\\d{2}:\\d{2}([.,]\\d{3}|\\s))|(?:\\s{2,})',\n",
    "        value=' ',\n",
    "        regex=True)\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "QLKVLZioq_2i",
    "tags": []
   },
   "source": [
    "### PhraseCaptureLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gFTBqUREEHLn"
   },
   "outputs": [],
   "source": [
    "class PhraseCaptureLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 config: PhraseCaptureLayerConfig,\n",
    "                 global_config: PreprocessingGlobalConfig):\n",
    "\n",
    "        super(PhraseCaptureLayer, self).__init__()\n",
    "        self.min_count = config.min_count\n",
    "        self.threshold = config.threshold\n",
    "        self.load_model = config.load_model\n",
    "        self.save_model = config.save_model\n",
    "        self.path = global_config.path\n",
    "        self.model_name = config.model_name\n",
    "\n",
    "        if self.load_model:\n",
    "            self.phrase_model = joblib.load(SOURCE +\n",
    "                                            self.path +\n",
    "                                            self.model_name)\n",
    "        else:\n",
    "            self.phrase_model = Phrases(min_count=self.min_count,\n",
    "                                        threshold=self.threshold)\n",
    "\n",
    "    def call(self, corpus, training):\n",
    "\n",
    "        def clean_log(log):\n",
    "            log = log.lower().strip()\n",
    "            return re.sub(r'\\s{2,}', ' ', log)\n",
    "\n",
    "        def reorganize_return(corpus_with_phrases):\n",
    "            log_list = []\n",
    "            for tokenized_log in corpus_with_phrases:\n",
    "                log_list.append(' '.join(tokenized_log))\n",
    "            return log_list\n",
    "\n",
    "        split_corpus = [log.split(' ') for log in corpus['log']]\n",
    "\n",
    "        if not training:\n",
    "            self.phrase_model = self.phrase_model.freeze()\n",
    "        else:\n",
    "            self.phrase_model.add_vocab(split_corpus)\n",
    "\n",
    "        if self.save_model:\n",
    "            save_model(self.phrase_model, SOURCE + self.path + self.model_name)\n",
    "\n",
    "        corpus_with_phrases = self.phrase_model.__getitem__(split_corpus)\n",
    "        return reorganize_return(corpus_with_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "eb6Ncm7-rKLZ",
    "tags": []
   },
   "source": [
    "### TextClusteringLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nGOICjK9MtxY"
   },
   "outputs": [],
   "source": [
    "class TextClusteringLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 config: TextClusteringLayerConfig,\n",
    "                 global_config: PreprocessingGlobalConfig):\n",
    "\n",
    "        super(TextClusteringLayer, self).__init__()\n",
    "        self.load_model = config.load_model\n",
    "        self.save_model = config.save_model\n",
    "        self.path = global_config.path\n",
    "        self.model_name = config.model_name\n",
    "\n",
    "        if self.load_model is True:\n",
    "            self.template_miner = joblib.load(SOURCE +\n",
    "                                              self.path +\n",
    "                                              self.model_name)\n",
    "        else:\n",
    "            self.template_miner = drain3.TemplateMiner()\n",
    "\n",
    "    def call(self, corpus, training):\n",
    "        if training:\n",
    "            for log in corpus:\n",
    "                self.template_miner.add_log_message(log)\n",
    "            if self.save_model:\n",
    "                save_model(self.template_miner,\n",
    "                           SOURCE + self.path + self.model_name)\n",
    "\n",
    "            for idx, log in enumerate(corpus):\n",
    "                template = self.template_miner.match(log).get_template()\n",
    "                corpus[idx] = template\n",
    "\n",
    "            return [re.sub(pattern=r' +',\n",
    "                           repl=' ',\n",
    "                           string=cluster) for cluster in corpus]\n",
    "        else:\n",
    "            log_list = []\n",
    "            for log in corpus:\n",
    "                match_cluster = self.template_miner.match(log)\n",
    "                if match_cluster is None:\n",
    "                    match_cluster = self.template_miner.add_log_message(log)\n",
    "                log_list.append(match_cluster)\n",
    "            return [re.sub(pattern=r' +',\n",
    "                           repl=' ',\n",
    "                           string=cluster.get_template()) for cluster in log_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "Jl_BXs9DrSA5",
    "tags": []
   },
   "source": [
    "### NegativeSkipgramLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GAfbeuTcnFQK"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NSLBundle:\n",
    "    vocab: dict\n",
    "    targets: list\n",
    "    contexts: list\n",
    "    labels: list\n",
    "\n",
    "\n",
    "class NegativeSkipgramLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 config: NegativeSkipgramLayerConfig,\n",
    "                 global_config: PreprocessingGlobalConfig):\n",
    "\n",
    "        super(NegativeSkipgramLayer, self).__init__()\n",
    "        self.vocab_size = 0\n",
    "        self.vectorized_logs, self.corpus = [], []\n",
    "        self.targets, self.contexts, self.labels = [], [], []\n",
    "        self.vocab = {}\n",
    "        self.embedding_dim = global_config.embed_size\n",
    "        self.window_size = config.window_size\n",
    "        self.load_data = config.load_model\n",
    "        self.save_data = config.save_model\n",
    "        self.num_neg_sampling = global_config.num_neg_sampling\n",
    "        self.path = global_config.path\n",
    "\n",
    "    def collect_vocabulary(self):\n",
    "        self.vocab[0] = '<pad>'\n",
    "\n",
    "        # --- OLD --- No longer need to fit\n",
    "        # log_tokenizer.fit_on_texts(self.corpus)\n",
    "        # TODO: Need to add text to seqeuence methods (Instead of  Tokenize)\n",
    "        self.vectorized_logs = log_tokenizer.texts_to_sequences(self.corpus)\n",
    "\n",
    "        # TODO: Need to add word vocabulary dictionary options\n",
    "        self.vocab.update({v: k for k, v in log_tokenizer.word_index.items()})\n",
    "        self.vocab_size = len(self.vocab.keys())\n",
    "\n",
    "    def find_word_context(self):\n",
    "\n",
    "        # Build the sampling table for vocab_size tokens.\n",
    "        sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(len(self.vocab))\n",
    "\n",
    "        for sequence in tqdm(self.vectorized_logs, position=0, leave=True):\n",
    "\n",
    "            positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "                sequence,\n",
    "                vocabulary_size=len(self.vocab),\n",
    "                sampling_table=sampling_table,\n",
    "                window_size=self.window_size,\n",
    "                negative_samples=0)\n",
    "\n",
    "            for target_word, context_word in positive_skip_grams:\n",
    "                context_class = tf.expand_dims(\n",
    "                    tf.constant([context_word], dtype='int64'), 1)\n",
    "\n",
    "                negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                    true_classes=context_class,\n",
    "                    num_true=1,\n",
    "                    num_sampled=self.num_neg_sampling,\n",
    "                    unique=True,\n",
    "                    range_max=len(self.vocab),\n",
    "                    seed=42,\n",
    "                    name=\"negative_sampling\")\n",
    "\n",
    "                negative_sampling_candidates = tf.expand_dims(\n",
    "                    negative_sampling_candidates, 1)\n",
    "\n",
    "                context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "                label = tf.constant([1] + [0] * self.num_neg_sampling, dtype='int64')\n",
    "\n",
    "                self.targets.append(target_word)\n",
    "                self.contexts.append(context)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def call(self, corpus, training):\n",
    "        if self.load_data:\n",
    "            print(\"WTF X 2\")\n",
    "            try:\n",
    "                self.vocab = joblib.load(SOURCE + self.path + 'vocab.joblib')\n",
    "                self.targets = joblib.load(SOURCE + self.path + 'targets.joblib')\n",
    "                self.contexts = joblib.load(SOURCE + self.path + 'contexts.joblib')\n",
    "                self.labels = joblib.load(SOURCE + self.path + 'labels.joblib')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            self.corpus = corpus\n",
    "            self.collect_vocabulary()\n",
    "            self.find_word_context()\n",
    "\n",
    "            if self.save_data:\n",
    "                save_model(self.vocab,\n",
    "                           SOURCE + self.path + 'vocab.joblib')\n",
    "                save_model(self.targets,\n",
    "                           SOURCE + self.path + 'targets.joblib')\n",
    "                save_model(self.contexts,\n",
    "                           SOURCE + self.path + 'contexts.joblib')\n",
    "                save_model(self.labels,\n",
    "                           SOURCE + self.path + 'labels.joblib')\n",
    "\n",
    "        return NSLBundle(self.vocab, self.targets, self.contexts, self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "DxXEjBM_rWYC",
    "tags": []
   },
   "source": [
    "### Word2VecEmbeddingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-JyKVfDf8CaP"
   },
   "outputs": [],
   "source": [
    "class Word2VecEmbeddingLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 config: W2VLayerConfig,\n",
    "                 global_config: PreprocessingGlobalConfig):\n",
    "\n",
    "        super(Word2VecEmbeddingLayer, self).__init__()\n",
    "        self.embeddings = {}\n",
    "        self.embedding_dim = global_config.embed_size\n",
    "        self.buffer_size = global_config.buffer_size\n",
    "        self.num_neg_sampling = global_config.num_neg_sampling\n",
    "        self.load_model = config.load_model\n",
    "        self.save_model = config.save_model\n",
    "        self.batch_size = config.batch_size\n",
    "        self.epochs = config.epochs\n",
    "        self.Optimizer = tf.keras.optimizers.Adam()\n",
    "        self.path = global_config.path\n",
    "        self.model_name = config.model_name\n",
    "\n",
    "        if self.load_model:\n",
    "            self.Word2Vec = load_model(SOURCE + self.path + self.model_name)\n",
    "        else:\n",
    "            self.Word2Vec = None\n",
    "\n",
    "    def call(self, in_bundle, training):\n",
    "\n",
    "        vocab = in_bundle.vocab\n",
    "        targets = in_bundle.targets\n",
    "        contexts = in_bundle.contexts\n",
    "        labels = in_bundle.labels\n",
    "\n",
    "        if self.Word2Vec is None:\n",
    "            self.Word2Vec = Word2Vec(len(vocab.keys()), self.embedding_dim, self.num_neg_sampling)\n",
    "            self.Word2Vec.compile(\n",
    "                optimizer=self.Optimizer,\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "        dataset = dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)\n",
    "        dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "        if training:\n",
    "            self.Word2Vec.fit(dataset, epochs=self.epochs)\n",
    "\n",
    "        weights = self.Word2Vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "\n",
    "        for word in vocab.items():\n",
    "            self.embeddings.update({\n",
    "                word[1]: weights[word[0]]\n",
    "                })\n",
    "\n",
    "        if self.save_model:\n",
    "            if os.path.exists(SOURCE + self.path + self.model_name):\n",
    "                shutil.rmtree(SOURCE + self.path + self.model_name)\n",
    "            self.Word2Vec.save(SOURCE + self.path + self.model_name)\n",
    "            out_v = io.open(SOURCE + self.path + 'vectors.tsv', 'w', encoding='utf-8')\n",
    "            out_m = io.open(SOURCE + self.path + 'metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "            for index, word in enumerate(vocab.values()):\n",
    "                if index == 0:\n",
    "                    continue  # skip 0, it's padding.\n",
    "                vec = weights[index]\n",
    "                out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "                out_m.write(word + \"\\n\")\n",
    "            out_v.close()\n",
    "            out_m.close()\n",
    "\n",
    "        self.Word2Vec.summary()\n",
    "        return self.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "id": "6hQRAbPfrZwt",
    "tags": []
   },
   "source": [
    "### Word2VecModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "H_GiqTup8AY3"
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, num_neg_sampling):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=1, # input length 1 since we are focusing on one token\n",
    "            name=\"w2v_embedding\")\n",
    "\n",
    "        self.context_embedding = tf.keras.layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=num_neg_sampling + 1) # window size for contextual \n",
    "            # reasoning behind the sample token\n",
    "        self.dots = tf.keras.layers.Dot(axes=(3, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        we = self.target_embedding(target)\n",
    "        ce = self.context_embedding(context)\n",
    "        dots = self.dots([ce, we])\n",
    "        return self.flatten(dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvhQ3bvitv5b"
   },
   "source": [
    "### W2V_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "R_nmehscsdmv"
   },
   "outputs": [],
   "source": [
    "class W2V_Pipeline(tf.keras.Model):\n",
    "    def __init__(self, config: PreprocessingPipelineConfig):\n",
    "        super(W2V_Pipeline, self).__init__()\n",
    "\n",
    "        self.PCL = PhraseCaptureLayer(config.PhraseCaptureLayerConfig,\n",
    "                                      config.PreprocessingGlobalConfig)\n",
    "\n",
    "        self.global_train = config.PreprocessingGlobalConfig.global_training\n",
    "        self.PCL_train = True if self.global_train else config.PhraseCaptureLayerConfig.training  # noqa\n",
    "\n",
    "    def call(self, x, tokenizer: PrimeTokenizer):\n",
    "        x = standardize_logs(x)\n",
    "        x = self.PCL(x, self.PCL_train)\n",
    "        tokenizer.train(x)\n",
    "        joblib.dump(tokenizer, SOURCE + '/results/tokenizer.joblib')\n",
    "        print('dooooooooone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>container_name</th>\n",
       "      <th>log</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>2021-01-21T17:19:21.350Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:19:12,170 | ERROR | Thread-244  ...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>2021-01-21T17:19:21.350Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:19:12,170 | ERROR | Thread-244  ...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>2021-01-21T17:19:21.350Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:19:11,906 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>2021-01-21T17:19:21.350Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:19:11,906 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>nitf-messaging-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,488 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,499 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,646 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>2021-01-21T17:34:19.606Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:13,771 | ERROR | Thread-281  ...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,499 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>2021-01-21T17:34:19.606Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:15,394 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7768</th>\n",
       "      <td>2021-01-21T17:34:19.606Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:15,394 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,646 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>2021-01-21T17:34:19.605Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:13,481 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>2021-01-21T17:34:19.606Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:13,771 | ERROR | Thread-281  ...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,639 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,488 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>2021-01-21T17:46:39.665Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:46:31,639 | INFO  | cxf-StsThrea...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272</th>\n",
       "      <td>2021-01-21T17:34:19.605Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:13,481 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10273</th>\n",
       "      <td>2021-01-21T17:34:19.606Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:15,772 | ERROR | Thread-282  ...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11065</th>\n",
       "      <td>2021-01-21T17:34:19.606Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:34:15,772 | ERROR | Thread-282  ...</td>\n",
       "      <td>newscene-bundle-stopped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11837</th>\n",
       "      <td>2021-01-21T17:49:25.617Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:49:17,145 | ERROR | Thread-321  ...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13590</th>\n",
       "      <td>2021-01-21T17:49:25.617Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:49:17,145 | ERROR | Thread-321  ...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14116</th>\n",
       "      <td>2021-01-21T17:49:25.617Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:49:16,947 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>2021-01-21T17:49:25.617Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T17:49:16,947 | INFO  | 1]-nio2-thre...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16898</th>\n",
       "      <td>2021-01-21T18:13:09.800Z</td>\n",
       "      <td>core.soaesb</td>\n",
       "      <td>2021-01-21T18:13:03,024 | INFO  | lCheckerThre...</td>\n",
       "      <td>core.soaesb-dead-soa-process</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp container_name  \\\n",
       "1271   2021-01-21T17:19:21.350Z    core.soaesb   \n",
       "1486   2021-01-21T17:19:21.350Z    core.soaesb   \n",
       "4897   2021-01-21T17:19:21.350Z    core.soaesb   \n",
       "5465   2021-01-21T17:19:21.350Z    core.soaesb   \n",
       "6712   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "6713   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "6734   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "6766   2021-01-21T17:34:19.606Z    core.soaesb   \n",
       "6963   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "7502   2021-01-21T17:34:19.606Z    core.soaesb   \n",
       "7768   2021-01-21T17:34:19.606Z    core.soaesb   \n",
       "8239   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "8990   2021-01-21T17:34:19.605Z    core.soaesb   \n",
       "9232   2021-01-21T17:34:19.606Z    core.soaesb   \n",
       "9447   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "9964   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "9965   2021-01-21T17:46:39.665Z    core.soaesb   \n",
       "10272  2021-01-21T17:34:19.605Z    core.soaesb   \n",
       "10273  2021-01-21T17:34:19.606Z    core.soaesb   \n",
       "11065  2021-01-21T17:34:19.606Z    core.soaesb   \n",
       "11837  2021-01-21T17:49:25.617Z    core.soaesb   \n",
       "13590  2021-01-21T17:49:25.617Z    core.soaesb   \n",
       "14116  2021-01-21T17:49:25.617Z    core.soaesb   \n",
       "14378  2021-01-21T17:49:25.617Z    core.soaesb   \n",
       "16898  2021-01-21T18:13:09.800Z    core.soaesb   \n",
       "\n",
       "                                                     log  \\\n",
       "1271   2021-01-21T17:19:12,170 | ERROR | Thread-244  ...   \n",
       "1486   2021-01-21T17:19:12,170 | ERROR | Thread-244  ...   \n",
       "4897   2021-01-21T17:19:11,906 | INFO  | 1]-nio2-thre...   \n",
       "5465   2021-01-21T17:19:11,906 | INFO  | 1]-nio2-thre...   \n",
       "6712   2021-01-21T17:46:31,488 | INFO  | cxf-StsThrea...   \n",
       "6713   2021-01-21T17:46:31,499 | INFO  | cxf-StsThrea...   \n",
       "6734   2021-01-21T17:46:31,646 | INFO  | cxf-StsThrea...   \n",
       "6766   2021-01-21T17:34:13,771 | ERROR | Thread-281  ...   \n",
       "6963   2021-01-21T17:46:31,499 | INFO  | cxf-StsThrea...   \n",
       "7502   2021-01-21T17:34:15,394 | INFO  | 1]-nio2-thre...   \n",
       "7768   2021-01-21T17:34:15,394 | INFO  | 1]-nio2-thre...   \n",
       "8239   2021-01-21T17:46:31,646 | INFO  | cxf-StsThrea...   \n",
       "8990   2021-01-21T17:34:13,481 | INFO  | 1]-nio2-thre...   \n",
       "9232   2021-01-21T17:34:13,771 | ERROR | Thread-281  ...   \n",
       "9447   2021-01-21T17:46:31,639 | INFO  | cxf-StsThrea...   \n",
       "9964   2021-01-21T17:46:31,488 | INFO  | cxf-StsThrea...   \n",
       "9965   2021-01-21T17:46:31,639 | INFO  | cxf-StsThrea...   \n",
       "10272  2021-01-21T17:34:13,481 | INFO  | 1]-nio2-thre...   \n",
       "10273  2021-01-21T17:34:15,772 | ERROR | Thread-282  ...   \n",
       "11065  2021-01-21T17:34:15,772 | ERROR | Thread-282  ...   \n",
       "11837  2021-01-21T17:49:17,145 | ERROR | Thread-321  ...   \n",
       "13590  2021-01-21T17:49:17,145 | ERROR | Thread-321  ...   \n",
       "14116  2021-01-21T17:49:16,947 | INFO  | 1]-nio2-thre...   \n",
       "14378  2021-01-21T17:49:16,947 | INFO  | 1]-nio2-thre...   \n",
       "16898  2021-01-21T18:13:03,024 | INFO  | lCheckerThre...   \n",
       "\n",
       "                               label  \n",
       "1271   nitf-messaging-bundle-stopped  \n",
       "1486   nitf-messaging-bundle-stopped  \n",
       "4897   nitf-messaging-bundle-stopped  \n",
       "5465   nitf-messaging-bundle-stopped  \n",
       "6712         newscene-bundle-stopped  \n",
       "6713         newscene-bundle-stopped  \n",
       "6734         newscene-bundle-stopped  \n",
       "6766         newscene-bundle-stopped  \n",
       "6963         newscene-bundle-stopped  \n",
       "7502         newscene-bundle-stopped  \n",
       "7768         newscene-bundle-stopped  \n",
       "8239         newscene-bundle-stopped  \n",
       "8990         newscene-bundle-stopped  \n",
       "9232         newscene-bundle-stopped  \n",
       "9447         newscene-bundle-stopped  \n",
       "9964         newscene-bundle-stopped  \n",
       "9965         newscene-bundle-stopped  \n",
       "10272        newscene-bundle-stopped  \n",
       "10273        newscene-bundle-stopped  \n",
       "11065        newscene-bundle-stopped  \n",
       "11837                        healthy  \n",
       "13590                        healthy  \n",
       "14116                        healthy  \n",
       "14378                        healthy  \n",
       "16898   core.soaesb-dead-soa-process  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container_dataset.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiNfWpckbW3A"
   },
   "source": [
    "## W2V Pipeline Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ll4n92B5rGYW",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:52:47,241 INFO | collecting all words and their counts\n",
      "2021-05-27 16:52:47,241 INFO | PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2021-05-27 16:52:47,524 INFO | PROGRESS: at sentence #10000, processed 201154 words and 14141 word types\n",
      "2021-05-27 16:52:47,825 INFO | PROGRESS: at sentence #20000, processed 416699 words and 22358 word types\n",
      "2021-05-27 16:52:48,101 INFO | PROGRESS: at sentence #30000, processed 620573 words and 29247 word types\n",
      "2021-05-27 16:52:48,368 INFO | PROGRESS: at sentence #40000, processed 817972 words and 35127 word types\n",
      "2021-05-27 16:52:48,636 INFO | PROGRESS: at sentence #50000, processed 1016814 words and 40970 word types\n",
      "2021-05-27 16:52:48,912 INFO | PROGRESS: at sentence #60000, processed 1214843 words and 46444 word types\n",
      "2021-05-27 16:52:49,207 INFO | PROGRESS: at sentence #70000, processed 1412743 words and 51187 word types\n",
      "2021-05-27 16:52:49,483 INFO | PROGRESS: at sentence #80000, processed 1614224 words and 55846 word types\n",
      "2021-05-27 16:52:49,748 INFO | PROGRESS: at sentence #90000, processed 1811239 words and 60244 word types\n",
      "2021-05-27 16:52:50,027 INFO | PROGRESS: at sentence #100000, processed 2010128 words and 64455 word types\n",
      "2021-05-27 16:52:50,304 INFO | PROGRESS: at sentence #110000, processed 2209670 words and 68521 word types\n",
      "2021-05-27 16:52:50,577 INFO | PROGRESS: at sentence #120000, processed 2409585 words and 72328 word types\n",
      "2021-05-27 16:52:50,846 INFO | PROGRESS: at sentence #130000, processed 2606410 words and 75845 word types\n",
      "2021-05-27 16:52:51,126 INFO | PROGRESS: at sentence #140000, processed 2808075 words and 79437 word types\n",
      "2021-05-27 16:52:51,396 INFO | PROGRESS: at sentence #150000, processed 3006108 words and 82742 word types\n",
      "2021-05-27 16:52:51,670 INFO | PROGRESS: at sentence #160000, processed 3204115 words and 86050 word types\n",
      "2021-05-27 16:52:51,943 INFO | PROGRESS: at sentence #170000, processed 3403290 words and 89158 word types\n",
      "2021-05-27 16:52:52,212 INFO | PROGRESS: at sentence #180000, processed 3601651 words and 92352 word types\n",
      "2021-05-27 16:52:52,481 INFO | PROGRESS: at sentence #190000, processed 3799576 words and 95604 word types\n",
      "2021-05-27 16:52:52,758 INFO | PROGRESS: at sentence #200000, processed 3998956 words and 98674 word types\n",
      "2021-05-27 16:52:53,031 INFO | PROGRESS: at sentence #210000, processed 4198252 words and 101746 word types\n",
      "2021-05-27 16:52:53,307 INFO | PROGRESS: at sentence #220000, processed 4397898 words and 104729 word types\n",
      "2021-05-27 16:52:53,579 INFO | PROGRESS: at sentence #230000, processed 4596415 words and 107574 word types\n",
      "2021-05-27 16:52:53,855 INFO | PROGRESS: at sentence #240000, processed 4797083 words and 110380 word types\n",
      "2021-05-27 16:52:54,125 INFO | PROGRESS: at sentence #250000, processed 4995235 words and 113161 word types\n",
      "2021-05-27 16:52:54,408 INFO | PROGRESS: at sentence #260000, processed 5195887 words and 115997 word types\n",
      "2021-05-27 16:52:54,685 INFO | PROGRESS: at sentence #270000, processed 5394127 words and 118733 word types\n",
      "2021-05-27 16:52:54,965 INFO | PROGRESS: at sentence #280000, processed 5593825 words and 121476 word types\n",
      "2021-05-27 16:52:55,251 INFO | PROGRESS: at sentence #290000, processed 5793078 words and 124178 word types\n",
      "2021-05-27 16:52:55,530 INFO | PROGRESS: at sentence #300000, processed 5993130 words and 126879 word types\n",
      "2021-05-27 16:52:55,817 INFO | PROGRESS: at sentence #310000, processed 6199279 words and 137364 word types\n",
      "2021-05-27 16:52:56,088 INFO | PROGRESS: at sentence #320000, processed 6392417 words and 145972 word types\n",
      "2021-05-27 16:52:56,589 INFO | PROGRESS: at sentence #330000, processed 6742740 words and 208854 word types\n",
      "2021-05-27 16:52:56,853 INFO | PROGRESS: at sentence #340000, processed 6937402 words and 221918 word types\n",
      "2021-05-27 16:52:57,122 INFO | PROGRESS: at sentence #350000, processed 7130082 words and 225344 word types\n",
      "2021-05-27 16:52:57,377 INFO | PROGRESS: at sentence #360000, processed 7319479 words and 227798 word types\n",
      "2021-05-27 16:52:57,640 INFO | PROGRESS: at sentence #370000, processed 7507853 words and 233470 word types\n",
      "2021-05-27 16:52:57,892 INFO | PROGRESS: at sentence #380000, processed 7691675 words and 239902 word types\n",
      "2021-05-27 16:52:58,144 INFO | PROGRESS: at sentence #390000, processed 7878249 words and 242823 word types\n",
      "2021-05-27 16:52:58,387 INFO | PROGRESS: at sentence #400000, processed 8056797 words and 245417 word types\n",
      "2021-05-27 16:52:58,648 INFO | PROGRESS: at sentence #410000, processed 8244752 words and 252403 word types\n",
      "2021-05-27 16:52:58,907 INFO | PROGRESS: at sentence #420000, processed 8431421 words and 254957 word types\n",
      "2021-05-27 16:52:59,162 INFO | PROGRESS: at sentence #430000, processed 8618317 words and 256063 word types\n",
      "2021-05-27 16:52:59,477 INFO | PROGRESS: at sentence #440000, processed 8840303 words and 261048 word types\n",
      "2021-05-27 16:52:59,781 INFO | PROGRESS: at sentence #450000, processed 9058666 words and 262211 word types\n",
      "2021-05-27 16:53:00,072 INFO | PROGRESS: at sentence #460000, processed 9271338 words and 270549 word types\n",
      "2021-05-27 16:53:00,387 INFO | PROGRESS: at sentence #470000, processed 9502654 words and 274269 word types\n",
      "2021-05-27 16:53:00,723 INFO | PROGRESS: at sentence #480000, processed 9748691 words and 275151 word types\n",
      "2021-05-27 16:53:01,037 INFO | PROGRESS: at sentence #490000, processed 9979591 words and 279552 word types\n",
      "2021-05-27 16:53:01,338 INFO | PROGRESS: at sentence #500000, processed 10198174 words and 282921 word types\n",
      "2021-05-27 16:53:01,621 INFO | PROGRESS: at sentence #510000, processed 10409976 words and 283839 word types\n",
      "2021-05-27 16:53:01,894 INFO | PROGRESS: at sentence #520000, processed 10613376 words and 288042 word types\n",
      "2021-05-27 16:53:02,184 INFO | PROGRESS: at sentence #530000, processed 10827598 words and 290260 word types\n",
      "2021-05-27 16:53:02,489 INFO | PROGRESS: at sentence #540000, processed 11048032 words and 291416 word types\n",
      "2021-05-27 16:53:02,797 INFO | PROGRESS: at sentence #550000, processed 11266724 words and 292397 word types\n",
      "2021-05-27 16:53:03,107 INFO | PROGRESS: at sentence #560000, processed 11490862 words and 294018 word types\n",
      "2021-05-27 16:53:03,427 INFO | PROGRESS: at sentence #570000, processed 11724545 words and 294787 word types\n",
      "2021-05-27 16:53:03,750 INFO | PROGRESS: at sentence #580000, processed 11958996 words and 295091 word types\n",
      "2021-05-27 16:53:04,053 INFO | PROGRESS: at sentence #590000, processed 12176653 words and 300473 word types\n",
      "2021-05-27 16:53:04,350 INFO | PROGRESS: at sentence #600000, processed 12390830 words and 301567 word types\n",
      "2021-05-27 16:53:04,652 INFO | PROGRESS: at sentence #610000, processed 12607505 words and 302984 word types\n",
      "2021-05-27 16:53:04,966 INFO | PROGRESS: at sentence #620000, processed 12825956 words and 304608 word types\n",
      "2021-05-27 16:53:05,288 INFO | PROGRESS: at sentence #630000, processed 13045284 words and 308557 word types\n",
      "2021-05-27 16:53:05,589 INFO | PROGRESS: at sentence #640000, processed 13263673 words and 309620 word types\n",
      "2021-05-27 16:53:05,860 INFO | PROGRESS: at sentence #650000, processed 13460526 words and 311436 word types\n",
      "2021-05-27 16:53:06,159 INFO | PROGRESS: at sentence #660000, processed 13678000 words and 315363 word types\n",
      "2021-05-27 16:53:06,456 INFO | PROGRESS: at sentence #670000, processed 13892684 words and 316756 word types\n",
      "2021-05-27 16:53:06,764 INFO | PROGRESS: at sentence #680000, processed 14109060 words and 316884 word types\n",
      "2021-05-27 16:53:07,061 INFO | PROGRESS: at sentence #690000, processed 14325562 words and 317820 word types\n",
      "2021-05-27 16:53:07,380 INFO | PROGRESS: at sentence #700000, processed 14558739 words and 318797 word types\n",
      "2021-05-27 16:53:07,695 INFO | PROGRESS: at sentence #710000, processed 14788377 words and 319050 word types\n",
      "2021-05-27 16:53:07,934 INFO | collected 319112 token types (unigram + bigrams) from a corpus of 14958663 words and 717348 sentences\n",
      "2021-05-27 16:53:07,934 INFO | merged Phrases<319112 vocab, min_count=5, threshold=7, max_vocab_size=40000000>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "717348it [00:14, 50980.01it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'tokenizers.trainers.WordPieceTrainer' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-197e8b9b1f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprime_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrimeTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mw2vp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW2V_Pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mw2vp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# prime_tokenizer.train(dataset['log'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-faea302ffcaa>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, tokenizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCL_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOURCE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/results/tokenizer.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dooooooooone'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_setter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                     \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'tokenizers.trainers.WordPieceTrainer' object"
     ]
    }
   ],
   "source": [
    "# ** Preprocessing **\n",
    "'''\n",
    "standardize_logs\n",
    "'''\n",
    "\n",
    "# ** Model **\n",
    "# 1.\n",
    "# LogTokenEmbedder\n",
    "'''\n",
    "Seq = [PCL\n",
    "       TCL\n",
    "       NSL\n",
    "       GT1: W2V] -> {embedding_matrix, vocab}\n",
    "'''\n",
    "######\n",
    "\n",
    "# 2.\n",
    "# Transformer Stuff\n",
    "'''\n",
    "{log, embedding_matrix, vocab} ->\n",
    "GT2: Transformer -> prediction\n",
    "'''\n",
    "# LOG_DIR = SOURCE + 'logs'\n",
    "# metadata = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "# config = projector.ProjectorConfig()\n",
    "\n",
    "config_path = SOURCE + '/assets/notebooks/PreprocessingConfig.yaml'\n",
    "preprocessing_config = PreprocessingPipelineConfig()\n",
    "preprocessing_config.load(config_path)\n",
    "\n",
    "# --- OLD SUBWORD TOKENIZER ---\n",
    "# log_tokenizer = Tokenizer(src_path=SOURCE + '/assets/notebooks/demofile2.txt',\n",
    "#                           model_path=SOURCE + '/assets/notebooks/sentencepiece_model',\n",
    "#                           num_words=preprocessing_config.PreprocessingGlobalConfig.max_vocab_size)\n",
    "# w2vp = W2V_Pipeline(preprocessing_config)\n",
    "# embed_weights = w2vp(container_dataset)\n",
    "\n",
    "# --- SUBWORD TOKENIZER --\n",
    "prime_tokenizer = PrimeTokenizer()\n",
    "w2vp = W2V_Pipeline(preprocessing_config)\n",
    "w2vp(dataset, prime_tokenizer)\n",
    "# prime_tokenizer.train(dataset['log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'info', '(', 'qtp1752461090', '-', '16', ')', '[', 'c', ':', 'catalog', 's', ':', 'shard1', 'r', ':', 'core_node3', 'x', ':', 'catalog_shard1_replica_n1', ']', 'o', '.', 'a', '.', 's', '.', 'u', '.', 'p', '.', 'logupdateprocessorfactory', '[', 'catalog_shard1_replica_n1', ']', 'webapp', '=/', 'solr', 'path', '=/', 'update', 'params', '={', 'wt', '=', 'javabin', '&', 'version', '=', '2', '}{', 'add', '=[', '799', '##1df', '##2b6', '##81', '##a4', '##753', '##969', '##ed2', '##fa0e', '##f916', '##ec', '(', '16895271934', '##6866', '##5856', ')]}', '0', '12', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "value = random.randint(0, 100000)\n",
    "print(prime_tokenizer.text_to_sequence(dataset['log'].iloc[value]).tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWSpd9MecA8b"
   },
   "source": [
    "## W2V Dash "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRGlsN0McF1D"
   },
   "source": [
    "### Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "l9AAeUOmnz4h"
   },
   "outputs": [],
   "source": [
    "def tree_parser(node, inner_list, outer_list, root_node, depth):\n",
    "    d = node.key_to_child_node  # dict\n",
    "    for token in list(d.keys()):\n",
    "        if len(root_node.key_to_child_node.keys()) == 0:\n",
    "            ret_list = []\n",
    "            for row in outer_list:\n",
    "                proper_len = int(row[1])\n",
    "                if len(row) == proper_len+1 or len(row) + 1 == depth:\n",
    "                    ret_list.append(row)\n",
    "            return ret_list\n",
    "        inner_list.append(token)\n",
    "        child = d[token]\n",
    "        if child.key_to_child_node:\n",
    "            tree_parser(child, inner_list, outer_list, root_node, depth)\n",
    "        else:\n",
    "            d.pop(token)\n",
    "            outer_list.append(inner_list)\n",
    "            inner_list = ['root']\n",
    "            tree_parser(root_node, inner_list, outer_list, root_node, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_list_parser(node):\n",
    "    tree_df = []\n",
    "    curr_path = []\n",
    "    tree_dict = {}\n",
    "    prev_root = [(\"root\", node)]\n",
    "    while len(prev_root) > 0:\n",
    "        # Peek at last value\n",
    "        curr_root = prev_root[-1]\n",
    "\n",
    "        # Get the node element\n",
    "        curr_node = curr_root[1].key_to_child_node\n",
    "\n",
    "        # Follow path value if not already there\n",
    "        if len(curr_path) <= 0 or curr_path[-1] != curr_root[0]:\n",
    "            curr_path.append(curr_root[0])\n",
    "\n",
    "        visited = False\n",
    "        if curr_root[1] in tree_dict:\n",
    "            visited = True\n",
    "        else:\n",
    "            tree_dict[curr_root[1]] = True\n",
    "\n",
    "        # Check if value has any leaf nodes\n",
    "        if not visited and len(curr_node.keys()) > 0:\n",
    "            # Add those to the stack\n",
    "            for nn in curr_node.items():\n",
    "                prev_root.append((nn[0], nn[1]))\n",
    "        else:\n",
    "            # Remove previous node in the path\n",
    "            prev_root.pop()\n",
    "\n",
    "            # Record to the database if leaf\n",
    "            if len(curr_node.keys()) <= 0:\n",
    "                tree_df.append(deepcopy(curr_path))\n",
    "\n",
    "            # Move back up tree\n",
    "            curr_path.pop()\n",
    "    return tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendSpherical_np(xyz):\n",
    "    ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "    xy = xyz[:, 0]**2 + xyz[:, 1]**2\n",
    "    ptsnew[:, 3] = np.sqrt(xy + xyz[:, 2]**2)\n",
    "    ptsnew[:, 4] = np.arctan2(np.sqrt(xy), xyz[:, 2])  # for elevation angle defined from Z-axis down\n",
    "    # ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "    ptsnew[:, 5] = np.arctan2(xyz[:, 1], xyz[:, 0])\n",
    "    return ptsnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spherical_coords(xyz):\n",
    "    sph = np.zeros(shape=xyz.shape)\n",
    "    xy = xyz[:, 0]**2 + xyz[:, 1]**2\n",
    "    sph[:, 0] = np.sqrt(xy + xyz[:, 2]**2)\n",
    "    sph[:, 1] = np.arctan2(np.sqrt(xy), xyz[:, 2])\n",
    "    sph[:, 2] = np.arctan2(xyz[:, 1], xyz[:, 0])\n",
    "    return sph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCgMbFevmC88"
   },
   "source": [
    "The output of the W2V pipeline is a matrix of size [vocab size x embedding size] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jw4mwJz6eGa6"
   },
   "outputs": [],
   "source": [
    "# -- W2V Dash Environmental Variables -- #\n",
    "\n",
    "W2V_NEIGHBORS = 20\n",
    "RECURSION_LIMIT = 10**6\n",
    "N_PROJ_DIM = 3\n",
    "DASH_SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Projection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a60tfcLUoERG"
   },
   "outputs": [],
   "source": [
    "# -- Generate Data for Word Embeddings Projector -- #\n",
    "\n",
    "# shape = vocab size x embedding dim size\n",
    "weights = np.ndarray(shape=(len(embed_weights), w2v_config[\"embed_size\"]))\n",
    "\n",
    "# -- Populate Matrix for PCA -- #\n",
    "for idx, weight in enumerate(list(embed_weights.values())):\n",
    "    weights[idx, :] = weight\n",
    "\n",
    "# -- Dimensionality Reduction -- #\n",
    "pca = PCA(n_components=N_PROJ_DIM, random_state=DASH_SEED).fit(weights)\n",
    "ica = FastICA(n_components=N_PROJ_DIM, random_state=DASH_SEED).fit(weights)\n",
    "srp = SparseRandomProjection(n_components=N_PROJ_DIM, random_state=DASH_SEED).fit(weights)\n",
    "reduced_embeddings = pca.transform(weights)\n",
    "\n",
    "# -- Calculate Nearest Neighbors -- #\n",
    "model = NearestNeighbors(n_neighbors=W2V_NEIGHBORS, algorithm='auto')\n",
    "trained_embeddings = model.fit(reduced_embeddings)\n",
    "\n",
    "# Currently the array has a shape of vocab size x N_PROJ_DIM and contains\n",
    "# the fitted PCA data. We need to add the vocab in the first column so\n",
    "# we know which vectors are represented.\n",
    "scatter_plot_3d_cols = ['token', 'x1', 'x2', 'x3']\n",
    "embedding_vocab_arr = np.array(list(embed_weights.keys()))\n",
    "embedding_vocab_arr = np.expand_dims(embedding_vocab_arr, 1)\n",
    "named_reduced_embeddings = np.hstack((embedding_vocab_arr, reduced_embeddings))\n",
    "scatter_plot_3d_df = pd.DataFrame(\n",
    "    data=named_reduced_embeddings,\n",
    "    columns=scatter_plot_3d_cols)\n",
    "scatter_plot_3d_df['x1'] = pd.to_numeric(scatter_plot_3d_df['x1'])\n",
    "scatter_plot_3d_df['x2'] = pd.to_numeric(scatter_plot_3d_df['x2'])\n",
    "scatter_plot_3d_df['x3'] = pd.to_numeric(scatter_plot_3d_df['x3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC17hivjjKs0"
   },
   "source": [
    "We will build our plot using the tree_parser function. This function recursively\n",
    "steps through the drain3.TemplateMiner.drain.Node structure of our \n",
    "**TextClusteringLayer** (TCL). The recursion populates a np.array which is then used\n",
    "to build a pandas dataframe which the plotly treemap accepts. There is a column\n",
    "appended to the tail of the dataframe which counts the number of stars \n",
    "(wild card masks) present in the row. This is used to define the colors shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Treemap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7TkKEOFyRH3"
   },
   "outputs": [],
   "source": [
    "# By default python's recursion limit is 10**4 which is too small for our needs\n",
    "sys.setrecursionlimit(RECURSION_LIMIT)\n",
    "\n",
    "# The root node is the master node of the tree and will be our return point\n",
    "root_node = deepcopy(w2vp.TCL.template_miner.drain.root_node)\n",
    "parsed_tree = tree_to_list_parser(root_node)\n",
    "parsed_tree_df = pd.DataFrame(data=parsed_tree)\n",
    "\n",
    "# The returned dataframe has generic columns so we will provide custom labels\n",
    "n_cols = len(parsed_tree_df.columns)\n",
    "col_name_list = []\n",
    "for idx in range(n_cols):\n",
    "    col_name_list.append('level' + str(idx))\n",
    "parsed_tree_df.columns = col_name_list\n",
    "\n",
    "'''\n",
    "Without a color column our treemap would just be plain. We thought that taking\n",
    "the sum of the drain mask would be an interesting way to color the treemap.\n",
    "This lambda function will sum those values in each row and return them to a new\n",
    "columnn named 'sum'\n",
    "'''\n",
    "parsed_tree_df['sum'] = parsed_tree_df.apply(lambda x: x.str.contains('<*>'), axis=1).sum(axis=1)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dash Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.templates.default = \"plotly_dark\"\n",
    "external_stylesheets_url = 'https://drive.google.com/uc?export=view&id=19OXGQ5iJIjRZD4VEZ-xiVChDmj0-SlSF'  # noqa\n",
    "external_stylesheets = [external_stylesheets_url]\n",
    "\n",
    "CACHE_CONFIG = dict()\n",
    "CACHE_CONFIG['CACHE_TYPE'] = 'filesystem'\n",
    "CACHE_CONFIG['CACHE_DIR'] = SOURCE + '/results/dash_cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_d = dict()\n",
    "color_d['blue'] = 'rgb(66, 133, 244)'\n",
    "color_d['red'] = 'rgb(219, 68, 55)'\n",
    "color_d['yellow'] = 'rgb(244, 180, 0)'\n",
    "color_d['orange'] = 'rgb(255, 165, 0)'\n",
    "color_d['green'] = 'rgb(15, 157, 88)'\n",
    "color_d['mint'] = 'rgb(3, 218, 198)'\n",
    "color_d['dark mint'] = 'rgb(1, 135, 134)'\n",
    "color_d['dark purple'] = 'rgb(55, 0, 179)'\n",
    "color_d['purple'] = 'rgb(98, 0, 238)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dash Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= #\n",
    "#  3d Scatter Plot  #\n",
    "# ================= #\n",
    "\n",
    "# Line formatting\n",
    "scatter_plot_3d_line = dict()\n",
    "scatter_plot_3d_line['width'] = 2\n",
    "scatter_plot_3d_line['color'] = color_d['dark mint']\n",
    "\n",
    "scatter_plot_3d_selected_line = dict()\n",
    "scatter_plot_3d_selected_line['width'] = 2\n",
    "scatter_plot_3d_selected_line['color'] = color_d['dark mint']\n",
    "\n",
    "scatter_plot_3d_nonselected_line = dict()\n",
    "scatter_plot_3d_nonselected_line['width'] = 2\n",
    "scatter_plot_3d_nonselected_line['color'] = color_d['dark mint']\n",
    "\n",
    "scatter_plot_3d_darker_line = dict()\n",
    "scatter_plot_3d_darker_line['width'] = 2\n",
    "scatter_plot_3d_darker_line['color'] = color_d['dark purple']\n",
    "\n",
    "\n",
    "# Marker formatting\n",
    "scatter_plot_3d_marker = dict()\n",
    "scatter_plot_3d_marker['size'] = 5\n",
    "scatter_plot_3d_marker['line'] = scatter_plot_3d_line\n",
    "scatter_plot_3d_marker['color'] = color_d['mint']\n",
    "\n",
    "scatter_plot_3d_selected_marker = dict()\n",
    "scatter_plot_3d_selected_marker['size'] = 5\n",
    "scatter_plot_3d_selected_marker['color'] = color_d['mint']\n",
    "scatter_plot_3d_selected_marker['line'] = scatter_plot_3d_selected_line\n",
    "\n",
    "scatter_plot_3d_nonselected_marker = dict()\n",
    "scatter_plot_3d_nonselected_marker['size'] = 5\n",
    "scatter_plot_3d_nonselected_marker['color'] = color_d['mint']\n",
    "scatter_plot_3d_nonselected_marker['opacity'] = 0.15\n",
    "scatter_plot_3d_nonselected_marker['line'] = scatter_plot_3d_nonselected_line\n",
    "\n",
    "scatter_plot_3d_marker_no_color = dict()\n",
    "scatter_plot_3d_marker_no_color['size'] = 5\n",
    "scatter_plot_3d_marker_no_color['line'] = scatter_plot_3d_darker_line\n",
    "\n",
    "scatter_plot_3d_marker_cluster_center = dict()\n",
    "scatter_plot_3d_marker_cluster_center['size'] = 10\n",
    "scatter_plot_3d_marker_cluster_center['color'] = color_d['orange']\n",
    "scatter_plot_3d_marker_cluster_center['opacity'] = 0.5\n",
    "scatter_plot_3d_marker_cluster_center['line'] = scatter_plot_3d_darker_line\n",
    "\n",
    "scatter_plot_3d_selected_table_marker = dict()\n",
    "scatter_plot_3d_selected_table_marker['size'] = 5\n",
    "scatter_plot_3d_selected_table_marker['color'] = color_d['yellow']\n",
    "scatter_plot_3d_selected_table_marker['line'] = scatter_plot_3d_darker_line\n",
    "\n",
    "\n",
    "# Style\n",
    "scatter_plot_3d_style = dict()\n",
    "scatter_plot_3d_style['height'] = '100%'\n",
    "scatter_plot_3d_style['width'] = '100%'\n",
    "\n",
    "\n",
    "# ========= #\n",
    "#  Treemap  #\n",
    "# ========= #\n",
    "\n",
    "# Style\n",
    "treemap_style = dict()\n",
    "treemap_style['height'] = '100%'\n",
    "treemap_style['width'] = '100%'\n",
    "\n",
    "\n",
    "# ============ #\n",
    "#  Data Table  #\n",
    "# ============ #\n",
    "\n",
    "# Style\n",
    "data_table_cell_style = dict()\n",
    "data_table_cell_style['textAlign'] = 'left'\n",
    "data_table_cell_style['overflow'] = 'hidden'\n",
    "data_table_cell_style['textOverflow'] = 'ellipsis'\n",
    "data_table_cell_style['maxWidth'] = 0\n",
    "data_table_cell_style['backgroundColor'] = 'rgb(20, 20, 20)'\n",
    "data_table_cell_style['color'] = 'white'\n",
    "\n",
    "data_table_header_style = dict()\n",
    "data_table_header_style['backgroundColor'] = color_d['purple']\n",
    "\n",
    "\n",
    "# ======== #\n",
    "#  Labels  #\n",
    "# ======== #\n",
    "\n",
    "# Style\n",
    "clustering_alg_drop_down_label_style = dict()\n",
    "clustering_alg_drop_down_label_style['color'] = 'white'\n",
    "\n",
    "coordinate_space_drop_down_label_style = dict()\n",
    "coordinate_space_drop_down_label_style['color'] = 'white'\n",
    "\n",
    "dim_reduction_drop_down_label_style = dict()\n",
    "dim_reduction_drop_down_label_style['color'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dash Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= #\n",
    "#  3d Scatter Plot  #\n",
    "# ================= #\n",
    "scatter_plot_3d_config = dict()\n",
    "scatter_plot_3d_config['responsive'] = True\n",
    "\n",
    "\n",
    "# ========= #\n",
    "#  Treemap  #\n",
    "# ========= #\n",
    "treemap_config = dict()\n",
    "treemap_config['responsive'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dash Dropdown Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_alg_drop_down_options = [\n",
    "    {'label': 'KNN', 'value': 'KNN'},\n",
    "    {'label': 'GMM', 'value': 'GMM'},\n",
    "    {'label': 'Bayesian GMM', 'value': 'BGMM'},\n",
    "    {'label': 'Affinity Prop.', 'value': 'AP'},\n",
    "    {'label': 'KMEANS', 'value': 'KM'},\n",
    "    {'label': 'SVM', 'value': 'SVM'},\n",
    "]\n",
    "\n",
    "coordinate_space_drop_down_options = [\n",
    "    {'label': 'Cartesian', 'value': 'CT'},\n",
    "    {'label': 'Spherical', 'value': 'SP'}\n",
    "]\n",
    "\n",
    "dim_reduction_drop_down_options = [\n",
    "    {'label': 'PCA', 'value': 'PCA'},\n",
    "    {'label': 'ICA', 'value': 'ICA'},\n",
    "    {'label': 'LDA', 'value': 'LDA'},\n",
    "    {'label': 'Sparse RP', 'value': 'SRP'},\n",
    "    {'label': 'Gaussian RP', 'value': 'GRP'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dash Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Je-dqJAGlzA9"
   },
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)\n",
    "cache = Cache()\n",
    "cache.init_app(app.server, config=CACHE_CONFIG)\n",
    "\n",
    "\n",
    "# =============== #\n",
    "#  Cluster Table  #\n",
    "# =============== #\n",
    "table = pd.DataFrame(\n",
    "    data=list(embed_weights.keys()),\n",
    "    columns=['token'])\n",
    "\n",
    "# ============= #\n",
    "#  Scatterplot  #\n",
    "# ============= #\n",
    "scatter_plot_3d_fig = px.scatter_3d(\n",
    "                      scatter_plot_3d_df,\n",
    "                      x='x1',\n",
    "                      y='x2',\n",
    "                      z='x3',\n",
    "                      hover_name='token')\n",
    "\n",
    "scatter_plot_2d_fig = px.scatter(\n",
    "                     scatter_plot_3d_df,\n",
    "                     x='x1',\n",
    "                     y='x2',\n",
    "                     hover_name='token')\n",
    "\n",
    "scatter_plot_3d_fig.update_traces(marker=scatter_plot_3d_marker)\n",
    "scatter_plot_3d_fig['layout']['uirevision'] = 1\n",
    "\n",
    "scatter_plot_2d_fig.update_traces(marker=scatter_plot_3d_marker)\n",
    "scatter_plot_2d_fig['layout']['uirevision'] = 1\n",
    "\n",
    "\n",
    "# ========= #\n",
    "#  Treemap  #\n",
    "# ========= #\n",
    "treemap_fig = px.treemap(\n",
    "    parsed_tree_df,\n",
    "    path=col_name_list,\n",
    "    color='sum')\n",
    "\n",
    "\n",
    "# ============ #\n",
    "#  App Layout  #\n",
    "# ============ #\n",
    "app.layout = html.Div([\n",
    "\n",
    "        html.Div([\n",
    "\n",
    "            # -- Clustering Technique Dropdown -- #\n",
    "            html.Label(\n",
    "                \"Clustering Algorithm (TODO)\",\n",
    "                style=clustering_alg_drop_down_label_style),\n",
    "            dcc.Dropdown(\n",
    "                id='cluster-dropdown',\n",
    "                options=clustering_alg_drop_down_options,\n",
    "                value='KNN'),\n",
    "\n",
    "            # -- Coordinate Space Dropdown -- #\n",
    "            html.Label(\n",
    "                \"Coordinate Space\",\n",
    "                style=coordinate_space_drop_down_label_style),\n",
    "            dcc.Dropdown(\n",
    "                id='coord-dropdown',\n",
    "                options=coordinate_space_drop_down_options,\n",
    "                value='CT'),\n",
    "\n",
    "            # -- Dimensionality Reduction Technique Dropdown -- #\n",
    "            html.Label(\n",
    "                \"Dimensionality Reduction (TODO)\",\n",
    "                style=dim_reduction_drop_down_label_style),\n",
    "            dcc.Dropdown(\n",
    "                id='dr-dropdown',\n",
    "                options=dim_reduction_drop_down_options,\n",
    "                value='PCA'\n",
    "            )\n",
    "        ], className='options-graph-container'),\n",
    "\n",
    "        # -- 3d Scatter Plot -- #\n",
    "        html.Div(\n",
    "            [dcc.Graph(\n",
    "                id='3d_scat',\n",
    "                figure=scatter_plot_3d_fig,\n",
    "                config=scatter_plot_3d_config,\n",
    "                style=scatter_plot_3d_style),\n",
    "             dcc.Slider(\n",
    "                id='my-slider',\n",
    "                min=0.5,\n",
    "                max=0.9,\n",
    "                step=0.05,\n",
    "                value=0.5)],\n",
    "            className='main-graph-container',\n",
    "            id='graph_div'),\n",
    "\n",
    "        # -- Tree Map -- #\n",
    "        html.Div(\n",
    "            dcc.Graph(\n",
    "                id='3d_tree',\n",
    "                figure=treemap_fig,\n",
    "                config=treemap_config,\n",
    "                style=treemap_style),\n",
    "            className='secondary-graph-container',\n",
    "            id='tree_div'),\n",
    "\n",
    "        # -- Neighbors Datatable -- #\n",
    "        html.Div(\n",
    "            children=[dash_table.DataTable(\n",
    "                 id='table',\n",
    "                 columns=[{\"name\": i, \"id\": i} for i in table.columns],\n",
    "                 data=pd.DataFrame().to_dict('records'),\n",
    "                 style_cell=data_table_cell_style,\n",
    "                 style_header=data_table_header_style,\n",
    "             )],\n",
    "            className='related-graph',\n",
    "            id='data_table'),\n",
    "\n",
    "        # signal value to trigger callbacks\n",
    "        dcc.Store(id='signal')],\n",
    "\n",
    "    id='report-container')\n",
    "\n",
    "\n",
    "# ============= #\n",
    "#  Memoization  #\n",
    "# ============= #\n",
    "\n",
    "# Table of Contents:\n",
    "# -----------------------------\n",
    "# 1. Projection DataFrame\n",
    "# 2. Coordinates\n",
    "# 3. Dimensionality Reductions\n",
    "# 4. Clustering Algorithms\n",
    "# -----------------------------\n",
    "\n",
    "# -- 1. Projection DataFrame -- #\n",
    "@cache.memoize()\n",
    "def dataframe_store(embeddings):\n",
    "    new_df = pd.DataFrame(\n",
    "        data=embeddings,\n",
    "        columns=scatter_plot_3d_cols)\n",
    "    new_df['x1'] = pd.to_numeric(new_df['x1'])\n",
    "    new_df['x2'] = pd.to_numeric(new_df['x2'])\n",
    "    new_df['x3'] = pd.to_numeric(new_df['x3'])\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# -- 2. Coordinates -- #\n",
    "@cache.memoize()\n",
    "def coordinate_space_store(value, embeddings):\n",
    "    # calculate new coordinate space\n",
    "    if value == 'SP':\n",
    "        spherical_embeddings = get_spherical_coords(embeddings)\n",
    "        embeddings_stack_tup = (embedding_vocab_arr, spherical_embeddings)\n",
    "        named_embeddings = np.hstack(embeddings_stack_tup)\n",
    "    elif value == \"CT\":\n",
    "        embeddings_stack_tup = (embedding_vocab_arr, embeddings)\n",
    "        named_embeddings = np.hstack(embeddings_stack_tup)\n",
    "    else:\n",
    "        return no_update\n",
    "    return named_embeddings\n",
    "\n",
    "\n",
    "# -- 3. Dimensionality Reduction -- #\n",
    "@cache.memoize()\n",
    "def dimension_reduct_store(value):\n",
    "    # calculate new dimensionality reduction algorithm\n",
    "    if value == \"PCA\":\n",
    "        dr_embeddings = pca.transform(weights)\n",
    "    elif value == \"ICA\":\n",
    "        dr_embeddings = ica.transform(weights)\n",
    "    elif value == \"SRP\":\n",
    "        dr_embeddings = srp.transform(weights)\n",
    "    else:\n",
    "        return no_update\n",
    "    return dr_embeddings\n",
    "\n",
    "\n",
    "# -- 4. Clustering Algorithms -- #\n",
    "@cache.memoize()\n",
    "def clustering_algo_store(value, damp_value):\n",
    "    # calculate new clustering algorithm\n",
    "    if value == \"KNN\":\n",
    "        model = NearestNeighbors(n_neighbors=W2V_NEIGHBORS, algorithm='auto')\n",
    "    elif value == \"AP\":\n",
    "        model = AffinityPropagation(damping=damp_value, random_state=DASH_SEED)\n",
    "    elif value == \"KM\":\n",
    "        model = KMeans(n_clusters=4)\n",
    "    elif value == \"GMM\":\n",
    "        model = GaussianMixture(n_components=4)\n",
    "    elif value == \"SVM\":\n",
    "        model = SVC(kernel='poly', degree=3, probability=True, random_state=DASH_SEED)\n",
    "    return model\n",
    "\n",
    "\n",
    "# =========== #\n",
    "#  Callbacks  #\n",
    "# =========== #\n",
    "\n",
    "# -- Calculate Projection Data -- #\n",
    "@app.callback(Output('signal', 'data'),\n",
    "              Input('dr-dropdown', 'value'),\n",
    "              Input('cluster-dropdown', 'value'),\n",
    "              Input('coord-dropdown', 'value'),\n",
    "              Input('my-slider', 'value'))\n",
    "def compute_coordinate_space(dr_val, cluster_val, coord_val, damp_value):\n",
    "    return (dr_val, cluster_val, coord_val, damp_value)\n",
    "\n",
    "\n",
    "# -- Point Selection Mechanics -- #\n",
    "@app.callback(Output(\"table\", \"data\"),\n",
    "              Output(\"3d_scat\", \"figure\"),\n",
    "              Input('3d_scat', 'clickData'),\n",
    "              Input(\"signal\", \"data\"),\n",
    "              Input(\"table\", \"selected_rows\"))\n",
    "def select_point(clickData, value, rows):\n",
    "    ctx = dash.callback_context\n",
    "    ids = [c['prop_id'] for c in ctx.triggered]\n",
    "\n",
    "    embeddings = dimension_reduct_store(value[0])\n",
    "    model = clustering_algo_store(value[1], value[3])\n",
    "    named_embeddings = coordinate_space_store(value[2], embeddings)\n",
    "    df = dataframe_store(named_embeddings)\n",
    "\n",
    "    clustering_model = model.fit(named_embeddings[:, 1:4].astype(float))\n",
    "\n",
    "    if '3d_scat.clickData' in ids:\n",
    "        if clickData:\n",
    "            for p in clickData['points']:\n",
    "                if value[1] != \"KNN\":\n",
    "                    return no_update, no_update\n",
    "\n",
    "                coord_list = [p['x'], p['y'], p['z']]\n",
    "                query_arr = np.array(coord_list).reshape(1, -1)\n",
    "\n",
    "                _, neighbors = clustering_model.kneighbors(X=query_arr)\n",
    "                neighbors_list = neighbors.tolist()[0]\n",
    "                tokens = []\n",
    "                for idx in neighbors_list:\n",
    "                    tokens.append(table.iloc[idx])\n",
    "                update = pd.DataFrame(data=tokens)\n",
    "\n",
    "                selected_df = df[df.index.isin(neighbors_list)]\n",
    "                nonselected_df = df.drop(index=neighbors_list)\n",
    "\n",
    "                ff = px.scatter_3d(\n",
    "                    selected_df,\n",
    "                    x='x1',\n",
    "                    y='x2',\n",
    "                    z='x3',\n",
    "                    hover_name='token')\n",
    "\n",
    "                ff = ff.update_traces(marker=scatter_plot_3d_selected_marker)\n",
    "\n",
    "                if rows is not None:\n",
    "                    table_point = selected_df[selected_df['token'] == rows]\n",
    "                    ff2_1 = px.scatter_3d(\n",
    "                            table_point,\n",
    "                            x='x1',\n",
    "                            y='x2',\n",
    "                            z='x3',\n",
    "                            text='token')\n",
    "\n",
    "                    ff2_1 = ff2_1.update_traces(marker=scatter_plot_3d_selected_table_marker)\n",
    "                    ff.add_trace(ff2_1.data[0])\n",
    "\n",
    "                ff2 = px.scatter_3d(\n",
    "                    nonselected_df,\n",
    "                    x='x1',\n",
    "                    y='x2',\n",
    "                    z='x3',\n",
    "                    hover_name='token')\n",
    "\n",
    "                ff2 = ff2.update_traces(marker=scatter_plot_3d_nonselected_marker)\n",
    "\n",
    "                ff.add_trace(ff2.data[0])\n",
    "                ff['layout']['uirevision'] = 1\n",
    "\n",
    "                return update.to_dict('records'), ff\n",
    "    elif 'signal.data' in ids:\n",
    "        if value[1] != \"KNN\":\n",
    "            y_pred = clustering_model.predict(embeddings)\n",
    "\n",
    "            df.insert(0, \"Label\", y_pred, True)\n",
    "            ff = px.scatter_3d(\n",
    "                df,\n",
    "                x='x1',\n",
    "                y='x2',\n",
    "                z='x3',\n",
    "                color='Label',\n",
    "                hover_name='token')\n",
    "\n",
    "            ff.update_traces(marker=scatter_plot_3d_marker_no_color)\n",
    "\n",
    "            if \"GMM\" not in value[1]:\n",
    "                centers = pd.DataFrame(data=clustering_model.cluster_centers_, columns=[\"x1\", \"x2\", \"x3\"])\n",
    "                ff2 = px.scatter_3d(\n",
    "                    centers,\n",
    "                    x='x1',\n",
    "                    y='x2',\n",
    "                    z='x3')\n",
    "                ff2.update_traces(marker=scatter_plot_3d_marker_cluster_center)\n",
    "\n",
    "                ff.add_trace(ff2.data[0])\n",
    "        else:\n",
    "            ff = px.scatter_3d(\n",
    "                df,\n",
    "                x='x1',\n",
    "                y='x2',\n",
    "                z='x3',\n",
    "                hover_name='token')\n",
    "\n",
    "            ff.update_traces(marker=scatter_plot_3d_marker)\n",
    "\n",
    "        ff['layout']['uirevision'] = 1\n",
    "\n",
    "        return no_update, ff\n",
    "    else:\n",
    "        return no_update, no_update\n",
    "\n",
    "\n",
    "app.run_server(host='0.0.0.0', mode='jupyterlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZNPHgwy3XXZ"
   },
   "source": [
    "# Transformer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TransformerGlobalConfig:\n",
    "    d_model: int = 512\n",
    "    max_seq_length: int = 200\n",
    "    global_training: bool = True\n",
    "    storage_path: str = '/results/'\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BERTLayerConfig:\n",
    "    num_attention_heads: int = 8\n",
    "    num_encoder_layers: int = 12\n",
    "    dff: int = 2048\n",
    "    max_seq_len: int = 2048\n",
    "    dropout_rate: float = 0.1\n",
    "    load_model: bool = False\n",
    "    save_model: bool = True\n",
    "    training: bool = True\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HitAnomalyLayerConfig:\n",
    "    num_attention_heads: int = 12\n",
    "    num_encoder_layers: int = 3\n",
    "    dff: int = 2048\n",
    "    max_seq_len: int = 2048\n",
    "    dropout_rate: float = 0.1\n",
    "    load_model: bool = False\n",
    "    save_model: bool = True\n",
    "    training: bool = True\n",
    "\n",
    "    def load(self, config):\n",
    "        set_attributes(self, config)\n",
    "\n",
    "\n",
    "class TransformerConfig:\n",
    "    def __init__(self):\n",
    "        self._global = TransformerGlobalConfig()\n",
    "        self.BERT = BERTLayerConfig()\n",
    "        self.HitAnomaly = HitAnomalyLayerConfig()\n",
    "\n",
    "    def load(self, path):\n",
    "        try:\n",
    "            with open(path) as f:\n",
    "                transformer_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        except FileNotFoundError as e:\n",
    "            logger.warning(e)\n",
    "            return None\n",
    "\n",
    "        self._global.load(transformer_config)\n",
    "        self.BERT.load(transformer_config)\n",
    "        self.HitAnomaly.load(transformer_config)\n",
    "        \n",
    "def set_attributes_from_object(self, *args):\n",
    "    try:\n",
    "        for obj in args:\n",
    "            for attr_key, attr in obj.__dict__.items():\n",
    "                setattr(self, attr_key, attr)\n",
    "    except Exception as e:\n",
    "        logger.warning(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K5ODbmo_hWj"
   },
   "source": [
    "## Metric Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5QbcqbJ_vZH"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WytrcTtl-4q2"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73Jm1yHR_wou"
   },
   "source": [
    "### Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mZodkFf-_09c"
   },
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=1))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MubVySBE_wVH"
   },
   "source": [
    "### Custom Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_FjRZs2A_286"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model: int, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JtgL-iQkqj2"
   },
   "source": [
    "## Pipeline Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zzi2tYRAYC1"
   },
   "source": [
    "### PositionalEncodingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QfyQUMo4Aarf"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if max_dims % 2 == 1: max_dims += 1  # max_dims must be even\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10000 ** (2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000 ** (2 * i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARsH5IxX_Th0"
   },
   "source": [
    "### EncoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QSmeFr022zA0"
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(Layer):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        num_heads: int,\n",
    "        dff: int,\n",
    "        rate=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.multi_headed_attention = MultiHeadAttention(num_heads=num_heads,\n",
    "                                                         key_dim=d_model // num_heads,\n",
    "                                                         dropout=0.1,\n",
    "                                                         attention_axes=(1))\n",
    "\n",
    "        self.feed_forward_network = Sequential([\n",
    "            Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "            Dense(d_model, activation='relu')  # (batch_size, seq_len, d_model)\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        # (1) - Attention Score\n",
    "#         logger.info('MULTIHEADED ATTENTION')\n",
    "#         logger.info(x.shape)\n",
    "        attn_output, attn_weights = self.multi_headed_attention(\n",
    "            x,\n",
    "            x,\n",
    "            return_attention_scores=True)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # (2) - Add & Normalize\n",
    "        attn_output = self.dropout1(attn_output, training=True)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # (3) - Feed Forward NN\n",
    "        feed_forward_output = self.feed_forward_network(out1)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # (4) - Add & Normalize\n",
    "        feed_forward_output = self.dropout2(feed_forward_output, training=True)\n",
    "        out2 = self.layernorm2(out1 + feed_forward_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return tf.convert_to_tensor(out2), tf.convert_to_tensor(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        global_config: TransformerGlobalConfig,\n",
    "        config: BERTLayerConfig):\n",
    "        super(BERTLayer, self).__init__()\n",
    "\n",
    "        set_attributes_from_object(\n",
    "            self, \n",
    "            global_config,\n",
    "            config)\n",
    "\n",
    "        self.bert_layer_blocks = [EncoderBlock(\n",
    "            self.d_model,\n",
    "            self.num_attention_heads,\n",
    "            self.dff,\n",
    "            rate=self.dropout_rate) for _ in range(self.num_encoder_layers)]\n",
    "\n",
    "    def call(self, input_: tf.tuple, **kwargs):\n",
    "        enc_input = input_[0]\n",
    "#         logger.info('BERT LAYER')\n",
    "#         logger.info(enc_input.shape)\n",
    "        encoding_padding_mask = None\n",
    "        # BERT for Log Sequence Embedding\n",
    "         for layer_idx in range(self.num_encoder_layers):\n",
    "#             logger.info('BERT LAYER LOOP')\n",
    "#             logger.info(enc_input.shape)            \n",
    "            enc_output, attention = self.bert_layer_blocks[layer_idx](enc_input, encoding_padding_mask)\n",
    "        return enc_output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HitAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitAnomalyLayer(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        global_config: TransformerGlobalConfig,\n",
    "        config: HitAnomalyLayerConfig):\n",
    "        super(HitAnomalyLayer, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        set_attributes_from_object(\n",
    "            self, \n",
    "            global_config,\n",
    "            config)\n",
    "        \n",
    "        self.encoding_blocks = [EncoderBlock(\n",
    "            self.d_model,\n",
    "            self.num_attention_heads,\n",
    "            self.dff,\n",
    "            rate=self.dropout_rate\n",
    "        ) for _ in range(self.num_encoder_layers)]\n",
    "\n",
    "        self.hidden_layer_output = []\n",
    "\n",
    "#     @tf.function(jit_compile=True)\n",
    "    def call(self, input_: tf.tuple, **kwargs):\n",
    "        enc_input = input_[0]\n",
    "        encoding_padding_mask = None\n",
    "\n",
    "        # Encoder Block Hidden Layers for Log Encoder\n",
    "        # (batch_size, inp_seq_len, d_model), (batch_size, class, inp_seq_len, inp_seq_len)\n",
    "        for layer_idx in range(self.num_encoder_layers - 1):\n",
    "            enc_output, att = self.encoding_blocks[layer_idx](enc_input, encoding_padding_mask)\n",
    "            self.hidden_layer_output.append(enc_output)\n",
    "\n",
    "        fin_output = enc_output\n",
    "        final_output = tf.reduce_mean(fin_output, axis=1)\n",
    "        final_output = tf.expand_dims(final_output, axis=0)\n",
    "\n",
    "        # Last Encoding Block for Log Sequence Representation\n",
    "        out, att = self.encoding_blocks[self.num_encoder_layers - 1](final_output, encoding_padding_mask)\n",
    "        self.hidden_layer_output.append(out)\n",
    "\n",
    "        # Final Pooling Layer\n",
    "        seq_representation = tf.reduce_mean(out, axis=1)\n",
    "\n",
    "        return seq_representation, att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-Dg1Sc6_QU2"
   },
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "NRk21bVC2oWu"
   },
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: PrimeTokenizer,\n",
    "        config: TransformerConfig):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.vocab_size = tokenizer.get_vocab_size()   \n",
    "        set_attributes_from_object(\n",
    "            self, \n",
    "            config._global)\n",
    "\n",
    "        self.embedding = Embedding(\n",
    "            self.vocab_size,\n",
    "            self.d_model,\n",
    "            input_length=self.max_seq_len)\n",
    "\n",
    "        self.pos_encoding = PositionalEncoding(\n",
    "            self.max_seq_len, \n",
    "            self.d_model)\n",
    "\n",
    "        self.bert_layer = BERTLayer(\n",
    "            config._global,\n",
    "            config.BERT)\n",
    "\n",
    "        self.hitanomaly_layer = HitAnomalyLayer(\n",
    "            self.vocab_size,\n",
    "            config._global,\n",
    "            config.HitAnomaly)\n",
    "\n",
    "        #self.dropout = Dropout(rate)\n",
    "\n",
    "#     @tf.function(jit_compile=True)\n",
    "    def call(self, input_tuple: tf.tuple, **kwargs):\n",
    "        log_batch = input_tuple[0]\n",
    "#         logger.info('INITIAL')\n",
    "#         logger.info(log_batch.shape)\n",
    "        encoding_padding_mask = None # input_tuple[1]\n",
    "        \n",
    "        embedding_tensor = self.embedding(log_batch) # (batch_size, input_seq_len, d_model)\n",
    "#         logger.info('POST EMBEDDING LAYER')\n",
    "#         logger.info(embedding_tensor.shape)\n",
    "        \n",
    "        embedding_tensor = self.pos_encoding(embedding_tensor)\n",
    "#         logger.info('POST POSITIONAL ENCODING')\n",
    "#         logger.info(embedding_tensor.shape)\n",
    "        #embedding_tensor = self.dropout(embedding_tensor, training=TRAINING)\n",
    "\n",
    "        # BERT for Log Sequence Embedding\n",
    "        bert_arg = tf.tuple(embedding_tensor, encoding_padding_mask)\n",
    "        enc_output, attention = self.bert_layer(bert_arg)\n",
    "\n",
    "        # Encoder Block Hidden Layers for Log Sequence Representation\n",
    "#         seq_representation, att = self.hitanomaly_layer(tf.tuple(enc_output, encoding_padding_mask))\n",
    "\n",
    "        return enc_output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OtCEbgsytePO"
   },
   "outputs": [],
   "source": [
    "def process_all_batches(n_iter, log_labels, batch_size):\n",
    "    batches = []\n",
    "\n",
    "    for idx in range(n_iter + 1):\n",
    "        log_batch, labels = process_batch(dataset, idx, log_labels, batch_size)\n",
    "\n",
    "        batches.append((log_batch, labels))\n",
    "\n",
    "    return batches\n",
    "\n",
    "def process_batch(dataset: pd.DataFrame,\n",
    "                  idx: int,\n",
    "                  labels: dict,\n",
    "                  batch_size: int) -> tuple:\n",
    "    start_window = idx * batch_size\n",
    "    end_window = (idx + 1) * batch_size\n",
    "    batched_data = dataset.iloc[start_window:end_window]\n",
    "    encoded_batch = prime_tokenizer.text_to_sequence(batched_data['log'].to_list())\n",
    "    id_batch = [log.ids for log in encoded_batch]\n",
    "#     y_batch = labels[batched_data['label']]\n",
    "    y_batch = [labels[idx] for idx in batched_data['label']]\n",
    "\n",
    "    tf_idf = tf.convert_to_tensor(id_batch, dtype=tf.float32)\n",
    "    y_idf  = tf.convert_to_tensor(y_batch, dtype=tf.float32)\n",
    "    \n",
    "    return tf_idf, y_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmiGMB4_-l8x"
   },
   "source": [
    "### Main (Initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "j7hXYiqW3o6M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "# -- Transformer Model -- #\n",
    "transformer_config_path = SOURCE + '/assets/notebooks/TransformerConfig.yaml'\n",
    "transformer_config = TransformerConfig()\n",
    "transformer_config.load(transformer_config_path)\n",
    "optimus_prime = Transformer(prime_tokenizer, transformer_config)\n",
    "\n",
    "t_config = transformer_config._global\n",
    "\n",
    "# -- Pipeline Info -- #\n",
    "n_logs = len(container_dataset.index)\n",
    "n_iter = n_logs // t_config.batch_size\n",
    "remainder = n_logs % t_config.batch_size\n",
    "attns = []\n",
    "\n",
    "# -- Labels -- #\n",
    "label_unique = dataset['label'].unique()\n",
    "lbp = LabelEncoder().fit(label_unique)\n",
    "binary_labels = lbp.transform(label_unique)\n",
    "\n",
    "log_labels = {}\n",
    "for idx, label in enumerate(label_unique):\n",
    "    log_labels.update({\n",
    "        label: binary_labels[idx]\n",
    "    })\n",
    "    \n",
    "# -- Data Batches -- #\n",
    "batched_dataset = process_all_batches(n_iter, log_labels, t_config.batch_size)\n",
    "\n",
    "# -- Model Metrics -- #\n",
    "learning_rate = CustomSchedule(t_config.d_model)\n",
    "epoch_loss = Mean(name='train_loss')\n",
    "epoch_accuracy = Mean(name='train_accuracy')\n",
    "loss_object = SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# -- Classification Step Layers -- #\n",
    "add_att_layer = AdditiveAttention()\n",
    "softmax = Softmax()\n",
    "s1 = Sequential([\n",
    "    Dense(t_config.batch_size, activation=t_config.activation),\n",
    "    Dense(4, activation=t_config.activation),\n",
    "    Softmax()\n",
    "])\n",
    "\n",
    "# -- Checkpoints -- #\n",
    "checkpoint_path = SOURCE + \"checkpoints/\"\n",
    "checkpoint = Checkpoint(step=tf.Variable(1), transformer=optimus_prime, optimizer=optimizer)\n",
    "checkpoint_manager = CheckpointManager(checkpoint, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "writer = tf.summary.create_file_writer(SOURCE + t_config.logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "hT-fshbn3WUy"
   },
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=([None, None]), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=([None]), dtype=tf.int8)\n",
    "]\n",
    "\n",
    "# @tf.function(input_signature=train_step_signature)#, experimental_compile=True)\n",
    "def train_step(log_batch: tf.Tensor, \n",
    "               labels: tf.Tensor):\n",
    "    \n",
    "    transformer_input = tf.tuple([\n",
    "        log_batch,  # <tf.Tensor: shape=(batch_size, max_seq_len), dtype=float32>\n",
    "        None  # <tf.Tensor: shape=(batch_size, num_classes), dtype=float32>\n",
    "    ])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        Rs, acc = optimus_prime(transformer_input)\n",
    "#         a_s = add_att_layer([Rs, Rs])\n",
    "#         y = softmax(a_s * Rs)\n",
    "#         print(a_s.shape)\n",
    "        # y = Rs\n",
    "#         loss = tf.py_function(loss_function, [labels, y], tf.float32)\n",
    "#         pred = s1(y)\n",
    "#         labels = tf.cast(labels, tf.int8)\n",
    "    # Optimize the model\n",
    "#     grads = tape.gradient(loss, optimus_prime.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(grads, optimus_prime.trainable_variables))\n",
    "\n",
    "#     acc = accuracy_function(labels, pred)\n",
    "\n",
    "    # Tracking Progress\n",
    "#     epoch_loss.update_state(loss)  # Adding Batch Loss\n",
    "#     epoch_accuracy.update_state(acc)\n",
    "\n",
    "    return Rs, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKEF1GYqtXSv"
   },
   "source": [
    "### Main (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1dc-ZONUfLHe",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000%:   0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:54,811 INFO | INITIAL\n",
      "2021-05-27 16:54:54,811 INFO | (50, 200)\n",
      "2021-05-27 16:54:55,018 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:55,018 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:55,020 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:55,020 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:55,021 INFO | BERT LAYER\n",
      "2021-05-27 16:54:55,022 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,022 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,024 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,476 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,477 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,477 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,478 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,506 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,507 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,534 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,535 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,564 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,565 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,594 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,595 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,620 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,621 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,654 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,655 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,683 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,683 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,710 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,711 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,736 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,737 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,764 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,765 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   0%|          | 1/574 [00:00<09:26,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:55,800 INFO | INITIAL\n",
      "2021-05-27 16:54:55,800 INFO | (50, 200)\n",
      "2021-05-27 16:54:55,808 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:55,809 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:55,810 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:55,811 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:55,812 INFO | BERT LAYER\n",
      "2021-05-27 16:54:55,813 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,813 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,813 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,814 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,821 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,822 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,828 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,829 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,836 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,837 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,845 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,846 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,852 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,853 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,859 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,860 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,867 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,868 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,875 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,876 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,883 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,884 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,890 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,892 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,899 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,900 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   0%|          | 2/574 [00:01<04:30,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:55,911 INFO | INITIAL\n",
      "2021-05-27 16:54:55,912 INFO | (50, 200)\n",
      "2021-05-27 16:54:55,917 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:55,917 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:55,919 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:55,919 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:55,920 INFO | BERT LAYER\n",
      "2021-05-27 16:54:55,920 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,921 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,922 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,930 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,931 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,937 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,938 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,944 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,945 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,951 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,952 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,959 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,961 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,969 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,970 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,976 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,977 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,983 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,983 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,990 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,991 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:55,997 INFO | (200, 512)\n",
      "2021-05-27 16:54:55,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:55,998 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,004 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,005 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   1%|          | 3/574 [00:01<02:54,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,016 INFO | INITIAL\n",
      "2021-05-27 16:54:56,016 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,034 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,035 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,037 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,038 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,039 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,039 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,041 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,042 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,049 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,051 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,061 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,063 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,069 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,070 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,077 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,077 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,077 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,084 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,084 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,090 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,090 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,098 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,099 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,106 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,107 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,107 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,108 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,115 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,115 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,121 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,122 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,128 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,129 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   1%|          | 4/574 [00:01<02:12,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,138 INFO | INITIAL\n",
      "2021-05-27 16:54:56,138 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,146 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,147 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,148 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,149 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,149 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,150 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,150 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,150 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,151 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,151 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,157 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,157 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,158 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,164 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,165 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,171 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,172 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,178 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,180 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,186 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,186 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,194 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,195 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,201 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,202 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,208 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,209 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,217 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,218 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,223 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,225 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,231 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,231 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,232 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   1%|          | 5/574 [00:01<01:46,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,243 INFO | INITIAL\n",
      "2021-05-27 16:54:56,243 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,249 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,250 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,252 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,252 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,253 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,254 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,254 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,256 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,263 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,264 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,270 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,271 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,272 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,279 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,280 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,286 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,286 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,287 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,287 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,294 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,295 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,300 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,301 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,302 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,309 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,309 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,311 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,319 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,320 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,327 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,328 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,328 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,335 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,336 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,341 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,342 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,342 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,342 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   1%|          | 6/574 [00:01<01:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,355 INFO | INITIAL\n",
      "2021-05-27 16:54:56,355 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,361 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,361 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,363 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,363 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,364 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,365 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,366 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,367 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,372 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,373 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,373 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,374 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,383 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,384 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,384 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,390 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,391 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,391 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,397 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,398 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,399 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,405 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,405 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,413 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,415 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,422 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,423 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,430 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,431 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,437 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,438 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,445 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,445 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,446 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,454 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,455 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   1%|          | 7/574 [00:01<01:22,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,468 INFO | INITIAL\n",
      "2021-05-27 16:54:56,468 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,473 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,474 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,476 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,476 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,477 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,478 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,479 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,480 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,487 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,488 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,494 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,495 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,500 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,501 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,508 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,508 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,517 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,518 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,526 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,527 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,534 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,535 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,542 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,542 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,550 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,551 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,557 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,558 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,564 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,565 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   1%|         | 8/574 [00:01<01:15,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,575 INFO | INITIAL\n",
      "2021-05-27 16:54:56,575 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,582 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,582 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,584 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,585 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,586 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,586 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,587 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,588 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,595 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,596 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,602 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,603 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,610 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,612 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,618 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,618 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,619 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,619 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,625 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,625 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,631 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,632 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,632 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,633 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,638 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,639 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,645 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,646 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,653 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,654 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,660 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,661 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,667 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,668 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   2%|         | 9/574 [00:01<01:10,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,681 INFO | INITIAL\n",
      "2021-05-27 16:54:56,681 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,686 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,686 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,688 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,688 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,689 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,690 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,690 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,691 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,692 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,697 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,698 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,704 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,706 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,715 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,716 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,723 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,724 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,730 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,731 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,736 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,737 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,744 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,745 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,752 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,752 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,758 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,758 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,759 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,766 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,767 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,767 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,767 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,774 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,775 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   2%|         | 10/574 [00:01<01:07,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,787 INFO | INITIAL\n",
      "2021-05-27 16:54:56,787 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,794 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,794 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,796 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,796 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,797 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,798 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,798 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,798 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,799 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,799 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,806 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,806 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,813 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,813 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,814 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,820 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,821 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,828 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,828 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,829 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,835 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,835 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,836 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,842 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,843 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,844 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,845 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,852 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,852 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,858 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,860 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,865 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,866 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,872 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,873 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,880 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,881 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   2%|         | 11/574 [00:02<01:04,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,891 INFO | INITIAL\n",
      "2021-05-27 16:54:56,892 INFO | (50, 200)\n",
      "2021-05-27 16:54:56,898 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:56,898 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,899 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:56,900 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:56,901 INFO | BERT LAYER\n",
      "2021-05-27 16:54:56,901 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,902 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,902 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,910 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,912 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,919 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,919 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,925 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,926 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,932 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,933 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,938 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,939 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,945 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,947 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,947 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,954 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,955 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,962 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,963 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,970 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,970 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,977 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,978 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:56,984 INFO | (200, 512)\n",
      "2021-05-27 16:54:56,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:56,984 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   2%|         | 12/574 [00:02<01:02,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:56,994 INFO | INITIAL\n",
      "2021-05-27 16:54:56,994 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,000 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,001 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,002 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,002 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,003 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,004 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,010 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,014 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,022 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,023 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,029 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,030 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,036 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,036 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,042 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,043 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,051 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,052 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,058 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,059 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,066 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,069 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,075 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,075 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,076 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,076 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,082 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,083 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,088 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,089 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,095 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,096 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   2%|         | 13/574 [00:02<01:02,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,108 INFO | INITIAL\n",
      "2021-05-27 16:54:57,109 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,115 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,116 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,118 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,119 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,120 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,120 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,121 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,121 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,122 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,130 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,130 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,132 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,138 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,141 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,147 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,148 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,154 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,154 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,160 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,161 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,167 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,168 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,176 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,177 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,186 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,187 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,194 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,195 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,201 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,202 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,203 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,209 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,210 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   2%|         | 14/574 [00:02<01:03,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,223 INFO | INITIAL\n",
      "2021-05-27 16:54:57,223 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,231 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,232 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,233 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,233 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,234 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,235 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,236 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,237 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,244 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,246 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,253 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,254 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,260 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,261 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,268 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,269 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,277 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,277 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,283 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,284 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,289 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,289 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,290 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,297 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,298 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,303 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,304 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,311 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,312 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,319 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,319 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   3%|         | 15/574 [00:02<01:02,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,332 INFO | INITIAL\n",
      "2021-05-27 16:54:57,332 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,337 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,338 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,339 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,340 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,341 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,349 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,350 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,351 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,356 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,357 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,357 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,358 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,364 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,365 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,365 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,370 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,371 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,371 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,379 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,380 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,386 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,387 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,394 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,396 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,403 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,403 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,410 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,410 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,416 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,417 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,422 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,422 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,430 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,431 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   3%|         | 16/574 [00:02<01:01,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,440 INFO | INITIAL\n",
      "2021-05-27 16:54:57,441 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,448 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,449 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,451 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,451 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,452 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,453 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,453 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,455 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,460 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,461 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,467 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,468 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,474 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,475 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,483 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,484 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,489 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,490 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,497 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,497 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,503 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,504 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,509 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,510 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,518 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,519 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,526 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,527 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,534 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,535 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   3%|         | 17/574 [00:02<01:01,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,547 INFO | INITIAL\n",
      "2021-05-27 16:54:57,548 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,553 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,553 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,554 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,555 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,555 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,556 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,556 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,557 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,564 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,565 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,570 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,571 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,579 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,580 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,580 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,586 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,587 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,592 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,593 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,593 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,599 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,599 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,600 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,600 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,606 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,607 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,607 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,615 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,616 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,616 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,617 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,624 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,625 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,632 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,634 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,639 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,640 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   3%|         | 18/574 [00:02<01:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,655 INFO | INITIAL\n",
      "2021-05-27 16:54:57,656 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,662 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,663 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,664 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,665 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,666 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,667 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,668 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,669 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,677 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,678 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,687 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,688 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,696 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,696 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,703 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,703 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,711 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,712 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,722 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,723 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,730 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,731 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,737 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,738 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,744 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,746 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,752 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,753 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,760 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,761 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   3%|         | 19/574 [00:02<01:01,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,770 INFO | INITIAL\n",
      "2021-05-27 16:54:57,771 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,780 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,781 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,782 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,784 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,785 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,786 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,787 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,788 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,794 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,795 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,801 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,802 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,808 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,809 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,809 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,810 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,816 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,817 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,823 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,823 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,831 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,832 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,838 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,839 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,847 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,849 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,855 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,855 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,862 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,863 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,870 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,870 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   3%|         | 20/574 [00:03<01:01,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,882 INFO | INITIAL\n",
      "2021-05-27 16:54:57,883 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,888 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,888 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,889 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,890 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,890 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,891 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,892 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,893 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,899 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,900 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,900 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,906 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,907 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,916 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,917 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,923 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,923 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,930 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,931 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,936 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,936 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,937 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,937 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,943 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,945 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,951 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,952 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,952 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,953 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,959 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,959 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,960 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,965 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,965 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,966 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,971 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,971 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,972 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   4%|         | 21/574 [00:03<01:00,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:57,985 INFO | INITIAL\n",
      "2021-05-27 16:54:57,985 INFO | (50, 200)\n",
      "2021-05-27 16:54:57,991 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:57,992 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,993 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:57,993 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:57,994 INFO | BERT LAYER\n",
      "2021-05-27 16:54:57,995 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:57,995 INFO | (200, 512)\n",
      "2021-05-27 16:54:57,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:57,996 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,003 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,004 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,010 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,013 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,018 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,019 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,025 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,026 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,033 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,034 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,041 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,042 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,049 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,050 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,056 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,056 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,063 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,064 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,070 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,071 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,078 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,079 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,079 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,080 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   4%|         | 22/574 [00:03<00:59,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,090 INFO | INITIAL\n",
      "2021-05-27 16:54:58,091 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,098 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,099 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,100 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,100 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,101 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,101 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,102 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,103 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,109 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,111 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,118 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,119 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,125 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,125 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,131 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,132 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,139 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,140 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,147 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,148 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,154 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,155 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,161 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,162 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,168 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,169 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,174 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,175 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,182 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,182 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,182 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   4%|         | 23/574 [00:03<00:58,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,194 INFO | INITIAL\n",
      "2021-05-27 16:54:58,194 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,200 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,201 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,202 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,202 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,203 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,204 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,205 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,206 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,212 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,212 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,218 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,218 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,219 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,224 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,225 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,231 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,232 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,233 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,238 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,239 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,239 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,239 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,246 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,247 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,254 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,254 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,260 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,261 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,268 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,269 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,275 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,277 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,283 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,284 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   4%|         | 24/574 [00:03<00:57,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,295 INFO | INITIAL\n",
      "2021-05-27 16:54:58,296 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,301 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,301 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,302 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,303 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,304 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,304 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,305 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,306 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,313 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,314 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,321 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,322 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,327 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,327 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,328 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,328 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,334 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,334 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,341 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,342 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,343 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,348 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,349 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,354 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,355 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,361 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,361 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,368 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,369 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,378 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,379 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,386 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,387 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   4%|         | 25/574 [00:03<00:57,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,398 INFO | INITIAL\n",
      "2021-05-27 16:54:58,399 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,405 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,405 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,406 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,407 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,407 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,408 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,409 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,410 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,417 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,417 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,417 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,423 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,425 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,431 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,432 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,438 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,439 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,447 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,448 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,455 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,456 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,462 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,463 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,463 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,470 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,471 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,478 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,478 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,479 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,485 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,485 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,486 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,493 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,494 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   5%|         | 26/574 [00:03<00:57,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,503 INFO | INITIAL\n",
      "2021-05-27 16:54:58,504 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,509 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,509 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,511 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,511 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,512 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,513 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,513 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,514 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,521 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,522 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,528 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,530 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,537 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,538 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,546 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,547 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,553 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,553 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,559 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,559 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,560 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,560 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,566 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,567 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,574 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,574 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,581 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,583 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,590 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,590 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,597 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,598 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   5%|         | 27/574 [00:03<00:57,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,609 INFO | INITIAL\n",
      "2021-05-27 16:54:58,610 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,616 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,616 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,618 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,618 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,619 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,620 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,621 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,622 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,629 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,630 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,630 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,631 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,637 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,638 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,644 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,645 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,653 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,654 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,660 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,661 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,668 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,668 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,673 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,674 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,681 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,681 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,686 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,687 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,693 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,694 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,699 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,700 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   5%|         | 28/574 [00:03<00:57,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,713 INFO | INITIAL\n",
      "2021-05-27 16:54:58,714 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,721 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,722 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,723 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,723 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,724 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,725 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,726 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,727 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,733 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,733 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,734 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,734 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,743 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,744 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,750 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,751 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,756 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,757 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,763 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,764 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,771 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,772 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,777 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,779 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,785 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,786 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,786 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,791 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,792 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,793 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,798 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,798 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,799 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,799 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,804 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,805 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   5%|         | 29/574 [00:04<00:56,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,817 INFO | INITIAL\n",
      "2021-05-27 16:54:58,817 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,822 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,823 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,824 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,824 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,825 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,826 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,827 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,828 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,834 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,834 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,840 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,841 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,850 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,851 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,851 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,852 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,857 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,858 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,858 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,859 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,865 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,865 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,866 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,872 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,872 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,873 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,880 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,881 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,888 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,889 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,896 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,896 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,902 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,903 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,909 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,910 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   5%|         | 30/574 [00:04<00:56,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:58,921 INFO | INITIAL\n",
      "2021-05-27 16:54:58,922 INFO | (50, 200)\n",
      "2021-05-27 16:54:58,929 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:58,930 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,931 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:58,932 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:58,932 INFO | BERT LAYER\n",
      "2021-05-27 16:54:58,933 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,934 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,934 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,940 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,941 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,942 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,949 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,949 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,955 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,956 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,963 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,964 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,970 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,971 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,978 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,978 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,979 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,979 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,985 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,986 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,992 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,992 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:58,993 INFO | (200, 512)\n",
      "2021-05-27 16:54:58,999 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:58,999 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,000 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,000 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,007 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,008 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,016 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,016 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   5%|         | 31/574 [00:04<00:56,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,026 INFO | INITIAL\n",
      "2021-05-27 16:54:59,026 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,032 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,033 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,034 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,035 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,035 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,036 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,036 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,037 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,045 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,046 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,053 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,053 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,054 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,060 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,062 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,067 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,068 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,075 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,077 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,083 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,084 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,090 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,090 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,091 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,091 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,098 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,098 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,104 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,105 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,111 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,112 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,118 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,119 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 32/574 [00:04<00:56,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,131 INFO | INITIAL\n",
      "2021-05-27 16:54:59,131 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,136 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,137 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,138 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,138 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,139 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,139 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,140 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,141 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,149 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,150 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,156 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,157 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,158 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,158 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,164 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,165 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,170 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,171 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,177 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,179 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,186 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,187 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,193 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,194 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,201 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,202 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,207 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,210 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,216 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,216 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,222 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,222 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 33/574 [00:04<00:56,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,233 INFO | INITIAL\n",
      "2021-05-27 16:54:59,234 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,239 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,240 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,242 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,242 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,243 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,244 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,245 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,246 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,253 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,253 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,259 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,260 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,266 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,266 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,266 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,273 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,274 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,280 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,281 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,286 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,286 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,287 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,287 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,293 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,294 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,300 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,300 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,306 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,307 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,316 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,317 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,323 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,323 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 34/574 [00:04<00:55,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,334 INFO | INITIAL\n",
      "2021-05-27 16:54:59,334 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,340 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,340 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,343 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,344 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,345 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,345 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,346 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,346 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,348 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,355 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,356 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,362 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,363 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,369 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,370 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,370 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,371 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,376 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,377 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,377 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,377 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,385 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,386 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,393 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,394 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,400 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,401 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,406 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,407 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,407 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,414 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,415 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,420 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,420 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,421 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,421 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,428 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,429 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 35/574 [00:04<00:55,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,439 INFO | INITIAL\n",
      "2021-05-27 16:54:59,440 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,446 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,446 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,448 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,448 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,449 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,449 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,450 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,450 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,451 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,457 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,457 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,465 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,466 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,472 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,472 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,478 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,479 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,486 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,486 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,492 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,493 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,499 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,500 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,506 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,506 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,513 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,514 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,521 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,521 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,527 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,528 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 35/574 [00:04<00:55,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,539 INFO | INITIAL\n",
      "2021-05-27 16:54:59,539 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,547 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,547 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,548 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,549 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,549 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,550 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,551 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,551 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,557 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,557 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,563 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,564 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,570 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,571 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,578 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,579 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,586 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,586 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,592 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,592 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,593 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,599 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,600 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,605 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,606 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,613 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,613 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,620 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,621 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,626 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,627 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,628 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 37/574 [00:04<00:54,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,638 INFO | INITIAL\n",
      "2021-05-27 16:54:59,638 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,644 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,644 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,646 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,646 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,647 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,648 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,649 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,649 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,655 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,655 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,656 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,662 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,662 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,663 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,663 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,671 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,671 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,677 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,678 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,679 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,685 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,686 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,691 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,692 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,698 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,699 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,699 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,705 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,706 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,713 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,714 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,719 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,720 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,720 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,727 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,728 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   6%|         | 37/574 [00:04<00:54,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,737 INFO | INITIAL\n",
      "2021-05-27 16:54:59,738 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,744 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,744 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,746 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,747 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,747 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,748 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,749 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,750 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,755 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,756 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,762 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,763 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,763 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,769 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,769 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,770 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,776 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,777 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,786 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,786 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,786 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,793 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,794 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,800 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,801 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,807 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,808 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,816 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,817 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,822 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,823 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,829 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,830 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,830 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,830 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   7%|         | 39/574 [00:05<00:54,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,840 INFO | INITIAL\n",
      "2021-05-27 16:54:59,840 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,847 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,847 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,849 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,850 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,851 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,852 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,853 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,854 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,862 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,862 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,868 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,868 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,869 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,875 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,876 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,877 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,883 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,883 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,884 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,884 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,890 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,891 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,897 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,898 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,904 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,905 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,911 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,912 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,920 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,921 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,927 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,928 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,928 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,934 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,935 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   7%|         | 40/574 [00:05<00:54,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:54:59,947 INFO | INITIAL\n",
      "2021-05-27 16:54:59,947 INFO | (50, 200)\n",
      "2021-05-27 16:54:59,952 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:54:59,953 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,954 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:54:59,954 INFO | (50, 200, 512)\n",
      "2021-05-27 16:54:59,955 INFO | BERT LAYER\n",
      "2021-05-27 16:54:59,955 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,956 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,957 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,963 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,964 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,970 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,970 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,976 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,977 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,984 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,985 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,991 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,992 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,992 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:54:59,998 INFO | (200, 512)\n",
      "2021-05-27 16:54:59,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:54:59,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,026 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,027 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,035 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   7%|         | 40/574 [00:05<00:54,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,046 INFO | INITIAL\n",
      "2021-05-27 16:55:00,047 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,054 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,054 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,056 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,056 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,057 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,138 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   7%|         | 42/574 [00:05<00:54,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,153 INFO | INITIAL\n",
      "2021-05-27 16:55:00,154 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,160 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,160 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,162 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,162 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,163 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,255 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   7%|         | 43/574 [00:05<00:55,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,266 INFO | INITIAL\n",
      "2021-05-27 16:55:00,267 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,271 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,272 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,273 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,274 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,275 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,318 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,358 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,365 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,365 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   8%|         | 44/574 [00:05<00:56,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,375 INFO | INITIAL\n",
      "2021-05-27 16:55:00,376 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,383 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,384 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,385 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,386 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,387 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,463 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,473 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   8%|         | 45/574 [00:05<00:56,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,486 INFO | INITIAL\n",
      "2021-05-27 16:55:00,487 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,492 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,493 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,495 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,495 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,497 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,522 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,523 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,523 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,548 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,554 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,555 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,587 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   8%|         | 46/574 [00:05<00:57,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,601 INFO | INITIAL\n",
      "2021-05-27 16:55:00,602 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,607 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,608 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,610 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,611 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,612 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,634 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,635 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,692 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   8%|         | 47/574 [00:05<00:56,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,703 INFO | INITIAL\n",
      "2021-05-27 16:55:00,703 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,708 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,709 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,710 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,711 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,712 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,727 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,733 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,734 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,779 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,780 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,789 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,796 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,797 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,797 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   8%|         | 48/574 [00:05<00:56,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,808 INFO | INITIAL\n",
      "2021-05-27 16:55:00,809 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,815 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,815 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,817 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,817 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,818 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,864 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,870 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,871 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,877 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,892 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,899 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,915 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   9%|         | 49/574 [00:06<00:57,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:00,927 INFO | INITIAL\n",
      "2021-05-27 16:55:00,928 INFO | (50, 200)\n",
      "2021-05-27 16:55:00,933 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:00,934 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,935 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:00,935 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:00,936 INFO | BERT LAYER\n",
      "2021-05-27 16:55:00,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,936 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,937 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,946 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:00,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:00,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:00,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,020 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   9%|         | 50/574 [00:06<00:56,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,032 INFO | INITIAL\n",
      "2021-05-27 16:55:01,033 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,038 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,038 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,040 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,040 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,041 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,132 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   9%|         | 51/574 [00:06<00:57,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,142 INFO | INITIAL\n",
      "2021-05-27 16:55:01,143 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,148 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,148 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,150 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,150 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,151 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,184 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,189 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,190 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,217 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,218 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,233 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   9%|         | 51/574 [00:06<00:57,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,241 INFO | INITIAL\n",
      "2021-05-27 16:55:01,242 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,249 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,249 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,251 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,251 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,252 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,339 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,341 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   9%|         | 53/574 [00:06<00:55,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,352 INFO | INITIAL\n",
      "2021-05-27 16:55:01,353 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,358 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,359 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,360 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,361 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,363 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,370 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,417 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,449 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :   9%|         | 54/574 [00:06<00:55,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,462 INFO | INITIAL\n",
      "2021-05-27 16:55:01,462 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,467 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,468 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,469 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,470 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,471 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,554 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  10%|         | 55/574 [00:06<00:55,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,565 INFO | INITIAL\n",
      "2021-05-27 16:55:01,566 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,571 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,571 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,572 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,573 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,574 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,661 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  10%|         | 56/574 [00:06<00:55,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,671 INFO | INITIAL\n",
      "2021-05-27 16:55:01,671 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,678 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,678 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,680 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,680 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,681 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,738 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,745 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,758 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,760 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  10%|         | 56/574 [00:06<00:55,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,769 INFO | INITIAL\n",
      "2021-05-27 16:55:01,769 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,774 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,775 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,776 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,777 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,778 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,779 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,824 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,861 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,862 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  10%|         | 58/574 [00:07<00:53,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,872 INFO | INITIAL\n",
      "2021-05-27 16:55:01,872 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,880 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,880 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,882 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,882 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,883 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,884 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,905 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,964 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  10%|         | 59/574 [00:07<00:53,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:01,973 INFO | INITIAL\n",
      "2021-05-27 16:55:01,974 INFO | (50, 200)\n",
      "2021-05-27 16:55:01,982 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:01,982 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,984 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:01,984 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:01,985 INFO | BERT LAYER\n",
      "2021-05-27 16:55:01,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,986 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:01,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:01,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:01,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,065 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  10%|         | 60/574 [00:07<00:52,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,076 INFO | INITIAL\n",
      "2021-05-27 16:55:02,076 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,082 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,083 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,086 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,086 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,087 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,157 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,173 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  11%|         | 61/574 [00:07<00:53,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,185 INFO | INITIAL\n",
      "2021-05-27 16:55:02,185 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,191 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,191 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,193 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,193 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,194 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,272 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,273 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,279 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,280 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,281 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  11%|         | 62/574 [00:07<00:53,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,291 INFO | INITIAL\n",
      "2021-05-27 16:55:02,292 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,299 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,300 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,301 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,301 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,302 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,327 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,328 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,389 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  11%|         | 63/574 [00:07<00:54,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,399 INFO | INITIAL\n",
      "2021-05-27 16:55:02,399 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,404 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,405 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,406 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,406 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,407 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,417 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,490 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  11%|         | 64/574 [00:07<00:53,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,500 INFO | INITIAL\n",
      "2021-05-27 16:55:02,501 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,506 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,506 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,508 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,508 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,509 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,547 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,569 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,574 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,575 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,591 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  11%|        | 65/574 [00:07<00:52,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,603 INFO | INITIAL\n",
      "2021-05-27 16:55:02,603 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,609 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,609 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,610 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,611 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,612 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,626 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,642 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,643 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,677 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,695 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  11%|        | 66/574 [00:07<00:52,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,705 INFO | INITIAL\n",
      "2021-05-27 16:55:02,705 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,711 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,712 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,713 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,713 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,714 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,791 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,798 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  12%|        | 67/574 [00:07<00:52,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,811 INFO | INITIAL\n",
      "2021-05-27 16:55:02,811 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,816 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,817 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,818 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,819 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,819 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,892 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,901 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  12%|        | 68/574 [00:08<00:52,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:02,914 INFO | INITIAL\n",
      "2021-05-27 16:55:02,914 INFO | (50, 200)\n",
      "2021-05-27 16:55:02,920 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:02,921 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,922 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:02,922 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:02,923 INFO | BERT LAYER\n",
      "2021-05-27 16:55:02,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,939 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:02,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:02,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:02,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,008 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,011 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  12%|        | 69/574 [00:08<00:53,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,022 INFO | INITIAL\n",
      "2021-05-27 16:55:03,022 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,028 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,028 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,030 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,030 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,031 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,057 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,058 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,120 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  12%|        | 70/574 [00:08<00:53,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,132 INFO | INITIAL\n",
      "2021-05-27 16:55:03,133 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,138 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,139 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,140 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,142 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,218 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,234 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  12%|        | 71/574 [00:08<00:54,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,247 INFO | INITIAL\n",
      "2021-05-27 16:55:03,248 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,254 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,255 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,257 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,257 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,258 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,282 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,345 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  13%|        | 72/574 [00:08<00:54,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,356 INFO | INITIAL\n",
      "2021-05-27 16:55:03,357 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,365 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,366 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,367 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,368 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,369 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,370 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,420 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,421 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,458 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  13%|        | 73/574 [00:08<00:55,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,470 INFO | INITIAL\n",
      "2021-05-27 16:55:03,470 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,475 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,476 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,477 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,478 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,479 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,497 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,529 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,544 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,567 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  13%|        | 74/574 [00:08<00:55,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,580 INFO | INITIAL\n",
      "2021-05-27 16:55:03,580 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,587 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,587 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,589 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,590 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,591 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,592 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,599 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,600 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,622 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,643 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,673 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  13%|        | 75/574 [00:08<00:54,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,685 INFO | INITIAL\n",
      "2021-05-27 16:55:03,685 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,690 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,691 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,692 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,693 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,693 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,780 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  13%|        | 76/574 [00:08<00:53,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,790 INFO | INITIAL\n",
      "2021-05-27 16:55:03,791 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,798 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,799 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,800 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,801 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,802 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,812 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,819 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,886 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  13%|        | 77/574 [00:09<00:53,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:03,898 INFO | INITIAL\n",
      "2021-05-27 16:55:03,899 INFO | (50, 200)\n",
      "2021-05-27 16:55:03,903 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:03,904 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,905 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:03,905 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:03,906 INFO | BERT LAYER\n",
      "2021-05-27 16:55:03,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:03,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:03,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:03,990 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  14%|        | 78/574 [00:09<00:52,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,001 INFO | INITIAL\n",
      "2021-05-27 16:55:04,002 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,008 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,009 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,010 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,010 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,011 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,059 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,060 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,097 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  14%|        | 79/574 [00:09<00:52,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,106 INFO | INITIAL\n",
      "2021-05-27 16:55:04,107 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,115 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,116 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,117 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,118 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,118 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,121 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,128 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,129 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,136 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,150 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,173 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,187 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,204 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  14%|        | 80/574 [00:09<00:52,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,216 INFO | INITIAL\n",
      "2021-05-27 16:55:04,216 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,221 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,222 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,223 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,224 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,225 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,289 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,302 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,303 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  14%|        | 80/574 [00:09<00:52,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,314 INFO | INITIAL\n",
      "2021-05-27 16:55:04,314 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,320 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,320 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,322 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,323 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,324 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,397 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,398 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,406 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  14%|        | 82/574 [00:09<00:51,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,418 INFO | INITIAL\n",
      "2021-05-27 16:55:04,418 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,423 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,424 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,425 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,426 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,427 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,458 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,510 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  14%|        | 83/574 [00:09<00:51,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,521 INFO | INITIAL\n",
      "2021-05-27 16:55:04,522 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,527 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,528 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,529 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,530 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,530 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,547 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,548 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,554 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,614 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  15%|        | 84/574 [00:09<00:50,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,625 INFO | INITIAL\n",
      "2021-05-27 16:55:04,626 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,633 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,633 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,634 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,635 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,635 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,723 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  15%|        | 85/574 [00:09<00:51,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,735 INFO | INITIAL\n",
      "2021-05-27 16:55:04,736 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,741 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,742 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,743 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,744 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,744 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,745 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,806 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,807 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,815 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,829 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  15%|        | 86/574 [00:10<00:51,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,839 INFO | INITIAL\n",
      "2021-05-27 16:55:04,839 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,846 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,846 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,848 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,849 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,850 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,868 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,877 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,892 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,899 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,930 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,931 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,939 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  15%|        | 87/574 [00:10<00:52,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:04,950 INFO | INITIAL\n",
      "2021-05-27 16:55:04,951 INFO | (50, 200)\n",
      "2021-05-27 16:55:04,955 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:04,956 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,957 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:04,957 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:04,959 INFO | BERT LAYER\n",
      "2021-05-27 16:55:04,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,967 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,987 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:04,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:04,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:04,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,017 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,018 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,031 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,039 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,040 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,040 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  15%|        | 88/574 [00:10<00:51,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,051 INFO | INITIAL\n",
      "2021-05-27 16:55:05,052 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,058 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,059 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,060 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,061 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,061 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,062 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,063 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,068 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,069 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,075 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,141 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,142 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,143 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  16%|        | 89/574 [00:10<00:50,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,153 INFO | INITIAL\n",
      "2021-05-27 16:55:05,154 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,159 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,159 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,160 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,161 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,162 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,184 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,191 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,207 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,243 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  16%|        | 90/574 [00:10<00:50,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,256 INFO | INITIAL\n",
      "2021-05-27 16:55:05,256 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,263 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,269 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,272 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,275 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,277 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,292 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,293 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,315 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,360 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  16%|        | 91/574 [00:10<00:51,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,369 INFO | INITIAL\n",
      "2021-05-27 16:55:05,370 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,375 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,375 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,376 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,377 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,377 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,445 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,450 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,458 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,459 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  16%|        | 92/574 [00:10<00:50,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,473 INFO | INITIAL\n",
      "2021-05-27 16:55:05,473 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,482 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,482 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,483 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,484 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,485 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,485 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,530 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,544 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,545 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,559 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,560 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,567 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  16%|        | 93/574 [00:10<00:51,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,581 INFO | INITIAL\n",
      "2021-05-27 16:55:05,582 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,588 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,588 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,590 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,591 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,592 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,593 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,609 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,655 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,691 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  16%|        | 94/574 [00:10<00:53,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,702 INFO | INITIAL\n",
      "2021-05-27 16:55:05,703 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,708 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,709 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,710 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,711 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,712 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,745 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,763 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,804 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  17%|        | 95/574 [00:11<00:54,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,822 INFO | INITIAL\n",
      "2021-05-27 16:55:05,822 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,827 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,828 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,829 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,830 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,831 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,864 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,865 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,917 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,918 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,918 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  17%|        | 96/574 [00:11<00:53,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:05,931 INFO | INITIAL\n",
      "2021-05-27 16:55:05,932 INFO | (50, 200)\n",
      "2021-05-27 16:55:05,939 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:05,939 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,941 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:05,941 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:05,943 INFO | BERT LAYER\n",
      "2021-05-27 16:55:05,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,966 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:05,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:05,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:05,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,037 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,045 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,046 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  17%|        | 97/574 [00:11<00:55,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,060 INFO | INITIAL\n",
      "2021-05-27 16:55:06,060 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,067 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,068 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,069 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,070 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,071 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,156 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  17%|        | 98/574 [00:11<00:54,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,168 INFO | INITIAL\n",
      "2021-05-27 16:55:06,169 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,174 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,174 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,176 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,176 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,177 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,265 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  17%|        | 99/574 [00:11<00:53,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,277 INFO | INITIAL\n",
      "2021-05-27 16:55:06,278 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,284 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,285 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,286 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,287 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,288 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,289 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,306 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,376 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  17%|        | 100/574 [00:11<00:53,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,388 INFO | INITIAL\n",
      "2021-05-27 16:55:06,388 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,395 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,396 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,397 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,397 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,398 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,399 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,400 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,463 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,486 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  18%|        | 101/574 [00:11<00:52,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,498 INFO | INITIAL\n",
      "2021-05-27 16:55:06,498 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,502 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,503 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,504 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,505 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,505 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,516 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,523 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,529 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,530 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,559 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,569 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,595 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  18%|        | 102/574 [00:11<00:52,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,606 INFO | INITIAL\n",
      "2021-05-27 16:55:06,607 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,618 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,618 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,620 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,620 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,622 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,626 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,661 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,663 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,686 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,700 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,715 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  18%|        | 103/574 [00:11<00:53,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,727 INFO | INITIAL\n",
      "2021-05-27 16:55:06,727 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,735 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,736 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,738 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,738 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,739 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,740 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,741 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,758 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,766 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,767 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,825 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  18%|        | 104/574 [00:12<00:52,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,835 INFO | INITIAL\n",
      "2021-05-27 16:55:06,836 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,840 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,841 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,842 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,843 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,844 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,844 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,844 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,845 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,861 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,868 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,875 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,930 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  18%|        | 105/574 [00:12<00:51,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:06,942 INFO | INITIAL\n",
      "2021-05-27 16:55:06,943 INFO | (50, 200)\n",
      "2021-05-27 16:55:06,948 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:06,949 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,950 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:06,951 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:06,952 INFO | BERT LAYER\n",
      "2021-05-27 16:55:06,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,979 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:06,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:06,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:06,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,037 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,038 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  18%|        | 106/574 [00:12<00:51,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,050 INFO | INITIAL\n",
      "2021-05-27 16:55:07,051 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,056 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,057 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,058 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,059 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,060 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,150 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  19%|        | 107/574 [00:12<00:51,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,162 INFO | INITIAL\n",
      "2021-05-27 16:55:07,163 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,169 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,170 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,171 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,172 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,173 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,181 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,181 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,189 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,190 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,266 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  19%|        | 108/574 [00:12<00:51,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,276 INFO | INITIAL\n",
      "2021-05-27 16:55:07,277 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,284 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,285 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,286 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,287 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,288 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,302 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,369 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  19%|        | 109/574 [00:12<00:50,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,380 INFO | INITIAL\n",
      "2021-05-27 16:55:07,381 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,386 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,387 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,388 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,388 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,389 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,391 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,397 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,463 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,472 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  19%|        | 110/574 [00:12<00:49,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,484 INFO | INITIAL\n",
      "2021-05-27 16:55:07,484 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,491 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,491 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,493 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,493 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,495 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,554 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,555 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,586 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  19%|        | 111/574 [00:12<00:50,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,598 INFO | INITIAL\n",
      "2021-05-27 16:55:07,599 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,606 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,606 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,607 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,608 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,609 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,643 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,701 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  20%|        | 112/574 [00:12<00:51,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,713 INFO | INITIAL\n",
      "2021-05-27 16:55:07,714 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,720 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,720 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,722 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,722 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,723 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,766 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,767 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,791 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,798 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,799 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,813 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,814 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  20%|        | 113/574 [00:13<00:51,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,825 INFO | INITIAL\n",
      "2021-05-27 16:55:07,826 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,832 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,833 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,834 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,834 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,835 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,843 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,844 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,844 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,850 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,851 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,857 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,858 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,883 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,884 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,922 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  20%|        | 114/574 [00:13<00:51,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:07,935 INFO | INITIAL\n",
      "2021-05-27 16:55:07,936 INFO | (50, 200)\n",
      "2021-05-27 16:55:07,942 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:07,942 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,944 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:07,944 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:07,945 INFO | BERT LAYER\n",
      "2021-05-27 16:55:07,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,978 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,979 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,979 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:07,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:07,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:07,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,034 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  20%|        | 115/574 [00:13<00:51,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,047 INFO | INITIAL\n",
      "2021-05-27 16:55:08,047 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,052 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,053 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,054 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,054 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,055 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,113 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,144 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  20%|        | 116/574 [00:13<00:50,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,155 INFO | INITIAL\n",
      "2021-05-27 16:55:08,155 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,161 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,162 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,163 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,164 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,165 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,250 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  20%|        | 117/574 [00:13<00:49,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,260 INFO | INITIAL\n",
      "2021-05-27 16:55:08,261 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,268 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,269 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,271 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,271 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,272 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,318 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,324 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,356 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,356 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  21%|        | 118/574 [00:13<00:49,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,368 INFO | INITIAL\n",
      "2021-05-27 16:55:08,368 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,373 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,374 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,376 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,376 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,377 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,435 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,436 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,458 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,467 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  21%|        | 119/574 [00:13<00:49,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,479 INFO | INITIAL\n",
      "2021-05-27 16:55:08,479 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,485 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,486 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,487 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,488 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,489 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,490 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,492 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,574 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  21%|        | 120/574 [00:13<00:49,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,586 INFO | INITIAL\n",
      "2021-05-27 16:55:08,587 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,593 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,594 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,595 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,596 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,596 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,611 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,618 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,626 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,676 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  21%|        | 121/574 [00:13<00:48,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,687 INFO | INITIAL\n",
      "2021-05-27 16:55:08,687 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,692 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,692 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,694 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,694 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,695 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,720 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,727 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,758 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,769 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,783 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  21%|       | 122/574 [00:13<00:49,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,805 INFO | INITIAL\n",
      "2021-05-27 16:55:08,805 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,813 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,813 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,814 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,814 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,815 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,904 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  21%|       | 123/574 [00:14<00:49,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:08,916 INFO | INITIAL\n",
      "2021-05-27 16:55:08,917 INFO | (50, 200)\n",
      "2021-05-27 16:55:08,922 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:08,923 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,924 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:08,925 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:08,926 INFO | BERT LAYER\n",
      "2021-05-27 16:55:08,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,972 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,980 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,987 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:08,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:08,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:08,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,010 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  22%|       | 124/574 [00:14<00:48,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,021 INFO | INITIAL\n",
      "2021-05-27 16:55:09,022 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,027 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,027 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,028 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,029 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,030 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,031 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,079 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,106 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,107 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,115 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  22%|       | 125/574 [00:14<00:48,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,126 INFO | INITIAL\n",
      "2021-05-27 16:55:09,127 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,132 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,133 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,134 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,135 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,136 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,173 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,217 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  22%|       | 126/574 [00:14<00:47,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,228 INFO | INITIAL\n",
      "2021-05-27 16:55:09,228 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,233 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,234 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,235 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,236 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,237 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,238 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,257 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,266 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,320 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  22%|       | 127/574 [00:14<00:47,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,332 INFO | INITIAL\n",
      "2021-05-27 16:55:09,333 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,340 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,341 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,342 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,343 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,344 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,383 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,389 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,431 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  22%|       | 128/574 [00:14<00:47,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,442 INFO | INITIAL\n",
      "2021-05-27 16:55:09,442 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,448 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,448 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,450 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,451 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,452 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,469 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,540 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  22%|       | 129/574 [00:14<00:47,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,552 INFO | INITIAL\n",
      "2021-05-27 16:55:09,553 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,558 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,558 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,560 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,561 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,562 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,599 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,615 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,616 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,649 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  23%|       | 130/574 [00:14<00:47,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,660 INFO | INITIAL\n",
      "2021-05-27 16:55:09,660 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,666 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,666 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,668 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,669 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,670 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,727 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,757 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  23%|       | 131/574 [00:14<00:48,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,770 INFO | INITIAL\n",
      "2021-05-27 16:55:09,771 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,776 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,776 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,778 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,778 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,779 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,780 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,808 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,809 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,860 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  23%|       | 132/574 [00:15<00:47,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,875 INFO | INITIAL\n",
      "2021-05-27 16:55:09,879 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,885 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,885 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,886 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,887 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,888 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,971 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  23%|       | 133/574 [00:15<00:47,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:09,983 INFO | INITIAL\n",
      "2021-05-27 16:55:09,983 INFO | (50, 200)\n",
      "2021-05-27 16:55:09,988 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:09,988 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,990 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:09,990 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:09,991 INFO | BERT LAYER\n",
      "2021-05-27 16:55:09,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:09,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:09,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:09,999 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,000 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,015 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,073 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  23%|       | 134/574 [00:15<00:46,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,085 INFO | INITIAL\n",
      "2021-05-27 16:55:10,086 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,092 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,092 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,093 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,094 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,094 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,146 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,176 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  24%|       | 135/574 [00:15<00:45,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,186 INFO | INITIAL\n",
      "2021-05-27 16:55:10,187 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,193 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,193 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,195 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,195 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,196 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,279 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,280 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,281 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  24%|       | 136/574 [00:15<00:46,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,293 INFO | INITIAL\n",
      "2021-05-27 16:55:10,293 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,300 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,301 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,302 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,303 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,304 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,372 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,373 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,373 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,380 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  24%|       | 136/574 [00:15<00:46,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,391 INFO | INITIAL\n",
      "2021-05-27 16:55:10,391 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,398 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,398 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,400 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,400 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,401 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,483 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  24%|       | 138/574 [00:15<00:44,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,492 INFO | INITIAL\n",
      "2021-05-27 16:55:10,493 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,498 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,499 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,500 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,500 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,501 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,516 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,523 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,524 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,583 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  24%|       | 139/574 [00:15<00:44,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,593 INFO | INITIAL\n",
      "2021-05-27 16:55:10,593 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,598 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,599 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,600 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,601 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,602 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,634 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,635 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,682 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  24%|       | 139/574 [00:15<00:44,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,693 INFO | INITIAL\n",
      "2021-05-27 16:55:10,693 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,699 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,700 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,701 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,702 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,702 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,790 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  25%|       | 141/574 [00:15<00:44,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,802 INFO | INITIAL\n",
      "2021-05-27 16:55:10,803 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,815 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,816 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,817 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,817 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,818 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,819 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,871 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,902 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  25%|       | 142/574 [00:16<00:45,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:10,914 INFO | INITIAL\n",
      "2021-05-27 16:55:10,914 INFO | (50, 200)\n",
      "2021-05-27 16:55:10,919 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:10,920 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,921 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:10,922 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:10,922 INFO | BERT LAYER\n",
      "2021-05-27 16:55:10,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,924 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,959 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,967 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,981 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:10,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:10,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:10,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,006 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,007 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,015 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,015 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  25%|       | 143/574 [00:16<00:46,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,026 INFO | INITIAL\n",
      "2021-05-27 16:55:11,027 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,034 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,034 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,036 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,036 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,037 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,037 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,045 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,053 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,090 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,091 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,113 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,119 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  25%|       | 144/574 [00:16<00:45,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,130 INFO | INITIAL\n",
      "2021-05-27 16:55:11,131 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,136 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,137 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,139 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,139 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,140 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,150 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,151 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,228 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  25%|       | 145/574 [00:16<00:45,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,237 INFO | INITIAL\n",
      "2021-05-27 16:55:11,238 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,243 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,244 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,245 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,246 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,246 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,279 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,280 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,286 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,287 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,300 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,336 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  25%|       | 146/574 [00:16<00:46,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,350 INFO | INITIAL\n",
      "2021-05-27 16:55:11,351 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,357 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,358 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,360 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,360 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,361 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,365 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,373 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,448 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  26%|       | 147/574 [00:16<00:46,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,459 INFO | INITIAL\n",
      "2021-05-27 16:55:11,461 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,467 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,468 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,470 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,470 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,472 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,559 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,561 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  26%|       | 148/574 [00:16<00:46,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,573 INFO | INITIAL\n",
      "2021-05-27 16:55:11,573 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,583 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,584 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,585 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,585 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,586 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,593 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,642 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,643 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,657 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,673 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  26%|       | 149/574 [00:16<00:47,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,686 INFO | INITIAL\n",
      "2021-05-27 16:55:11,686 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,695 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,696 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,697 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,697 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,698 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,733 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,734 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,772 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,774 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,782 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  26%|       | 150/574 [00:16<00:46,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,793 INFO | INITIAL\n",
      "2021-05-27 16:55:11,794 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,798 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,799 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,800 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,801 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,801 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,819 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,843 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,887 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  26%|       | 151/574 [00:17<00:45,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:11,897 INFO | INITIAL\n",
      "2021-05-27 16:55:11,898 INFO | (50, 200)\n",
      "2021-05-27 16:55:11,904 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:11,904 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,906 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:11,906 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:11,907 INFO | BERT LAYER\n",
      "2021-05-27 16:55:11,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,928 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:11,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:11,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:11,999 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,000 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,000 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,001 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  26%|       | 152/574 [00:17<00:46,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,013 INFO | INITIAL\n",
      "2021-05-27 16:55:12,014 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,021 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,021 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,023 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,023 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,024 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,068 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,069 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,075 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,076 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,084 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,092 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,121 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  27%|       | 153/574 [00:17<00:47,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,133 INFO | INITIAL\n",
      "2021-05-27 16:55:12,133 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,139 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,139 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,141 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,142 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,235 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  27%|       | 154/574 [00:17<00:47,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,248 INFO | INITIAL\n",
      "2021-05-27 16:55:12,248 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,253 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,253 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,255 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,255 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,256 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,257 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,272 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,273 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,294 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,300 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,309 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,339 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  27%|       | 155/574 [00:17<00:46,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,352 INFO | INITIAL\n",
      "2021-05-27 16:55:12,353 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,358 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,358 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,359 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,360 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,361 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,389 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,440 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  27%|       | 155/574 [00:17<00:46,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,449 INFO | INITIAL\n",
      "2021-05-27 16:55:12,449 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,454 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,454 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,456 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,456 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,457 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,458 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,495 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,508 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,509 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,538 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  27%|       | 157/574 [00:17<00:44,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,554 INFO | INITIAL\n",
      "2021-05-27 16:55:12,555 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,560 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,561 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,562 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,563 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,564 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,572 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,573 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,588 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,595 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,596 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,642 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,651 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  28%|       | 158/574 [00:17<00:44,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,663 INFO | INITIAL\n",
      "2021-05-27 16:55:12,663 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,669 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,669 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,671 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,671 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,672 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,698 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,738 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,762 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  28%|       | 159/574 [00:17<00:44,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,773 INFO | INITIAL\n",
      "2021-05-27 16:55:12,775 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,782 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,782 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,783 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,784 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,785 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,786 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,798 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,799 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,812 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,819 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,861 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  28%|       | 159/574 [00:18<00:44,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,869 INFO | INITIAL\n",
      "2021-05-27 16:55:12,870 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,875 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,875 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,877 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,878 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,879 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,919 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,920 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,939 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,954 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  28%|       | 161/574 [00:18<00:42,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:12,965 INFO | INITIAL\n",
      "2021-05-27 16:55:12,965 INFO | (50, 200)\n",
      "2021-05-27 16:55:12,970 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:12,971 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,972 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:12,972 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:12,973 INFO | BERT LAYER\n",
      "2021-05-27 16:55:12,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:12,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:12,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:12,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,038 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,039 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,046 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,047 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,055 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  28%|       | 162/574 [00:18<00:42,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,068 INFO | INITIAL\n",
      "2021-05-27 16:55:13,068 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,074 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,075 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,077 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,077 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,078 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,079 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,106 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,162 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,171 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  28%|       | 163/574 [00:18<00:43,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,184 INFO | INITIAL\n",
      "2021-05-27 16:55:13,185 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,189 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,190 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,191 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,192 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,193 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,251 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,280 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,280 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  29%|       | 164/574 [00:18<00:43,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,290 INFO | INITIAL\n",
      "2021-05-27 16:55:13,290 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,298 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,298 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,299 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,300 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,300 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,402 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  29%|       | 165/574 [00:18<00:45,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,414 INFO | INITIAL\n",
      "2021-05-27 16:55:13,415 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,420 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,420 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,421 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,422 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,423 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,491 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,509 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  29%|       | 166/574 [00:18<00:44,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,520 INFO | INITIAL\n",
      "2021-05-27 16:55:13,521 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,526 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,527 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,528 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,528 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,529 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,543 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,544 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,584 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,615 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,616 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  29%|       | 167/574 [00:18<00:44,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,629 INFO | INITIAL\n",
      "2021-05-27 16:55:13,630 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,636 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,636 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,638 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,638 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,639 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,663 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,663 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,723 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  29%|       | 168/574 [00:18<00:43,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,734 INFO | INITIAL\n",
      "2021-05-27 16:55:13,735 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,740 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,741 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,742 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,743 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,744 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,748 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,791 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,831 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  29%|       | 169/574 [00:19<00:43,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,844 INFO | INITIAL\n",
      "2021-05-27 16:55:13,845 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,850 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,850 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,852 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,852 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,854 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,864 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,872 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,879 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,880 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,917 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,918 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,939 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  30%|       | 170/574 [00:19<00:43,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:13,951 INFO | INITIAL\n",
      "2021-05-27 16:55:13,952 INFO | (50, 200)\n",
      "2021-05-27 16:55:13,960 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:13,961 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,962 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:13,963 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:13,964 INFO | BERT LAYER\n",
      "2021-05-27 16:55:13,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,965 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,966 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,972 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:13,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:13,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:13,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,053 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  30%|       | 171/574 [00:19<00:44,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,064 INFO | INITIAL\n",
      "2021-05-27 16:55:14,065 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,070 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,070 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,072 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,072 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,073 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,084 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,092 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,100 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,101 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,108 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,163 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,165 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  30%|       | 172/574 [00:19<00:44,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,175 INFO | INITIAL\n",
      "2021-05-27 16:55:14,176 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,181 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,182 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,183 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,184 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,185 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,230 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,231 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,269 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  30%|       | 173/574 [00:19<00:43,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,280 INFO | INITIAL\n",
      "2021-05-27 16:55:14,280 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,287 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,288 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,289 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,289 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,290 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,292 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,293 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,321 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,349 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,357 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,358 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,372 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,373 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,374 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  30%|       | 174/574 [00:19<00:42,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,384 INFO | INITIAL\n",
      "2021-05-27 16:55:14,385 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,390 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,390 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,391 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,392 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,393 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,426 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,480 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  30%|       | 175/574 [00:19<00:42,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,491 INFO | INITIAL\n",
      "2021-05-27 16:55:14,493 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,500 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,500 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,502 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,502 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,503 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,543 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,544 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,587 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  31%|       | 176/574 [00:19<00:42,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,598 INFO | INITIAL\n",
      "2021-05-27 16:55:14,599 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,604 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,604 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,605 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,606 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,606 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,615 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,633 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,634 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,655 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,693 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  31%|       | 177/574 [00:19<00:42,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,704 INFO | INITIAL\n",
      "2021-05-27 16:55:14,704 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,710 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,710 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,712 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,712 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,713 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,738 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,819 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  31%|       | 178/574 [00:20<00:44,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,830 INFO | INITIAL\n",
      "2021-05-27 16:55:14,831 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,836 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,837 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,838 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,839 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,841 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,842 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,892 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,905 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,919 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,920 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,920 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  31%|       | 179/574 [00:20<00:43,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:14,931 INFO | INITIAL\n",
      "2021-05-27 16:55:14,932 INFO | (50, 200)\n",
      "2021-05-27 16:55:14,938 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:14,938 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,939 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:14,940 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:14,940 INFO | BERT LAYER\n",
      "2021-05-27 16:55:14,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,981 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,982 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:14,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:14,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:14,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,029 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  31%|      | 180/574 [00:20<00:42,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,038 INFO | INITIAL\n",
      "2021-05-27 16:55:15,038 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,044 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,044 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,046 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,046 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,047 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,078 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,079 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,086 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,087 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,128 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,129 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,129 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  32%|      | 181/574 [00:20<00:41,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,138 INFO | INITIAL\n",
      "2021-05-27 16:55:15,139 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,146 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,146 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,148 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,148 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,149 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,150 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,151 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,184 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,236 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  32%|      | 182/574 [00:20<00:41,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,248 INFO | INITIAL\n",
      "2021-05-27 16:55:15,248 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,253 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,253 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,254 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,255 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,256 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,257 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,318 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,338 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  32%|      | 183/574 [00:20<00:41,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,349 INFO | INITIAL\n",
      "2021-05-27 16:55:15,350 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,355 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,356 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,357 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,358 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,359 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,383 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,384 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,391 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,397 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,398 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,440 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  32%|      | 184/574 [00:20<00:40,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,451 INFO | INITIAL\n",
      "2021-05-27 16:55:15,452 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,456 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,457 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,458 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,459 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,459 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,476 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,477 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,485 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,494 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,515 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,516 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,516 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,522 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,523 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,529 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,530 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,547 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  32%|      | 185/574 [00:20<00:40,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,559 INFO | INITIAL\n",
      "2021-05-27 16:55:15,560 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,565 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,565 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,567 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,567 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,568 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,576 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,577 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,595 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,596 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,625 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,655 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,655 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  32%|      | 186/574 [00:20<00:40,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,665 INFO | INITIAL\n",
      "2021-05-27 16:55:15,665 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,671 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,671 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,672 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,673 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,674 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,691 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,754 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  33%|      | 187/574 [00:20<00:40,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,765 INFO | INITIAL\n",
      "2021-05-27 16:55:15,766 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,773 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,773 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,774 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,775 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,777 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,791 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,797 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,822 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,828 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,835 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,843 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,844 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,844 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,850 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,851 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,857 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,858 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,859 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  33%|      | 188/574 [00:21<00:40,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,870 INFO | INITIAL\n",
      "2021-05-27 16:55:15,870 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,875 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,876 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,877 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,878 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,879 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,879 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,958 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  33%|      | 188/574 [00:21<00:40,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:15,967 INFO | INITIAL\n",
      "2021-05-27 16:55:15,968 INFO | (50, 200)\n",
      "2021-05-27 16:55:15,973 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:15,973 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,974 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:15,975 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:15,976 INFO | BERT LAYER\n",
      "2021-05-27 16:55:15,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:15,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:15,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:15,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,045 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,053 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,061 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  33%|      | 190/574 [00:21<00:39,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,071 INFO | INITIAL\n",
      "2021-05-27 16:55:16,071 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,076 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,077 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,078 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,079 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,080 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,163 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  33%|      | 191/574 [00:21<00:39,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,175 INFO | INITIAL\n",
      "2021-05-27 16:55:16,176 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,182 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,182 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,184 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,184 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,185 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,201 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,273 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  33%|      | 192/574 [00:21<00:40,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,288 INFO | INITIAL\n",
      "2021-05-27 16:55:16,288 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,295 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,296 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,297 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,298 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,299 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,300 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,346 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,347 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,356 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,363 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,388 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  34%|      | 193/574 [00:21<00:40,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,398 INFO | INITIAL\n",
      "2021-05-27 16:55:16,399 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,404 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,404 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,405 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,405 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,406 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,469 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,477 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,485 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,494 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  34%|      | 194/574 [00:21<00:40,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,504 INFO | INITIAL\n",
      "2021-05-27 16:55:16,504 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,510 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,510 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,512 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,513 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,514 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,515 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,516 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,522 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,523 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,523 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,544 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,545 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,574 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,575 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,600 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  34%|      | 195/574 [00:21<00:40,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,610 INFO | INITIAL\n",
      "2021-05-27 16:55:16,611 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,617 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,618 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,620 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,621 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,622 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,622 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,623 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,631 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,632 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,655 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,662 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,662 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,701 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,702 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,702 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  34%|      | 196/574 [00:21<00:39,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,715 INFO | INITIAL\n",
      "2021-05-27 16:55:16,715 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,720 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,721 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,722 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,722 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,723 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,738 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,761 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,777 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,791 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,808 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  34%|      | 197/574 [00:22<00:39,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,821 INFO | INITIAL\n",
      "2021-05-27 16:55:16,821 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,828 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,829 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,830 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,831 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,832 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,850 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,917 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  34%|      | 198/574 [00:22<00:40,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:16,929 INFO | INITIAL\n",
      "2021-05-27 16:55:16,930 INFO | (50, 200)\n",
      "2021-05-27 16:55:16,935 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:16,935 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,937 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:16,937 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:16,938 INFO | BERT LAYER\n",
      "2021-05-27 16:55:16,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,939 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:16,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:16,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:16,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,019 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  35%|      | 199/574 [00:22<00:39,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,030 INFO | INITIAL\n",
      "2021-05-27 16:55:17,031 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,036 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,037 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,038 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,038 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,039 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,126 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  35%|      | 200/574 [00:22<00:39,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,136 INFO | INITIAL\n",
      "2021-05-27 16:55:17,136 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,141 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,143 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,143 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,144 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,173 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,221 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  35%|      | 200/574 [00:22<00:39,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,231 INFO | INITIAL\n",
      "2021-05-27 16:55:17,231 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,236 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,237 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,238 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,239 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,239 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,241 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,323 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  35%|      | 202/574 [00:22<00:38,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,335 INFO | INITIAL\n",
      "2021-05-27 16:55:17,335 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,341 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,342 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,343 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,344 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,345 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,369 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,370 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,430 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  35%|      | 203/574 [00:22<00:38,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,440 INFO | INITIAL\n",
      "2021-05-27 16:55:17,441 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,449 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,450 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,451 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,451 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,452 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,452 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,494 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,532 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  36%|      | 204/574 [00:22<00:38,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,542 INFO | INITIAL\n",
      "2021-05-27 16:55:17,543 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,549 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,550 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,551 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,553 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,576 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,577 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,591 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,616 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,639 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  36%|      | 205/574 [00:22<00:38,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,649 INFO | INITIAL\n",
      "2021-05-27 16:55:17,649 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,655 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,655 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,656 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,656 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,657 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,745 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  36%|      | 206/574 [00:22<00:38,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,757 INFO | INITIAL\n",
      "2021-05-27 16:55:17,758 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,766 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,766 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,768 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,768 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,769 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,856 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  36%|      | 207/574 [00:23<00:39,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,871 INFO | INITIAL\n",
      "2021-05-27 16:55:17,871 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,876 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,877 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,878 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,879 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,880 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,940 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,941 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,965 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  36%|      | 208/574 [00:23<00:39,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:17,977 INFO | INITIAL\n",
      "2021-05-27 16:55:17,977 INFO | (50, 200)\n",
      "2021-05-27 16:55:17,983 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:17,983 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,984 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:17,985 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:17,985 INFO | BERT LAYER\n",
      "2021-05-27 16:55:17,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,986 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:17,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:17,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:17,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,031 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,038 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,067 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  36%|      | 209/574 [00:23<00:38,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,080 INFO | INITIAL\n",
      "2021-05-27 16:55:18,081 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,086 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,087 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,088 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,089 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,090 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,128 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,129 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,136 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,175 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  37%|      | 210/574 [00:23<00:38,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,185 INFO | INITIAL\n",
      "2021-05-27 16:55:18,185 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,191 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,192 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,193 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,194 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,195 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,277 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  37%|      | 211/574 [00:23<00:38,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,296 INFO | INITIAL\n",
      "2021-05-27 16:55:18,297 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,305 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,305 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,307 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,307 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,308 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,309 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,318 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,324 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,340 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,374 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,398 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  37%|      | 212/574 [00:23<00:39,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,413 INFO | INITIAL\n",
      "2021-05-27 16:55:18,414 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,420 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,420 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,422 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,423 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,423 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,477 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,478 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,507 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  37%|      | 213/574 [00:23<00:39,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,521 INFO | INITIAL\n",
      "2021-05-27 16:55:18,521 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,527 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,528 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,529 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,530 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,530 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,544 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,545 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,612 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  37%|      | 214/574 [00:23<00:39,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,628 INFO | INITIAL\n",
      "2021-05-27 16:55:18,629 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,634 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,634 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,636 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,636 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,637 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,728 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  37%|      | 215/574 [00:23<00:39,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,737 INFO | INITIAL\n",
      "2021-05-27 16:55:18,738 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,744 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,744 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,746 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,746 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,747 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,824 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,832 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  38%|      | 216/574 [00:24<00:38,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,844 INFO | INITIAL\n",
      "2021-05-27 16:55:18,845 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,850 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,851 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,852 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,852 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,853 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,892 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,899 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,936 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  38%|      | 217/574 [00:24<00:38,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:18,949 INFO | INITIAL\n",
      "2021-05-27 16:55:18,949 INFO | (50, 200)\n",
      "2021-05-27 16:55:18,956 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:18,956 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,958 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:18,959 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:18,960 INFO | BERT LAYER\n",
      "2021-05-27 16:55:18,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,986 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:18,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:18,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:18,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,031 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,038 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,039 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,040 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  38%|      | 218/574 [00:24<00:37,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,052 INFO | INITIAL\n",
      "2021-05-27 16:55:19,054 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,060 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,060 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,062 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,062 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,063 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,077 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,086 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,146 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  38%|      | 219/574 [00:24<00:37,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,159 INFO | INITIAL\n",
      "2021-05-27 16:55:19,160 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,167 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,167 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,168 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,169 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,170 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,187 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,242 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,250 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  38%|      | 220/574 [00:24<00:37,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,263 INFO | INITIAL\n",
      "2021-05-27 16:55:19,264 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,269 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,270 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,271 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,271 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,272 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,306 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,353 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  39%|      | 221/574 [00:24<00:37,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,370 INFO | INITIAL\n",
      "2021-05-27 16:55:19,370 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,376 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,377 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,378 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,378 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,379 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,380 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,426 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,442 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,443 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,450 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,459 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  39%|      | 221/574 [00:24<00:37,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,469 INFO | INITIAL\n",
      "2021-05-27 16:55:19,469 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,475 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,476 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,477 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,478 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,479 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,495 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,496 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,567 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  39%|      | 223/574 [00:24<00:36,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,578 INFO | INITIAL\n",
      "2021-05-27 16:55:19,578 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,584 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,584 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,587 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,587 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,588 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,621 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,622 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,677 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  39%|      | 224/574 [00:24<00:37,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,689 INFO | INITIAL\n",
      "2021-05-27 16:55:19,689 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,697 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,697 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,698 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,699 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,700 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,700 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,740 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,740 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,773 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,788 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  39%|      | 225/574 [00:24<00:37,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,798 INFO | INITIAL\n",
      "2021-05-27 16:55:19,799 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,803 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,804 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,805 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,806 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,806 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,809 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,815 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,892 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,894 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  39%|      | 226/574 [00:25<00:37,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:19,903 INFO | INITIAL\n",
      "2021-05-27 16:55:19,904 INFO | (50, 200)\n",
      "2021-05-27 16:55:19,909 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:19,910 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,911 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:19,912 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:19,912 INFO | BERT LAYER\n",
      "2021-05-27 16:55:19,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,967 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:19,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:19,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:19,999 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  40%|      | 227/574 [00:25<00:36,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,010 INFO | INITIAL\n",
      "2021-05-27 16:55:20,010 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,015 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,016 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,017 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,017 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,018 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,038 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,039 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,047 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,048 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,053 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,090 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,105 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  40%|      | 228/574 [00:25<00:36,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,115 INFO | INITIAL\n",
      "2021-05-27 16:55:20,116 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,122 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,122 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,124 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,125 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,126 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,157 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,163 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,181 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,207 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,207 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  40%|      | 229/574 [00:25<00:36,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,219 INFO | INITIAL\n",
      "2021-05-27 16:55:20,220 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,228 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,229 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,230 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,231 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,232 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,238 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,239 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,266 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,292 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,297 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,313 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,314 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  40%|      | 230/574 [00:25<00:36,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,326 INFO | INITIAL\n",
      "2021-05-27 16:55:20,327 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,333 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,333 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,334 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,335 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,336 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,395 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,412 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,420 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  40%|      | 231/574 [00:25<00:36,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,432 INFO | INITIAL\n",
      "2021-05-27 16:55:20,433 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,437 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,438 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,439 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,439 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,440 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,469 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,477 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,478 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,534 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  40%|      | 232/574 [00:25<00:37,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,546 INFO | INITIAL\n",
      "2021-05-27 16:55:20,546 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,551 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,553 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,559 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,560 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,561 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,576 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,577 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,584 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,591 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,619 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,643 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,651 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  41%|      | 233/574 [00:25<00:37,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,662 INFO | INITIAL\n",
      "2021-05-27 16:55:20,663 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,668 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,668 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,669 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,670 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,671 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,702 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,709 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,752 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  41%|      | 234/574 [00:25<00:36,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,764 INFO | INITIAL\n",
      "2021-05-27 16:55:20,765 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,771 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,771 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,773 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,773 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,774 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,810 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,835 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,850 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,857 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,858 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,858 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  41%|      | 235/574 [00:26<00:36,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,869 INFO | INITIAL\n",
      "2021-05-27 16:55:20,870 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,876 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,876 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,877 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,878 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,879 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,880 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,930 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,931 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,945 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,946 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,951 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,952 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,961 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  41%|      | 236/574 [00:26<00:35,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:20,972 INFO | INITIAL\n",
      "2021-05-27 16:55:20,972 INFO | (50, 200)\n",
      "2021-05-27 16:55:20,980 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:20,980 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,982 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:20,983 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:20,984 INFO | BERT LAYER\n",
      "2021-05-27 16:55:20,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:20,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:20,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:20,999 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,000 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,000 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,064 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  41%|     | 237/574 [00:26<00:35,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,074 INFO | INITIAL\n",
      "2021-05-27 16:55:21,075 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,081 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,081 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,083 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,083 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,084 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,086 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,170 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  41%|     | 238/574 [00:26<00:35,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,181 INFO | INITIAL\n",
      "2021-05-27 16:55:21,182 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,189 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,189 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,190 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,191 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,191 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,266 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,267 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,272 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,273 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,273 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  42%|     | 239/574 [00:26<00:34,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,283 INFO | INITIAL\n",
      "2021-05-27 16:55:21,284 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,289 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,290 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,292 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,292 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,294 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,327 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,342 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,343 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,382 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  42%|     | 240/574 [00:26<00:35,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,393 INFO | INITIAL\n",
      "2021-05-27 16:55:21,394 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,399 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,399 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,400 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,401 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,402 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,481 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  42%|     | 241/574 [00:26<00:34,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,494 INFO | INITIAL\n",
      "2021-05-27 16:55:21,495 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,502 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,503 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,504 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,505 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,505 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,561 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,575 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,582 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  42%|     | 241/574 [00:26<00:34,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,592 INFO | INITIAL\n",
      "2021-05-27 16:55:21,593 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,598 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,599 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,600 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,600 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,601 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,625 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,633 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,634 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,641 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,662 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,663 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,684 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  42%|     | 243/574 [00:26<00:34,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,697 INFO | INITIAL\n",
      "2021-05-27 16:55:21,698 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,702 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,703 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,704 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,705 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,706 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,724 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,774 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,789 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,789 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 244/574 [00:26<00:33,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,800 INFO | INITIAL\n",
      "2021-05-27 16:55:21,800 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,805 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,805 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,807 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,807 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,808 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,901 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 245/574 [00:27<00:34,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:21,913 INFO | INITIAL\n",
      "2021-05-27 16:55:21,914 INFO | (50, 200)\n",
      "2021-05-27 16:55:21,918 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:21,919 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,920 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:21,920 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:21,921 INFO | BERT LAYER\n",
      "2021-05-27 16:55:21,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,945 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,946 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,992 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:21,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:21,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:21,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,005 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 246/574 [00:27<00:34,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,016 INFO | INITIAL\n",
      "2021-05-27 16:55:22,016 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,022 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,022 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,024 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,024 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,026 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,077 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,108 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,109 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 247/574 [00:27<00:34,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,120 INFO | INITIAL\n",
      "2021-05-27 16:55:22,120 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,126 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,126 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,127 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,128 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,129 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,214 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 248/574 [00:27<00:34,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,225 INFO | INITIAL\n",
      "2021-05-27 16:55:22,225 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,232 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,232 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,233 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,234 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,235 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,318 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,319 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 249/574 [00:27<00:33,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,329 INFO | INITIAL\n",
      "2021-05-27 16:55:22,329 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,334 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,334 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,335 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,335 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,336 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,416 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  43%|     | 249/574 [00:27<00:33,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,427 INFO | INITIAL\n",
      "2021-05-27 16:55:22,428 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,434 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,434 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,436 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,436 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,437 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,445 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,452 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,476 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,477 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,490 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,491 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,491 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,521 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  44%|     | 251/574 [00:27<00:33,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,533 INFO | INITIAL\n",
      "2021-05-27 16:55:22,534 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,538 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,539 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,540 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,540 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,541 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,576 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,577 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,584 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,592 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,622 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,624 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  44%|     | 252/574 [00:27<00:33,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,636 INFO | INITIAL\n",
      "2021-05-27 16:55:22,637 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,642 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,643 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,644 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,645 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,646 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,655 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,657 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,701 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,702 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,733 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  44%|     | 253/574 [00:27<00:33,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,744 INFO | INITIAL\n",
      "2021-05-27 16:55:22,744 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,749 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,749 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,751 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,751 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,752 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,769 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,796 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,797 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,808 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,809 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,821 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,822 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,822 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,829 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,830 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,831 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  44%|     | 253/574 [00:28<00:33,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,842 INFO | INITIAL\n",
      "2021-05-27 16:55:22,842 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,849 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,849 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,851 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,851 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,852 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,905 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,935 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  44%|     | 255/574 [00:28<00:32,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:22,947 INFO | INITIAL\n",
      "2021-05-27 16:55:22,948 INFO | (50, 200)\n",
      "2021-05-27 16:55:22,953 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:22,954 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,955 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:22,956 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:22,957 INFO | BERT LAYER\n",
      "2021-05-27 16:55:22,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,981 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,982 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:22,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:22,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:22,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,041 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  45%|     | 256/574 [00:28<00:32,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,052 INFO | INITIAL\n",
      "2021-05-27 16:55:23,052 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,059 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,060 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,061 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,062 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,063 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,105 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,106 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,113 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,114 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,150 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,151 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  45%|     | 257/574 [00:28<00:33,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,161 INFO | INITIAL\n",
      "2021-05-27 16:55:23,162 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,172 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,173 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,174 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,175 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,176 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,257 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  45%|     | 258/574 [00:28<00:33,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,267 INFO | INITIAL\n",
      "2021-05-27 16:55:23,268 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,273 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,273 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,275 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,275 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,276 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,292 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,361 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  45%|     | 259/574 [00:28<00:33,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,372 INFO | INITIAL\n",
      "2021-05-27 16:55:23,373 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,379 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,380 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,381 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,382 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,383 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,463 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,471 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  45%|     | 260/574 [00:28<00:33,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,481 INFO | INITIAL\n",
      "2021-05-27 16:55:23,482 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,487 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,488 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,490 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,490 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,491 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,496 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,517 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,522 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,523 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,523 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,581 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  45%|     | 261/574 [00:28<00:33,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,593 INFO | INITIAL\n",
      "2021-05-27 16:55:23,594 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,599 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,599 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,601 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,601 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,602 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,611 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,630 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,680 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,688 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  46%|     | 262/574 [00:28<00:33,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,702 INFO | INITIAL\n",
      "2021-05-27 16:55:23,703 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,709 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,710 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,711 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,712 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,713 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,791 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,801 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  46%|     | 263/574 [00:29<00:33,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,814 INFO | INITIAL\n",
      "2021-05-27 16:55:23,815 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,820 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,820 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,822 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,822 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,823 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,864 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,865 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,912 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  46%|     | 264/574 [00:29<00:33,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:23,923 INFO | INITIAL\n",
      "2021-05-27 16:55:23,923 INFO | (50, 200)\n",
      "2021-05-27 16:55:23,931 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:23,931 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,933 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:23,933 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:23,934 INFO | BERT LAYER\n",
      "2021-05-27 16:55:23,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,972 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:23,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:23,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:23,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,020 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,021 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,021 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  46%|     | 265/574 [00:29<00:33,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,034 INFO | INITIAL\n",
      "2021-05-27 16:55:24,034 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,040 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,041 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,042 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,043 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,044 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,045 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,047 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,047 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,078 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,084 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,100 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,101 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,134 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  46%|     | 266/574 [00:29<00:33,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,144 INFO | INITIAL\n",
      "2021-05-27 16:55:24,145 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,150 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,150 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,152 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,152 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,153 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,163 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,201 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,239 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,247 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  47%|     | 267/574 [00:29<00:33,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,256 INFO | INITIAL\n",
      "2021-05-27 16:55:24,256 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,263 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,263 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,265 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,265 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,266 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,267 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,282 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,297 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,313 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,355 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  47%|     | 268/574 [00:29<00:34,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,369 INFO | INITIAL\n",
      "2021-05-27 16:55:24,370 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,377 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,377 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,379 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,380 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,381 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,389 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,407 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,469 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  47%|     | 269/574 [00:29<00:33,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,480 INFO | INITIAL\n",
      "2021-05-27 16:55:24,480 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,486 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,486 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,488 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,488 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,489 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,491 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,572 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  47%|     | 270/574 [00:29<00:32,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,582 INFO | INITIAL\n",
      "2021-05-27 16:55:24,583 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,588 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,589 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,591 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,592 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,593 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,609 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,675 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  47%|     | 271/574 [00:29<00:32,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,687 INFO | INITIAL\n",
      "2021-05-27 16:55:24,687 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,694 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,695 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,696 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,697 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,698 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,724 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,790 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  47%|     | 272/574 [00:29<00:33,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,801 INFO | INITIAL\n",
      "2021-05-27 16:55:24,802 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,812 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,813 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,814 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,815 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,816 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,834 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,843 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,861 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,868 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,922 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  48%|     | 273/574 [00:30<00:34,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:24,932 INFO | INITIAL\n",
      "2021-05-27 16:55:24,933 INFO | (50, 200)\n",
      "2021-05-27 16:55:24,940 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:24,941 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,943 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:24,943 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:24,944 INFO | BERT LAYER\n",
      "2021-05-27 16:55:24,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:24,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:24,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:24,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,000 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,033 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  48%|     | 274/574 [00:30<00:34,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,044 INFO | INITIAL\n",
      "2021-05-27 16:55:25,045 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,050 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,050 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,052 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,052 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,053 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,062 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,063 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,139 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  48%|     | 275/574 [00:30<00:33,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,153 INFO | INITIAL\n",
      "2021-05-27 16:55:25,155 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,161 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,162 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,164 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,165 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,166 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,187 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,253 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  48%|     | 276/574 [00:30<00:33,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,265 INFO | INITIAL\n",
      "2021-05-27 16:55:25,266 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,270 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,271 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,272 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,272 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,273 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,274 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,321 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,342 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,343 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,343 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,349 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,350 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,356 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,357 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,358 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  48%|     | 277/574 [00:30<00:32,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,369 INFO | INITIAL\n",
      "2021-05-27 16:55:25,370 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,377 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,377 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,378 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,379 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,380 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,380 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,445 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,460 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  48%|     | 278/574 [00:30<00:32,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,473 INFO | INITIAL\n",
      "2021-05-27 16:55:25,473 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,482 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,483 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,484 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,484 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,485 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,566 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  49%|     | 279/574 [00:30<00:31,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,580 INFO | INITIAL\n",
      "2021-05-27 16:55:25,581 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,588 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,588 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,590 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,590 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,595 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,607 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,615 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,623 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,652 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,680 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,689 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  49%|     | 280/574 [00:30<00:33,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,704 INFO | INITIAL\n",
      "2021-05-27 16:55:25,704 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,711 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,712 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,713 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,713 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,714 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,729 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,795 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  49%|     | 281/574 [00:30<00:32,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,805 INFO | INITIAL\n",
      "2021-05-27 16:55:25,805 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,810 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,811 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,812 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,812 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,813 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,815 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,821 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,822 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,822 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,828 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,836 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,837 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,896 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  49%|     | 282/574 [00:31<00:31,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:25,907 INFO | INITIAL\n",
      "2021-05-27 16:55:25,908 INFO | (50, 200)\n",
      "2021-05-27 16:55:25,919 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:25,920 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,921 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:25,921 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:25,923 INFO | BERT LAYER\n",
      "2021-05-27 16:55:25,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,924 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:25,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:25,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:25,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,011 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  49%|     | 283/574 [00:31<00:31,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,021 INFO | INITIAL\n",
      "2021-05-27 16:55:26,022 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,028 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,029 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,030 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,030 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,031 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,079 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,086 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,108 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,116 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,116 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  49%|     | 284/574 [00:31<00:31,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,131 INFO | INITIAL\n",
      "2021-05-27 16:55:26,132 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,138 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,139 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,141 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,142 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,191 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,192 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,226 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  50%|     | 285/574 [00:31<00:31,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,240 INFO | INITIAL\n",
      "2021-05-27 16:55:26,242 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,249 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,249 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,251 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,251 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,252 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,292 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,313 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,334 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  50%|     | 286/574 [00:31<00:31,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,347 INFO | INITIAL\n",
      "2021-05-27 16:55:26,348 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,353 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,354 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,355 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,355 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,356 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,357 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,358 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,372 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,373 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,373 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,380 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,395 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,419 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,426 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,442 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,443 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,443 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  50%|     | 287/574 [00:31<00:30,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,453 INFO | INITIAL\n",
      "2021-05-27 16:55:26,453 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,460 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,460 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,461 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,462 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,463 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,515 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,516 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,516 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,544 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,545 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,545 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  50%|     | 288/574 [00:31<00:30,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,557 INFO | INITIAL\n",
      "2021-05-27 16:55:26,558 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,566 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,566 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,568 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,569 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,569 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,611 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,635 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,643 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,661 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  50%|     | 289/574 [00:31<00:31,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,672 INFO | INITIAL\n",
      "2021-05-27 16:55:26,673 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,679 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,679 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,680 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,681 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,682 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,729 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,767 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  51%|     | 290/574 [00:31<00:30,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,780 INFO | INITIAL\n",
      "2021-05-27 16:55:26,781 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,786 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,786 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,788 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,788 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,789 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,812 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,813 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,829 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,875 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  51%|     | 291/574 [00:32<00:30,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,887 INFO | INITIAL\n",
      "2021-05-27 16:55:26,887 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,893 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,894 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,896 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,896 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,897 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,927 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,977 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  51%|     | 291/574 [00:32<00:30,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:26,986 INFO | INITIAL\n",
      "2021-05-27 16:55:26,987 INFO | (50, 200)\n",
      "2021-05-27 16:55:26,992 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:26,992 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,994 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:26,994 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:26,995 INFO | BERT LAYER\n",
      "2021-05-27 16:55:26,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:26,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:26,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:26,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,047 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,047 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,047 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,053 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,075 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  51%|     | 293/574 [00:32<00:29,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,085 INFO | INITIAL\n",
      "2021-05-27 16:55:27,085 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,090 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,092 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,093 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,094 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,095 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,162 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,177 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  51%|     | 294/574 [00:32<00:29,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,187 INFO | INITIAL\n",
      "2021-05-27 16:55:27,188 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,193 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,194 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,195 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,196 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,196 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,285 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  51%|    | 295/574 [00:32<00:29,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,296 INFO | INITIAL\n",
      "2021-05-27 16:55:27,297 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,302 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,302 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,304 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,304 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,305 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,340 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,370 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,395 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  52%|    | 296/574 [00:32<00:29,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,406 INFO | INITIAL\n",
      "2021-05-27 16:55:27,406 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,415 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,415 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,417 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,417 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,418 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,419 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,463 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,504 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  52%|    | 297/574 [00:32<00:29,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,515 INFO | INITIAL\n",
      "2021-05-27 16:55:27,515 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,521 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,521 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,523 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,523 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,524 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,588 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,595 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,596 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,612 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  52%|    | 298/574 [00:32<00:29,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,622 INFO | INITIAL\n",
      "2021-05-27 16:55:27,623 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,629 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,630 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,631 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,632 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,633 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,634 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,652 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,720 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  52%|    | 299/574 [00:32<00:29,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,731 INFO | INITIAL\n",
      "2021-05-27 16:55:27,731 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,736 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,737 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,738 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,739 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,740 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,740 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,791 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,813 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,832 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  52%|    | 300/574 [00:33<00:30,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,846 INFO | INITIAL\n",
      "2021-05-27 16:55:27,847 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,852 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,853 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,855 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,855 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,856 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,858 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,949 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  52%|    | 301/574 [00:33<00:30,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:27,957 INFO | INITIAL\n",
      "2021-05-27 16:55:27,958 INFO | (50, 200)\n",
      "2021-05-27 16:55:27,965 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:27,966 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,967 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:27,968 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:27,968 INFO | BERT LAYER\n",
      "2021-05-27 16:55:27,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:27,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:27,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:27,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,018 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,039 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,040 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,046 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,047 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,047 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,048 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  53%|    | 302/574 [00:33<00:29,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,062 INFO | INITIAL\n",
      "2021-05-27 16:55:28,063 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,069 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,070 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,071 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,071 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,072 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,112 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,113 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,150 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,156 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,157 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  53%|    | 303/574 [00:33<00:29,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,172 INFO | INITIAL\n",
      "2021-05-27 16:55:28,173 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,181 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,181 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,183 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,183 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,184 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,201 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,238 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,239 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,269 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  53%|    | 304/574 [00:33<00:29,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,282 INFO | INITIAL\n",
      "2021-05-27 16:55:28,282 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,287 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,288 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,289 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,290 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,290 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,292 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,356 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,363 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,373 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,373 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  53%|    | 305/574 [00:33<00:29,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,386 INFO | INITIAL\n",
      "2021-05-27 16:55:28,387 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,392 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,393 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,394 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,395 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,396 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,482 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  53%|    | 306/574 [00:33<00:28,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,494 INFO | INITIAL\n",
      "2021-05-27 16:55:28,495 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,500 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,500 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,502 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,502 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,503 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,586 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  53%|    | 307/574 [00:33<00:28,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,596 INFO | INITIAL\n",
      "2021-05-27 16:55:28,596 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,601 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,602 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,603 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,604 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,605 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,615 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,625 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,655 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,694 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  54%|    | 308/574 [00:33<00:28,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,705 INFO | INITIAL\n",
      "2021-05-27 16:55:28,705 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,713 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,713 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,715 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,715 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,716 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,720 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,806 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  54%|    | 309/574 [00:34<00:28,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,816 INFO | INITIAL\n",
      "2021-05-27 16:55:28,816 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,821 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,822 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,823 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,823 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,824 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,837 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,857 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,858 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,858 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,911 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  54%|    | 310/574 [00:34<00:28,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:28,921 INFO | INITIAL\n",
      "2021-05-27 16:55:28,922 INFO | (50, 200)\n",
      "2021-05-27 16:55:28,927 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:28,927 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,929 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:28,929 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:28,930 INFO | BERT LAYER\n",
      "2021-05-27 16:55:28,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,945 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,946 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:28,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:28,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:28,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,014 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  54%|    | 311/574 [00:34<00:27,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,024 INFO | INITIAL\n",
      "2021-05-27 16:55:29,025 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,031 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,032 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,033 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,033 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,034 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,112 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,113 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,113 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,120 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  54%|    | 312/574 [00:34<00:27,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,132 INFO | INITIAL\n",
      "2021-05-27 16:55:29,132 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,138 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,139 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,140 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,140 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,142 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,189 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,190 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,230 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,231 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,232 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  55%|    | 313/574 [00:34<00:28,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,244 INFO | INITIAL\n",
      "2021-05-27 16:55:29,244 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,249 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,250 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,251 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,252 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,253 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,270 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,297 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,306 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,321 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,339 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  55%|    | 314/574 [00:34<00:27,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,349 INFO | INITIAL\n",
      "2021-05-27 16:55:29,350 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,354 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,355 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,356 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,356 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,357 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,389 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,439 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  55%|    | 315/574 [00:34<00:27,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,452 INFO | INITIAL\n",
      "2021-05-27 16:55:29,452 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,457 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,457 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,458 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,459 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,460 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,469 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,476 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,477 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,478 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,542 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  55%|    | 316/574 [00:34<00:27,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,555 INFO | INITIAL\n",
      "2021-05-27 16:55:29,556 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,561 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,562 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,563 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,563 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,564 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,588 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,633 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,648 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  55%|    | 317/574 [00:34<00:26,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,657 INFO | INITIAL\n",
      "2021-05-27 16:55:29,658 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,665 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,666 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,667 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,667 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,668 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,686 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,745 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,754 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  55%|    | 318/574 [00:34<00:27,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,766 INFO | INITIAL\n",
      "2021-05-27 16:55:29,766 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,771 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,772 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,773 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,774 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,775 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,809 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,815 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,834 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,835 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,843 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,850 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,851 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,858 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,858 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  56%|    | 319/574 [00:35<00:26,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,871 INFO | INITIAL\n",
      "2021-05-27 16:55:29,871 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,879 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,880 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,881 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,881 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,882 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,883 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,884 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,965 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  56%|    | 320/574 [00:35<00:26,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:29,979 INFO | INITIAL\n",
      "2021-05-27 16:55:29,979 INFO | (50, 200)\n",
      "2021-05-27 16:55:29,985 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:29,986 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,987 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:29,988 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:29,988 INFO | BERT LAYER\n",
      "2021-05-27 16:55:29,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:29,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:29,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:29,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,053 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,068 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,069 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,069 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  56%|    | 321/574 [00:35<00:26,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,081 INFO | INITIAL\n",
      "2021-05-27 16:55:30,081 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,086 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,086 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,087 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,088 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,088 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,106 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,116 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,150 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,150 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,156 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,158 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,176 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  56%|    | 322/574 [00:35<00:26,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,189 INFO | INITIAL\n",
      "2021-05-27 16:55:30,190 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,198 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,198 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,199 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,200 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,201 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,201 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,214 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,215 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,231 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,274 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,286 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  56%|    | 323/574 [00:35<00:26,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,297 INFO | INITIAL\n",
      "2021-05-27 16:55:30,297 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,302 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,303 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,304 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,304 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,306 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,383 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,384 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,403 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  56%|    | 324/574 [00:35<00:27,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,416 INFO | INITIAL\n",
      "2021-05-27 16:55:30,417 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,422 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,422 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,424 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,424 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,425 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,426 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,509 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  57%|    | 325/574 [00:35<00:27,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,527 INFO | INITIAL\n",
      "2021-05-27 16:55:30,527 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,532 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,533 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,535 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,535 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,536 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,561 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,562 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,626 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,628 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  57%|    | 326/574 [00:35<00:27,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,639 INFO | INITIAL\n",
      "2021-05-27 16:55:30,640 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,649 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,649 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,651 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,651 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,652 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,655 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,663 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,751 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  57%|    | 327/574 [00:35<00:28,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,764 INFO | INITIAL\n",
      "2021-05-27 16:55:30,764 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,769 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,770 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,771 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,771 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,772 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,773 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,844 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,853 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  57%|    | 328/574 [00:36<00:27,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,865 INFO | INITIAL\n",
      "2021-05-27 16:55:30,865 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,877 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,877 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,879 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,879 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,880 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,961 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  57%|    | 329/574 [00:36<00:26,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:30,971 INFO | INITIAL\n",
      "2021-05-27 16:55:30,971 INFO | (50, 200)\n",
      "2021-05-27 16:55:30,977 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:30,977 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,979 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:30,979 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:30,980 INFO | BERT LAYER\n",
      "2021-05-27 16:55:30,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:30,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:30,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:30,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,020 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,021 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,067 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  57%|    | 330/574 [00:36<00:26,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,081 INFO | INITIAL\n",
      "2021-05-27 16:55:31,082 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,087 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,088 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,089 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,090 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,091 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,092 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,100 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,101 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,141 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,142 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,173 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,174 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  58%|    | 331/574 [00:36<00:26,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,186 INFO | INITIAL\n",
      "2021-05-27 16:55:31,186 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,199 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,199 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,201 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,201 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,202 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,230 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,231 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,285 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  58%|    | 332/574 [00:36<00:26,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,295 INFO | INITIAL\n",
      "2021-05-27 16:55:31,295 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,300 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,301 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,302 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,302 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,303 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,346 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,397 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  58%|    | 333/574 [00:36<00:26,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,409 INFO | INITIAL\n",
      "2021-05-27 16:55:31,410 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,415 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,417 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,418 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,419 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,420 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,421 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,491 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,508 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  58%|    | 334/574 [00:36<00:26,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,519 INFO | INITIAL\n",
      "2021-05-27 16:55:31,520 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,526 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,527 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,528 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,529 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,529 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,540 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,547 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,548 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,595 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,596 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,612 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,612 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  58%|    | 335/574 [00:36<00:25,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,624 INFO | INITIAL\n",
      "2021-05-27 16:55:31,624 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,633 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,633 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,634 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,635 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,635 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,686 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,700 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,709 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,726 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 336/574 [00:36<00:26,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,737 INFO | INITIAL\n",
      "2021-05-27 16:55:31,738 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,744 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,745 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,747 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,747 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,748 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,763 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,824 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,831 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 337/574 [00:37<00:25,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,845 INFO | INITIAL\n",
      "2021-05-27 16:55:31,845 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,852 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,853 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,854 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,854 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,855 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,858 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,938 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 338/574 [00:37<00:25,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:31,950 INFO | INITIAL\n",
      "2021-05-27 16:55:31,951 INFO | (50, 200)\n",
      "2021-05-27 16:55:31,957 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:31,957 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,959 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:31,960 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:31,960 INFO | BERT LAYER\n",
      "2021-05-27 16:55:31,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,992 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:31,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:31,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:31,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,000 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,000 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,037 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,046 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 339/574 [00:37<00:25,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,057 INFO | INITIAL\n",
      "2021-05-27 16:55:32,058 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,065 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,065 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,066 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,067 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,068 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,077 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,086 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,087 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,105 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,106 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,113 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,130 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,153 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 340/574 [00:37<00:25,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,164 INFO | INITIAL\n",
      "2021-05-27 16:55:32,165 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,170 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,170 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,171 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,172 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,172 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,207 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,214 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,215 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,246 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,262 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 341/574 [00:37<00:25,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,272 INFO | INITIAL\n",
      "2021-05-27 16:55:32,273 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,279 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,280 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,281 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,282 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,283 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,292 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,342 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,362 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  59%|    | 341/574 [00:37<00:25,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,372 INFO | INITIAL\n",
      "2021-05-27 16:55:32,372 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,378 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,379 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,381 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,382 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,383 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,399 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,400 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,407 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,420 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,421 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,435 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,436 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,442 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,467 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  60%|    | 343/574 [00:37<00:24,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,477 INFO | INITIAL\n",
      "2021-05-27 16:55:32,478 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,484 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,485 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,486 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,487 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,488 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,497 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,571 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  60%|    | 344/574 [00:37<00:24,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,581 INFO | INITIAL\n",
      "2021-05-27 16:55:32,582 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,587 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,588 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,589 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,589 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,590 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,652 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,677 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  60%|    | 345/574 [00:37<00:24,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,688 INFO | INITIAL\n",
      "2021-05-27 16:55:32,689 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,694 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,695 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,696 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,696 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,697 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,711 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,763 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,769 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,769 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,776 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  60%|    | 346/574 [00:37<00:23,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,791 INFO | INITIAL\n",
      "2021-05-27 16:55:32,793 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,800 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,801 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,802 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,802 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,803 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,850 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,865 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,870 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,871 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,883 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,884 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,884 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  60%|    | 347/574 [00:38<00:23,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:32,894 INFO | INITIAL\n",
      "2021-05-27 16:55:32,895 INFO | (50, 200)\n",
      "2021-05-27 16:55:32,900 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:32,900 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,902 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:32,903 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:32,904 INFO | BERT LAYER\n",
      "2021-05-27 16:55:32,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,905 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,946 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:32,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:32,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:32,994 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  61%|    | 348/574 [00:38<00:23,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,004 INFO | INITIAL\n",
      "2021-05-27 16:55:33,004 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,010 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,011 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,013 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,013 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,014 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,097 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  61%|    | 349/574 [00:38<00:23,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,106 INFO | INITIAL\n",
      "2021-05-27 16:55:33,106 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,112 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,113 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,115 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,115 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,116 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,209 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  61%|    | 350/574 [00:38<00:24,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,222 INFO | INITIAL\n",
      "2021-05-27 16:55:33,222 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,228 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,228 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,229 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,230 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,230 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,231 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,245 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,273 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,320 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  61%|    | 351/574 [00:38<00:24,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,334 INFO | INITIAL\n",
      "2021-05-27 16:55:33,335 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,342 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,343 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,345 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,345 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,346 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,347 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,399 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,400 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,419 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,427 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  61%|   | 352/574 [00:38<00:23,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,436 INFO | INITIAL\n",
      "2021-05-27 16:55:33,436 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,442 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,442 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,444 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,445 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,446 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,450 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,494 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,536 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  61%|   | 353/574 [00:38<00:23,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,547 INFO | INITIAL\n",
      "2021-05-27 16:55:33,548 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,552 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,554 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,554 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,555 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,647 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  62%|   | 354/574 [00:38<00:24,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,659 INFO | INITIAL\n",
      "2021-05-27 16:55:33,660 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,666 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,667 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,668 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,668 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,669 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,686 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,709 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,738 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,753 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  62%|   | 355/574 [00:38<00:23,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,765 INFO | INITIAL\n",
      "2021-05-27 16:55:33,766 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,771 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,772 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,773 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,774 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,775 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,777 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,806 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,807 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,861 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,861 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  62%|   | 356/574 [00:39<00:23,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,871 INFO | INITIAL\n",
      "2021-05-27 16:55:33,872 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,880 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,880 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,882 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,882 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,885 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,936 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,937 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,967 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,967 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  62%|   | 357/574 [00:39<00:23,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:33,977 INFO | INITIAL\n",
      "2021-05-27 16:55:33,978 INFO | (50, 200)\n",
      "2021-05-27 16:55:33,986 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:33,986 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,988 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:33,988 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:33,989 INFO | BERT LAYER\n",
      "2021-05-27 16:55:33,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:33,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:33,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:33,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,015 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,077 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,078 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  62%|   | 358/574 [00:39<00:23,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,087 INFO | INITIAL\n",
      "2021-05-27 16:55:34,088 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,093 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,093 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,095 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,095 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,095 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,146 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,174 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  62%|   | 358/574 [00:39<00:23,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,185 INFO | INITIAL\n",
      "2021-05-27 16:55:34,185 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,190 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,191 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,193 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,193 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,194 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,230 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,285 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  63%|   | 360/574 [00:39<00:22,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,295 INFO | INITIAL\n",
      "2021-05-27 16:55:34,295 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,300 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,300 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,301 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,302 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,302 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,342 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,343 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,343 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,356 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,357 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,363 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,380 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,389 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,390 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  63%|   | 361/574 [00:39<00:22,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,401 INFO | INITIAL\n",
      "2021-05-27 16:55:34,401 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,406 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,406 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,407 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,408 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,409 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,417 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,488 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  63%|   | 361/574 [00:39<00:22,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,499 INFO | INITIAL\n",
      "2021-05-27 16:55:34,500 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,505 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,506 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,507 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,508 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,509 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,554 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,555 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,576 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,577 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,593 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  63%|   | 363/574 [00:39<00:21,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,602 INFO | INITIAL\n",
      "2021-05-27 16:55:34,603 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,609 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,609 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,610 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,611 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,612 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,622 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,623 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,631 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,632 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,661 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,662 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,701 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  63%|   | 364/574 [00:39<00:22,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,711 INFO | INITIAL\n",
      "2021-05-27 16:55:34,712 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,717 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,718 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,719 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,719 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,720 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,745 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,761 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,769 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,805 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  64%|   | 365/574 [00:40<00:22,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,819 INFO | INITIAL\n",
      "2021-05-27 16:55:34,820 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,825 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,826 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,828 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,828 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,829 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,916 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  64%|   | 366/574 [00:40<00:22,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:34,927 INFO | INITIAL\n",
      "2021-05-27 16:55:34,927 INFO | (50, 200)\n",
      "2021-05-27 16:55:34,933 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:34,933 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,935 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:34,935 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:34,936 INFO | BERT LAYER\n",
      "2021-05-27 16:55:34,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,938 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,939 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,971 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,972 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,979 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,979 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,980 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,980 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,986 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:34,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:34,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:34,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,028 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  64%|   | 367/574 [00:40<00:22,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,038 INFO | INITIAL\n",
      "2021-05-27 16:55:35,039 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,046 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,046 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,048 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,048 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,049 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,059 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,060 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,130 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,138 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  64%|   | 368/574 [00:40<00:22,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,149 INFO | INITIAL\n",
      "2021-05-27 16:55:35,149 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,154 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,155 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,156 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,156 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,157 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,157 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,158 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,236 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  64%|   | 368/574 [00:40<00:22,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,248 INFO | INITIAL\n",
      "2021-05-27 16:55:35,248 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,255 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,255 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,256 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,257 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,258 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,292 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,306 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,327 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,343 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,344 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  64%|   | 370/574 [00:40<00:21,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,356 INFO | INITIAL\n",
      "2021-05-27 16:55:35,356 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,363 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,363 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,365 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,365 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,366 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,374 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,395 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,450 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  65%|   | 371/574 [00:40<00:21,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,464 INFO | INITIAL\n",
      "2021-05-27 16:55:35,464 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,469 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,471 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,472 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,473 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,473 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,495 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,496 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,556 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  65%|   | 372/574 [00:40<00:21,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,566 INFO | INITIAL\n",
      "2021-05-27 16:55:35,567 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,572 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,572 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,573 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,574 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,574 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,595 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,596 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,621 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,622 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,655 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,661 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,662 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,670 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  65%|   | 373/574 [00:40<00:21,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,681 INFO | INITIAL\n",
      "2021-05-27 16:55:35,681 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,686 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,687 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,688 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,691 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,692 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,700 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,720 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,727 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,733 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,734 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,755 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,761 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,763 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,780 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  65%|   | 374/574 [00:40<00:21,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,792 INFO | INITIAL\n",
      "2021-05-27 16:55:35,792 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,799 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,800 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,801 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,801 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,802 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,864 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,872 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,886 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  65%|   | 375/574 [00:41<00:21,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:35,898 INFO | INITIAL\n",
      "2021-05-27 16:55:35,899 INFO | (50, 200)\n",
      "2021-05-27 16:55:35,904 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:35,905 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,907 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:35,907 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:35,908 INFO | BERT LAYER\n",
      "2021-05-27 16:55:35,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,924 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,931 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,951 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:35,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:35,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:35,992 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 376/574 [00:41<00:21,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,001 INFO | INITIAL\n",
      "2021-05-27 16:55:36,002 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,006 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,007 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,008 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,009 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,010 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,057 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,058 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,094 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 377/574 [00:41<00:20,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,104 INFO | INITIAL\n",
      "2021-05-27 16:55:36,105 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,110 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,111 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,112 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,113 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,114 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,199 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 378/574 [00:41<00:20,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,209 INFO | INITIAL\n",
      "2021-05-27 16:55:36,210 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,215 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,216 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,217 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,217 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,218 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,282 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,289 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,305 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 379/574 [00:41<00:20,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,319 INFO | INITIAL\n",
      "2021-05-27 16:55:36,320 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,326 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,326 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,327 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,328 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,329 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,414 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 380/574 [00:41<00:20,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,425 INFO | INITIAL\n",
      "2021-05-27 16:55:36,425 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,432 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,432 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,433 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,434 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,435 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,490 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,491 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,491 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,522 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 381/574 [00:41<00:20,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,533 INFO | INITIAL\n",
      "2021-05-27 16:55:36,533 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,538 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,539 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,540 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,540 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,541 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,562 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,593 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,607 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,615 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,621 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,622 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,622 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  66%|   | 381/574 [00:41<00:20,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,631 INFO | INITIAL\n",
      "2021-05-27 16:55:36,631 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,636 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,637 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,638 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,639 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,639 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,727 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  67%|   | 383/574 [00:41<00:20,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,739 INFO | INITIAL\n",
      "2021-05-27 16:55:36,740 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,748 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,748 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,750 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,750 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,751 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,766 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,767 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,774 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,791 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,798 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,798 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,799 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,804 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,805 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,831 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  67%|   | 384/574 [00:42<00:19,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,841 INFO | INITIAL\n",
      "2021-05-27 16:55:36,842 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,848 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,849 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,851 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,851 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,852 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,864 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,872 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,931 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,940 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  67%|   | 385/574 [00:42<00:20,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:36,953 INFO | INITIAL\n",
      "2021-05-27 16:55:36,953 INFO | (50, 200)\n",
      "2021-05-27 16:55:36,958 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:36,958 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,960 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:36,961 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:36,961 INFO | BERT LAYER\n",
      "2021-05-27 16:55:36,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:36,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:36,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:36,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,008 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,041 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  67%|   | 385/574 [00:42<00:20,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,052 INFO | INITIAL\n",
      "2021-05-27 16:55:37,052 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,059 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,059 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,061 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,061 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,062 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,079 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,124 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,150 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  67%|   | 387/574 [00:42<00:19,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,162 INFO | INITIAL\n",
      "2021-05-27 16:55:37,162 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,168 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,168 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,170 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,170 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,171 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,241 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,257 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  68%|   | 388/574 [00:42<00:19,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,268 INFO | INITIAL\n",
      "2021-05-27 16:55:37,268 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,273 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,274 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,275 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,275 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,276 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,297 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,306 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,368 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  68%|   | 389/574 [00:42<00:19,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,379 INFO | INITIAL\n",
      "2021-05-27 16:55:37,379 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,384 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,385 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,386 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,386 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,387 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,395 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,426 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,475 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  68%|   | 390/574 [00:42<00:19,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,487 INFO | INITIAL\n",
      "2021-05-27 16:55:37,488 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,494 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,495 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,496 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,496 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,497 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,518 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,576 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  68%|   | 391/574 [00:42<00:19,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,588 INFO | INITIAL\n",
      "2021-05-27 16:55:37,588 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,594 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,594 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,596 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,596 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,597 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,634 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,635 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,642 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,643 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,652 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,685 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  68%|   | 392/574 [00:42<00:19,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,695 INFO | INITIAL\n",
      "2021-05-27 16:55:37,695 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,700 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,701 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,702 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,702 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,703 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,739 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,740 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,741 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,747 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,748 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,774 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,781 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  68%|   | 392/574 [00:42<00:19,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,792 INFO | INITIAL\n",
      "2021-05-27 16:55:37,792 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,798 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,799 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,800 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,800 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,801 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,810 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,828 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,843 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,844 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,844 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,861 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,875 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,883 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,884 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,891 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  69%|   | 394/574 [00:43<00:18,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:37,904 INFO | INITIAL\n",
      "2021-05-27 16:55:37,905 INFO | (50, 200)\n",
      "2021-05-27 16:55:37,911 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:37,912 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,913 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:37,914 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:37,915 INFO | BERT LAYER\n",
      "2021-05-27 16:55:37,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,918 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:37,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:37,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:37,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,004 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  69%|   | 395/574 [00:43<00:19,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,015 INFO | INITIAL\n",
      "2021-05-27 16:55:38,015 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,022 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,023 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,025 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,025 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,026 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,026 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,027 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,077 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,086 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,116 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,116 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  69%|   | 396/574 [00:43<00:19,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,129 INFO | INITIAL\n",
      "2021-05-27 16:55:38,129 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,135 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,135 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,137 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,142 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,191 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,192 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,217 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,218 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,225 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  69%|   | 397/574 [00:43<00:19,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,237 INFO | INITIAL\n",
      "2021-05-27 16:55:38,237 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,243 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,244 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,245 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,245 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,246 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,292 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,331 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  69%|   | 398/574 [00:43<00:18,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,341 INFO | INITIAL\n",
      "2021-05-27 16:55:38,341 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,349 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,349 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,350 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,351 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,352 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,391 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,426 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,444 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  70%|   | 399/574 [00:43<00:19,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,456 INFO | INITIAL\n",
      "2021-05-27 16:55:38,456 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,464 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,464 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,466 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,466 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,467 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,543 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,544 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,551 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  70%|   | 400/574 [00:43<00:19,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,565 INFO | INITIAL\n",
      "2021-05-27 16:55:38,565 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,570 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,571 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,572 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,573 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,574 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,574 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,575 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,591 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,662 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  70%|   | 401/574 [00:43<00:18,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,672 INFO | INITIAL\n",
      "2021-05-27 16:55:38,672 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,679 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,679 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,681 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,681 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,682 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,766 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  70%|   | 402/574 [00:43<00:18,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,777 INFO | INITIAL\n",
      "2021-05-27 16:55:38,777 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,783 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,783 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,784 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,785 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,785 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,861 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,869 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  70%|   | 403/574 [00:44<00:18,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,882 INFO | INITIAL\n",
      "2021-05-27 16:55:38,883 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,889 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,889 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,891 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,891 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,893 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,920 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,927 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,928 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,959 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,967 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,974 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  70%|   | 404/574 [00:44<00:17,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:38,985 INFO | INITIAL\n",
      "2021-05-27 16:55:38,985 INFO | (50, 200)\n",
      "2021-05-27 16:55:38,992 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:38,992 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,994 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:38,995 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:38,995 INFO | BERT LAYER\n",
      "2021-05-27 16:55:38,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:38,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:38,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:38,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,057 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,089 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  71%|   | 405/574 [00:44<00:18,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,099 INFO | INITIAL\n",
      "2021-05-27 16:55:39,100 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,105 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,105 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,106 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,107 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,107 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,116 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,147 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,148 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,193 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  71%|   | 406/574 [00:44<00:18,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,207 INFO | INITIAL\n",
      "2021-05-27 16:55:39,208 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,216 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,217 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,218 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,218 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,219 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,241 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,289 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,302 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,304 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  71%|   | 407/574 [00:44<00:23,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,417 INFO | INITIAL\n",
      "2021-05-27 16:55:39,418 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,424 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,424 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,426 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,426 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,428 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,495 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,495 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,510 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  71%|   | 408/574 [00:44<00:21,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,521 INFO | INITIAL\n",
      "2021-05-27 16:55:39,522 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,528 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,528 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,529 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,529 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,530 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,539 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,540 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,604 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,622 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  71%|  | 409/574 [00:44<00:20,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,632 INFO | INITIAL\n",
      "2021-05-27 16:55:39,632 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,638 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,638 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,640 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,640 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,641 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,641 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,701 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,722 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  71%|  | 410/574 [00:44<00:19,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,737 INFO | INITIAL\n",
      "2021-05-27 16:55:39,738 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,744 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,745 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,746 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,746 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,747 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,763 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,769 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,777 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,829 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,830 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,830 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  72%|  | 411/574 [00:45<00:18,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,840 INFO | INITIAL\n",
      "2021-05-27 16:55:39,840 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,847 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,847 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,848 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,849 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,850 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,875 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,933 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  72%|  | 412/574 [00:45<00:17,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:39,946 INFO | INITIAL\n",
      "2021-05-27 16:55:39,946 INFO | (50, 200)\n",
      "2021-05-27 16:55:39,951 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:39,951 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,953 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:39,953 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:39,954 INFO | BERT LAYER\n",
      "2021-05-27 16:55:39,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,987 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,988 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:39,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:39,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:39,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,026 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,027 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,033 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  72%|  | 412/574 [00:45<00:17,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,043 INFO | INITIAL\n",
      "2021-05-27 16:55:40,043 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,048 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,049 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,050 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,050 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,051 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,101 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,116 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,125 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,130 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,138 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  72%|  | 414/574 [00:45<00:17,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,150 INFO | INITIAL\n",
      "2021-05-27 16:55:40,150 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,157 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,157 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,159 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,160 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,160 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,162 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,189 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,190 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,242 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  72%|  | 415/574 [00:45<00:16,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,251 INFO | INITIAL\n",
      "2021-05-27 16:55:40,252 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,259 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,259 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,262 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,262 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,263 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,272 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,273 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,294 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,315 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,349 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  72%|  | 416/574 [00:45<00:16,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,359 INFO | INITIAL\n",
      "2021-05-27 16:55:40,360 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,366 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,367 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,368 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,368 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,369 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,369 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,370 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,411 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,412 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,455 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  73%|  | 417/574 [00:45<00:16,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,470 INFO | INITIAL\n",
      "2021-05-27 16:55:40,471 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,477 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,478 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,479 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,480 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,481 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,530 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,544 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,545 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,565 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  73%|  | 418/574 [00:45<00:16,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,576 INFO | INITIAL\n",
      "2021-05-27 16:55:40,576 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,582 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,582 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,583 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,584 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,585 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,609 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,625 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,655 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,663 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,664 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,682 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  73%|  | 419/574 [00:45<00:17,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,695 INFO | INITIAL\n",
      "2021-05-27 16:55:40,695 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,701 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,701 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,703 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,703 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,704 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,745 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,746 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,774 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,794 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  73%|  | 420/574 [00:45<00:17,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,807 INFO | INITIAL\n",
      "2021-05-27 16:55:40,807 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,815 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,815 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,816 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,817 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,818 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,850 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,858 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,899 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,900 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  73%|  | 421/574 [00:46<00:16,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:40,911 INFO | INITIAL\n",
      "2021-05-27 16:55:40,911 INFO | (50, 200)\n",
      "2021-05-27 16:55:40,917 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:40,917 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,919 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:40,920 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:40,922 INFO | BERT LAYER\n",
      "2021-05-27 16:55:40,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,924 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,924 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,971 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,972 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:40,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:40,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:40,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,014 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  74%|  | 422/574 [00:46<00:16,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,025 INFO | INITIAL\n",
      "2021-05-27 16:55:41,025 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,032 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,032 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,033 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,034 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,035 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,045 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,047 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,062 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,063 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,075 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,076 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,090 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,091 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,108 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,123 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  74%|  | 423/574 [00:46<00:16,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,135 INFO | INITIAL\n",
      "2021-05-27 16:55:41,135 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,141 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,142 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,143 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,144 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,189 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,224 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  74%|  | 424/574 [00:46<00:16,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,235 INFO | INITIAL\n",
      "2021-05-27 16:55:41,236 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,242 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,243 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,244 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,245 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,246 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,315 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,331 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  74%|  | 425/574 [00:46<00:16,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,343 INFO | INITIAL\n",
      "2021-05-27 16:55:41,343 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,348 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,349 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,350 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,351 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,351 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,380 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,411 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,412 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,419 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,437 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  74%|  | 426/574 [00:46<00:15,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,449 INFO | INITIAL\n",
      "2021-05-27 16:55:41,450 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,455 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,455 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,457 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,457 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,458 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,491 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,497 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,543 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  74%|  | 427/574 [00:46<00:15,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,554 INFO | INITIAL\n",
      "2021-05-27 16:55:41,555 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,561 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,562 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,563 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,564 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,565 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,572 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,573 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,647 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  75%|  | 428/574 [00:46<00:15,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,659 INFO | INITIAL\n",
      "2021-05-27 16:55:41,661 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,667 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,667 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,669 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,669 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,670 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,741 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,758 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  75%|  | 429/574 [00:46<00:15,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,769 INFO | INITIAL\n",
      "2021-05-27 16:55:41,770 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,775 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,775 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,776 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,777 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,778 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,786 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,810 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,868 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  75%|  | 430/574 [00:47<00:15,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,881 INFO | INITIAL\n",
      "2021-05-27 16:55:41,881 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,887 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,888 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,889 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,889 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,890 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,927 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,928 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,972 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  75%|  | 431/574 [00:47<00:15,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:41,984 INFO | INITIAL\n",
      "2021-05-27 16:55:41,985 INFO | (50, 200)\n",
      "2021-05-27 16:55:41,990 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:41,991 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,992 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:41,992 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:41,993 INFO | BERT LAYER\n",
      "2021-05-27 16:55:41,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:41,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:41,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:41,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,020 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,063 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,063 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,077 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,077 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  75%|  | 432/574 [00:47<00:15,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,087 INFO | INITIAL\n",
      "2021-05-27 16:55:42,087 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,094 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,094 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,096 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,096 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,097 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,127 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,141 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,142 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,155 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,177 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  75%|  | 433/574 [00:47<00:14,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,187 INFO | INITIAL\n",
      "2021-05-27 16:55:42,188 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,193 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,194 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,195 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,197 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,199 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,210 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,274 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,282 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,291 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  76%|  | 434/574 [00:47<00:15,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,302 INFO | INITIAL\n",
      "2021-05-27 16:55:42,303 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,308 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,309 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,310 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,311 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,312 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,359 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,396 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  76%|  | 435/574 [00:47<00:14,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,406 INFO | INITIAL\n",
      "2021-05-27 16:55:42,406 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,413 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,413 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,415 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,415 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,416 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,506 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  76%|  | 436/574 [00:47<00:14,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,517 INFO | INITIAL\n",
      "2021-05-27 16:55:42,518 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,524 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,525 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,528 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,528 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,529 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,539 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,540 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,588 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,605 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,612 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,621 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  76%|  | 437/574 [00:47<00:15,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,633 INFO | INITIAL\n",
      "2021-05-27 16:55:42,633 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,639 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,640 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,641 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,642 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,643 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,663 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,701 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,702 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,709 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,736 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  76%|  | 438/574 [00:47<00:15,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,747 INFO | INITIAL\n",
      "2021-05-27 16:55:42,747 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,752 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,753 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,754 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,755 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,756 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,848 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  76%|  | 439/574 [00:48<00:15,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,860 INFO | INITIAL\n",
      "2021-05-27 16:55:42,862 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,869 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,869 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,871 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,871 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,872 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,917 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,918 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,940 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,941 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,954 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  77%|  | 440/574 [00:48<00:14,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:42,966 INFO | INITIAL\n",
      "2021-05-27 16:55:42,967 INFO | (50, 200)\n",
      "2021-05-27 16:55:42,973 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:42,973 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,975 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:42,975 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:42,976 INFO | BERT LAYER\n",
      "2021-05-27 16:55:42,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,978 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:42,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:42,992 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:42,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,008 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,056 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  77%|  | 441/574 [00:48<00:14,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,069 INFO | INITIAL\n",
      "2021-05-27 16:55:43,069 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,075 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,076 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,077 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,078 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,079 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,091 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,106 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,107 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,171 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  77%|  | 442/574 [00:48<00:14,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,183 INFO | INITIAL\n",
      "2021-05-27 16:55:43,184 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,189 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,190 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,191 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,192 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,193 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,242 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,270 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,285 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  77%|  | 443/574 [00:48<00:14,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,296 INFO | INITIAL\n",
      "2021-05-27 16:55:43,296 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,301 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,302 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,304 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,304 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,305 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,373 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,374 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,395 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  77%|  | 444/574 [00:48<00:14,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,410 INFO | INITIAL\n",
      "2021-05-27 16:55:43,410 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,417 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,418 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,419 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,419 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,420 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,435 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,436 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,442 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,443 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,495 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,496 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,504 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  78%|  | 445/574 [00:48<00:14,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,515 INFO | INITIAL\n",
      "2021-05-27 16:55:43,515 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,521 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,521 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,522 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,523 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,523 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,541 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,547 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,548 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,554 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,555 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,611 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  78%|  | 446/574 [00:48<00:13,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,623 INFO | INITIAL\n",
      "2021-05-27 16:55:43,624 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,631 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,632 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,633 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,634 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,635 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,635 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,643 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,643 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,698 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,715 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  78%|  | 447/574 [00:48<00:13,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,725 INFO | INITIAL\n",
      "2021-05-27 16:55:43,725 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,732 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,733 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,734 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,735 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,735 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,761 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,769 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,825 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  78%|  | 448/574 [00:49<00:13,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,835 INFO | INITIAL\n",
      "2021-05-27 16:55:43,836 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,842 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,843 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,844 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,844 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,845 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,864 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,865 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,872 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,905 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,930 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  78%|  | 449/574 [00:49<00:13,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:43,942 INFO | INITIAL\n",
      "2021-05-27 16:55:43,943 INFO | (50, 200)\n",
      "2021-05-27 16:55:43,948 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:43,949 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,950 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:43,950 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:43,951 INFO | BERT LAYER\n",
      "2021-05-27 16:55:43,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,953 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:43,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:43,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:43,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,026 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,027 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,035 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  78%|  | 450/574 [00:49<00:13,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,049 INFO | INITIAL\n",
      "2021-05-27 16:55:44,050 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,055 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,055 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,057 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,057 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,059 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,077 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,086 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,116 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,130 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,146 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,148 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  79%|  | 451/574 [00:49<00:13,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,158 INFO | INITIAL\n",
      "2021-05-27 16:55:44,160 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,165 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,166 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,167 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,168 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,169 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,201 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,256 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  79%|  | 452/574 [00:49<00:13,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,270 INFO | INITIAL\n",
      "2021-05-27 16:55:44,270 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,276 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,277 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,278 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,278 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,279 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,286 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,287 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,306 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,342 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,343 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,356 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,357 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,357 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  79%|  | 452/574 [00:49<00:13,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,369 INFO | INITIAL\n",
      "2021-05-27 16:55:44,370 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,375 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,375 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,377 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,377 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,378 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,419 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,427 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,467 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  79%|  | 454/574 [00:49<00:12,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,478 INFO | INITIAL\n",
      "2021-05-27 16:55:44,479 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,484 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,484 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,485 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,486 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,487 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,500 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,572 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,573 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,574 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  79%|  | 455/574 [00:49<00:12,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,586 INFO | INITIAL\n",
      "2021-05-27 16:55:44,586 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,593 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,594 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,595 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,596 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,597 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,599 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,607 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,630 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,685 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  79%|  | 456/574 [00:49<00:12,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,697 INFO | INITIAL\n",
      "2021-05-27 16:55:44,698 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,704 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,704 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,705 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,706 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,707 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,709 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,773 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,779 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,780 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,789 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  80%|  | 457/574 [00:49<00:12,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,804 INFO | INITIAL\n",
      "2021-05-27 16:55:44,805 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,811 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,811 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,812 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,813 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,813 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,815 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,824 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,870 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,871 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,884 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,890 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,900 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  80%|  | 458/574 [00:50<00:12,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:44,916 INFO | INITIAL\n",
      "2021-05-27 16:55:44,917 INFO | (50, 200)\n",
      "2021-05-27 16:55:44,922 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:44,922 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,924 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:44,924 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:44,925 INFO | BERT LAYER\n",
      "2021-05-27 16:55:44,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,959 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,960 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,967 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:44,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:44,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:44,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,011 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  80%|  | 459/574 [00:50<00:12,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,022 INFO | INITIAL\n",
      "2021-05-27 16:55:45,022 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,029 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,030 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,031 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,031 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,032 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,034 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,086 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,108 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,115 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  80%|  | 460/574 [00:50<00:12,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,128 INFO | INITIAL\n",
      "2021-05-27 16:55:45,128 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,135 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,136 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,137 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,138 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,138 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,140 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,146 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,182 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,214 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,215 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,224 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  80%|  | 461/574 [00:50<00:12,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,234 INFO | INITIAL\n",
      "2021-05-27 16:55:45,235 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,239 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,240 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,241 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,242 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,243 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,341 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,342 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,342 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  80%|  | 462/574 [00:50<00:12,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,352 INFO | INITIAL\n",
      "2021-05-27 16:55:45,353 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,359 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,360 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,362 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,362 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,363 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,373 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,373 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,374 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,395 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,417 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,442 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,450 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  81%|  | 463/574 [00:50<00:12,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,462 INFO | INITIAL\n",
      "2021-05-27 16:55:45,462 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,470 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,471 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,472 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,472 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,473 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,494 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,523 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,530 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,561 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  81%|  | 464/574 [00:50<00:12,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,572 INFO | INITIAL\n",
      "2021-05-27 16:55:45,573 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,579 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,580 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,581 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,581 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,582 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,608 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,668 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  81%|  | 465/574 [00:50<00:11,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,681 INFO | INITIAL\n",
      "2021-05-27 16:55:45,683 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,688 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,689 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,690 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,691 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,692 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,722 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,734 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,734 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,742 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,766 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,767 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,776 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  81%|  | 466/574 [00:50<00:11,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,786 INFO | INITIAL\n",
      "2021-05-27 16:55:45,786 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,791 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,792 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,793 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,793 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,794 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,870 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,877 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,878 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  81%| | 467/574 [00:51<00:11,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:45,889 INFO | INITIAL\n",
      "2021-05-27 16:55:45,891 INFO | (50, 200)\n",
      "2021-05-27 16:55:45,900 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:45,901 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,903 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:45,903 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:45,904 INFO | BERT LAYER\n",
      "2021-05-27 16:55:45,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,905 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,923 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,929 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,930 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,951 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,952 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,959 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,965 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,966 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:45,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:45,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:45,989 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  82%| | 468/574 [00:51<00:11,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,000 INFO | INITIAL\n",
      "2021-05-27 16:55:46,001 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,007 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,007 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,009 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,009 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,010 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,026 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,098 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  82%| | 469/574 [00:51<00:11,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,110 INFO | INITIAL\n",
      "2021-05-27 16:55:46,110 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,116 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,116 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,117 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,118 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,119 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,140 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,141 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,148 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,156 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,157 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,158 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,166 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,172 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,172 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,173 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,173 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,180 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,191 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,192 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,200 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  82%| | 470/574 [00:51<00:11,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,213 INFO | INITIAL\n",
      "2021-05-27 16:55:46,213 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,220 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,221 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,222 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,223 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,224 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,282 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,293 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,308 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  82%| | 471/574 [00:51<00:10,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,317 INFO | INITIAL\n",
      "2021-05-27 16:55:46,318 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,323 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,323 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,324 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,325 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,325 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,342 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,356 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,380 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,381 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,381 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,411 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  82%| | 472/574 [00:51<00:10,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,421 INFO | INITIAL\n",
      "2021-05-27 16:55:46,422 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,428 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,429 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,430 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,430 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,431 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,460 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,469 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,476 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,477 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,477 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,491 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,515 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  82%| | 473/574 [00:51<00:10,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,526 INFO | INITIAL\n",
      "2021-05-27 16:55:46,526 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,533 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,534 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,535 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,536 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,537 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,538 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,545 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,546 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,559 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,593 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,615 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,624 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  83%| | 474/574 [00:51<00:10,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,636 INFO | INITIAL\n",
      "2021-05-27 16:55:46,636 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,643 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,643 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,645 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,645 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,646 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,654 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,655 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,655 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,662 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,664 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,677 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,701 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,708 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,708 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,730 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  83%| | 475/574 [00:51<00:10,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,741 INFO | INITIAL\n",
      "2021-05-27 16:55:46,741 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,748 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,749 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,750 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,751 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,751 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,791 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,812 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,813 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,834 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  83%| | 476/574 [00:52<00:10,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,845 INFO | INITIAL\n",
      "2021-05-27 16:55:46,845 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,851 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,852 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,853 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,854 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,855 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,864 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,907 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,935 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  83%| | 477/574 [00:52<00:10,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:46,948 INFO | INITIAL\n",
      "2021-05-27 16:55:46,949 INFO | (50, 200)\n",
      "2021-05-27 16:55:46,954 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:46,954 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,956 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:46,956 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:46,957 INFO | BERT LAYER\n",
      "2021-05-27 16:55:46,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,965 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,966 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,967 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,974 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,981 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,982 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:46,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:46,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:46,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,015 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,015 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,037 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,046 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  83%| | 478/574 [00:52<00:10,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,056 INFO | INITIAL\n",
      "2021-05-27 16:55:47,057 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,063 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,063 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,065 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,065 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,066 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,068 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,069 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,075 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,076 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,107 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,107 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,113 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,114 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,150 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,151 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  83%| | 479/574 [00:52<00:10,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,165 INFO | INITIAL\n",
      "2021-05-27 16:55:47,165 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,171 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,171 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,172 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,173 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,174 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,201 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,202 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,218 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,260 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  84%| | 480/574 [00:52<00:10,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,271 INFO | INITIAL\n",
      "2021-05-27 16:55:47,272 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,278 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,278 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,280 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,281 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,282 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,283 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,284 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,291 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,293 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,315 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,321 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,369 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,370 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,370 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  84%| | 481/574 [00:52<00:10,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,382 INFO | INITIAL\n",
      "2021-05-27 16:55:47,382 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,387 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,387 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,388 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,389 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,390 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,391 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,420 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,445 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,452 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,477 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  84%| | 482/574 [00:52<00:09,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,489 INFO | INITIAL\n",
      "2021-05-27 16:55:47,490 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,498 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,499 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,501 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,502 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,503 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,518 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,541 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,571 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,572 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,584 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,586 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  84%| | 483/574 [00:52<00:09,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,596 INFO | INITIAL\n",
      "2021-05-27 16:55:47,597 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,604 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,604 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,606 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,606 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,607 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,608 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,618 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,619 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,630 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,652 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,696 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  84%| | 484/574 [00:52<00:09,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,707 INFO | INITIAL\n",
      "2021-05-27 16:55:47,707 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,714 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,715 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,716 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,716 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,717 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,777 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,789 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,796 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  84%| | 484/574 [00:52<00:09,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,807 INFO | INITIAL\n",
      "2021-05-27 16:55:47,807 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,813 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,813 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,815 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,815 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,816 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,850 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,851 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,851 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,858 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,904 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  85%| | 486/574 [00:53<00:09,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:47,915 INFO | INITIAL\n",
      "2021-05-27 16:55:47,916 INFO | (50, 200)\n",
      "2021-05-27 16:55:47,923 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:47,923 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,924 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:47,925 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:47,926 INFO | BERT LAYER\n",
      "2021-05-27 16:55:47,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,927 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:47,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:47,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:47,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,004 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  85%| | 487/574 [00:53<00:09,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,018 INFO | INITIAL\n",
      "2021-05-27 16:55:48,019 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,027 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,027 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,029 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,029 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,030 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,030 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,038 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,039 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,045 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,045 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,046 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,057 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,058 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,058 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,074 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,112 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  85%| | 488/574 [00:53<00:09,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,123 INFO | INITIAL\n",
      "2021-05-27 16:55:48,123 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,129 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,130 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,131 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,131 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,132 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,141 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,142 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,149 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,156 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,156 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,157 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,211 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,219 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,221 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  85%| | 489/574 [00:53<00:09,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,234 INFO | INITIAL\n",
      "2021-05-27 16:55:48,234 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,240 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,240 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,242 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,243 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,244 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,259 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,267 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,274 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,289 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,290 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,290 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,307 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,314 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,327 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  85%| | 490/574 [00:53<00:08,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,339 INFO | INITIAL\n",
      "2021-05-27 16:55:48,339 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,346 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,346 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,348 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,348 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,349 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,351 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,357 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,360 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,366 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,366 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,374 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,389 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,396 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,409 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,429 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  86%| | 491/574 [00:53<00:08,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,443 INFO | INITIAL\n",
      "2021-05-27 16:55:48,443 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,449 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,449 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,450 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,451 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,452 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,452 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,459 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,460 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,460 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,467 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,532 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  86%| | 492/574 [00:53<00:08,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,544 INFO | INITIAL\n",
      "2021-05-27 16:55:48,545 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,549 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,550 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,551 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,553 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,578 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,579 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,579 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,593 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,608 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,609 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,625 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,641 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  86%| | 493/574 [00:53<00:08,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,654 INFO | INITIAL\n",
      "2021-05-27 16:55:48,655 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,660 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,661 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,662 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,663 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,664 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,680 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,687 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,700 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,751 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,751 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  86%| | 494/574 [00:53<00:08,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,762 INFO | INITIAL\n",
      "2021-05-27 16:55:48,763 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,775 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,776 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,777 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,778 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,779 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,786 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,813 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,832 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,864 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,879 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,881 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  86%| | 495/574 [00:54<00:08,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,891 INFO | INITIAL\n",
      "2021-05-27 16:55:48,892 INFO | (50, 200)\n",
      "2021-05-27 16:55:48,899 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:48,900 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,901 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:48,901 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:48,902 INFO | BERT LAYER\n",
      "2021-05-27 16:55:48,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,962 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,974 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,975 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,981 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:48,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:48,982 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:48,982 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  86%| | 496/574 [00:54<00:08,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:48,994 INFO | INITIAL\n",
      "2021-05-27 16:55:48,995 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,003 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,003 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,005 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,006 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,007 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,007 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,066 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,089 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  87%| | 497/574 [00:54<00:08,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,099 INFO | INITIAL\n",
      "2021-05-27 16:55:49,099 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,105 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,105 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,106 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,107 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,107 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,162 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,182 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,190 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  87%| | 498/574 [00:54<00:08,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,201 INFO | INITIAL\n",
      "2021-05-27 16:55:49,203 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,208 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,209 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,210 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,210 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,211 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,257 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,266 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,275 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,298 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  87%| | 499/574 [00:54<00:08,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,309 INFO | INITIAL\n",
      "2021-05-27 16:55:49,309 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,315 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,315 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,317 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,317 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,318 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,356 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,363 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,397 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,398 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,399 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  87%| | 500/574 [00:54<00:07,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,411 INFO | INITIAL\n",
      "2021-05-27 16:55:49,411 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,417 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,417 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,419 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,419 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,420 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,445 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,487 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,503 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  87%| | 501/574 [00:54<00:07,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,515 INFO | INITIAL\n",
      "2021-05-27 16:55:49,515 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,520 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,521 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,522 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,523 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,523 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,524 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,532 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,541 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,553 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,553 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,554 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,591 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,591 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,605 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,606 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  87%| | 502/574 [00:54<00:07,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,618 INFO | INITIAL\n",
      "2021-05-27 16:55:49,618 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,624 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,625 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,626 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,626 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,627 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,628 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,645 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,691 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,712 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  88%| | 503/574 [00:54<00:07,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,723 INFO | INITIAL\n",
      "2021-05-27 16:55:49,724 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,730 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,731 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,732 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,733 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,734 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,758 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,780 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,786 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,787 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,794 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,817 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  88%| | 504/574 [00:55<00:07,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,829 INFO | INITIAL\n",
      "2021-05-27 16:55:49,830 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,834 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,835 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,837 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,838 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,839 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,840 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,840 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,848 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,864 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,922 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  88%| | 505/574 [00:55<00:07,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:49,935 INFO | INITIAL\n",
      "2021-05-27 16:55:49,936 INFO | (50, 200)\n",
      "2021-05-27 16:55:49,943 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:49,944 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,945 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:49,946 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:49,947 INFO | BERT LAYER\n",
      "2021-05-27 16:55:49,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:49,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:49,998 INFO | (200, 512)\n",
      "2021-05-27 16:55:49,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,017 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,019 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,026 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,031 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,032 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  88%| | 506/574 [00:55<00:07,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,043 INFO | INITIAL\n",
      "2021-05-27 16:55:50,044 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,049 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,049 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,051 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,051 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,052 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,053 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,059 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,060 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,078 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,087 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,111 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,133 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,144 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  88%| | 507/574 [00:55<00:07,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,156 INFO | INITIAL\n",
      "2021-05-27 16:55:50,157 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,165 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,165 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,166 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,167 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,168 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,182 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,182 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,189 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,195 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,212 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,213 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,220 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,227 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,228 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,248 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  89%| | 508/574 [00:55<00:07,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,258 INFO | INITIAL\n",
      "2021-05-27 16:55:50,258 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,265 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,266 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,268 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,268 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,269 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,280 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,286 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,287 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,287 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,294 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,309 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,321 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,328 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,329 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,343 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,351 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  89%| | 509/574 [00:55<00:06,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,365 INFO | INITIAL\n",
      "2021-05-27 16:55:50,366 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,373 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,373 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,374 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,375 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,376 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,377 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,377 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,383 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,384 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,384 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,389 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,390 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,390 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,397 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,404 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,411 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,412 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,412 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,413 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,419 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,420 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,444 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,445 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,450 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,458 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  89%| | 510/574 [00:55<00:06,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,471 INFO | INITIAL\n",
      "2021-05-27 16:55:50,472 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,477 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,478 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,479 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,480 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,481 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,501 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,502 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,515 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,569 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  89%| | 511/574 [00:55<00:06,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,580 INFO | INITIAL\n",
      "2021-05-27 16:55:50,580 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,586 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,586 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,587 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,588 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,589 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,607 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,613 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,614 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,615 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,622 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,622 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,623 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,631 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,646 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,676 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  89%| | 512/574 [00:55<00:06,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,692 INFO | INITIAL\n",
      "2021-05-27 16:55:50,692 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,700 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,701 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,702 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,703 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,703 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,711 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,779 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,786 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  89%| | 513/574 [00:55<00:06,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,795 INFO | INITIAL\n",
      "2021-05-27 16:55:50,796 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,802 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,803 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,804 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,805 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,806 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,834 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,835 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,841 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,850 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,850 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,857 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,863 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,864 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,864 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,872 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,880 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,885 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,892 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,893 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  90%| | 514/574 [00:56<00:06,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:50,906 INFO | INITIAL\n",
      "2021-05-27 16:55:50,906 INFO | (50, 200)\n",
      "2021-05-27 16:55:50,913 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:50,913 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,915 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:50,916 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:50,917 INFO | BERT LAYER\n",
      "2021-05-27 16:55:50,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,918 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,947 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,953 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,972 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,979 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,980 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,980 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:50,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:50,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:50,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,003 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  90%| | 515/574 [00:56<00:06,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,014 INFO | INITIAL\n",
      "2021-05-27 16:55:51,015 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,020 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,020 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,022 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,022 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,023 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,023 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,072 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,078 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,079 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,110 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  90%| | 516/574 [00:56<00:06,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,121 INFO | INITIAL\n",
      "2021-05-27 16:55:51,122 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,127 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,128 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,129 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,129 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,130 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,139 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,146 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,147 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,184 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,207 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,214 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  90%| | 517/574 [00:56<00:06,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,225 INFO | INITIAL\n",
      "2021-05-27 16:55:51,226 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,232 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,233 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,234 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,234 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,235 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,251 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,260 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,261 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,270 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,284 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,284 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,285 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,297 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,317 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  90%| | 518/574 [00:56<00:05,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,328 INFO | INITIAL\n",
      "2021-05-27 16:55:51,328 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,334 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,335 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,336 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,337 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,338 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,339 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,340 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,356 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,357 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,358 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,365 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,391 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,426 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  90%| | 519/574 [00:56<00:05,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,437 INFO | INITIAL\n",
      "2021-05-27 16:55:51,437 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,442 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,443 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,444 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,444 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,445 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,446 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,447 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,447 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,455 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,463 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,497 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,498 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,504 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,505 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,518 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,534 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  91%| | 520/574 [00:56<00:05,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,549 INFO | INITIAL\n",
      "2021-05-27 16:55:51,550 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,555 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,556 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,557 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,558 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,560 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,560 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,561 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,561 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,562 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,571 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,578 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,586 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,592 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,598 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,599 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,606 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,607 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,614 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,614 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,615 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,616 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,641 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,648 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,649 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  91%| | 521/574 [00:56<00:05,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,658 INFO | INITIAL\n",
      "2021-05-27 16:55:51,658 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,665 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,666 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,667 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,668 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,669 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,678 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,679 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,679 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,685 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,686 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,686 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,694 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,717 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,724 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,752 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,752 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  91%| | 522/574 [00:56<00:05,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,766 INFO | INITIAL\n",
      "2021-05-27 16:55:51,766 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,773 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,774 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,775 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,775 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,776 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,791 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,796 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,797 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,824 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,854 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  91%| | 523/574 [00:57<00:05,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,866 INFO | INITIAL\n",
      "2021-05-27 16:55:51,866 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,872 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,872 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,874 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,874 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,875 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,877 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,887 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,894 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,917 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,965 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  91%|| 524/574 [00:57<00:05,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:51,974 INFO | INITIAL\n",
      "2021-05-27 16:55:51,974 INFO | (50, 200)\n",
      "2021-05-27 16:55:51,978 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:51,979 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,980 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:51,981 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:51,982 INFO | BERT LAYER\n",
      "2021-05-27 16:55:51,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,990 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:51,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:51,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:51,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,062 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  91%|| 524/574 [00:57<00:05,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,072 INFO | INITIAL\n",
      "2021-05-27 16:55:52,073 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,079 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,080 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,081 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,082 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,083 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,084 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,084 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,085 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,091 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,092 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,117 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,118 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,124 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,125 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,130 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,131 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,131 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,132 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,138 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,146 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,170 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  92%|| 526/574 [00:57<00:05,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,183 INFO | INITIAL\n",
      "2021-05-27 16:55:52,184 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,189 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,189 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,191 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,191 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,192 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,194 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,223 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,241 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,243 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,273 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  92%|| 527/574 [00:57<00:04,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,285 INFO | INITIAL\n",
      "2021-05-27 16:55:52,285 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,290 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,291 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,292 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,293 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,293 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,294 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,294 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,310 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,352 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,367 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,387 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  92%|| 528/574 [00:57<00:04,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,398 INFO | INITIAL\n",
      "2021-05-27 16:55:52,399 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,404 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,404 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,406 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,406 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,407 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,410 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,411 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,418 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,426 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,432 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,433 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,484 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,490 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,491 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,491 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,497 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,498 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  92%|| 529/574 [00:57<00:04,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,509 INFO | INITIAL\n",
      "2021-05-27 16:55:52,509 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,515 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,516 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,517 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,517 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,518 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,526 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,541 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,548 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,601 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  92%|| 530/574 [00:57<00:04,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,615 INFO | INITIAL\n",
      "2021-05-27 16:55:52,615 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,622 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,622 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,627 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,628 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,629 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,632 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,633 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,655 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,656 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,657 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,663 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,664 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,665 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,672 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,673 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,681 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,688 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,695 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,702 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,703 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,709 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,710 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,710 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,717 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  93%|| 531/574 [00:57<00:04,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,727 INFO | INITIAL\n",
      "2021-05-27 16:55:52,727 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,732 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,733 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,734 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,734 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,735 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,777 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,817 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  93%|| 532/574 [00:58<00:04,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,827 INFO | INITIAL\n",
      "2021-05-27 16:55:52,827 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,834 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,835 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,836 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,837 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,838 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,895 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,915 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,916 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  93%|| 532/574 [00:58<00:04,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:52,925 INFO | INITIAL\n",
      "2021-05-27 16:55:52,926 INFO | (50, 200)\n",
      "2021-05-27 16:55:52,932 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:52,933 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,934 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:52,934 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:52,935 INFO | BERT LAYER\n",
      "2021-05-27 16:55:52,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,936 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,937 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,938 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,951 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,952 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,964 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,979 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,979 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,980 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,986 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:52,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:52,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:52,997 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,004 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,023 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  93%|| 534/574 [00:58<00:04,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,034 INFO | INITIAL\n",
      "2021-05-27 16:55:53,034 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,039 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,040 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,041 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,042 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,043 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,052 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,053 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,053 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,060 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,068 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,069 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,069 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,078 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,079 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,086 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,087 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,093 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,100 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,101 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,102 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,106 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,107 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,113 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,113 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,114 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,127 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,127 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  93%|| 535/574 [00:58<00:04,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,138 INFO | INITIAL\n",
      "2021-05-27 16:55:53,140 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,148 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,148 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,150 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,150 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,151 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,167 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,167 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,168 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,189 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,189 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,190 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,197 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,197 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,230 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,236 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  93%|| 536/574 [00:58<00:04,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,248 INFO | INITIAL\n",
      "2021-05-27 16:55:53,248 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,253 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,253 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,255 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,255 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,256 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,271 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,296 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,303 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,304 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,311 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,317 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,339 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  94%|| 537/574 [00:58<00:03,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,351 INFO | INITIAL\n",
      "2021-05-27 16:55:53,352 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,357 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,358 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,359 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,360 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,360 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,376 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,383 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,394 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,399 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,400 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,407 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,437 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  94%|| 537/574 [00:58<00:03,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,448 INFO | INITIAL\n",
      "2021-05-27 16:55:53,449 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,453 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,454 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,455 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,455 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,456 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,463 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,464 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,470 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,479 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,485 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,485 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,486 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,491 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,499 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,506 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,521 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,535 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  94%|| 539/574 [00:58<00:03,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,546 INFO | INITIAL\n",
      "2021-05-27 16:55:53,546 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,552 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,553 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,554 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,555 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,613 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,637 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  94%|| 540/574 [00:58<00:03,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,650 INFO | INITIAL\n",
      "2021-05-27 16:55:53,650 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,655 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,655 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,656 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,657 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,658 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,659 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,696 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,711 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,720 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,721 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,729 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,735 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,743 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,744 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  94%|| 541/574 [00:58<00:03,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,755 INFO | INITIAL\n",
      "2021-05-27 16:55:53,756 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,763 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,764 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,765 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,765 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,766 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,766 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,793 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,823 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,824 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,831 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,847 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,853 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  94%|| 542/574 [00:59<00:03,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,867 INFO | INITIAL\n",
      "2021-05-27 16:55:53,867 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,874 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,874 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,876 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,876 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,878 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,905 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,925 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,966 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  95%|| 543/574 [00:59<00:03,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:53,976 INFO | INITIAL\n",
      "2021-05-27 16:55:53,976 INFO | (50, 200)\n",
      "2021-05-27 16:55:53,982 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:53,983 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,984 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:53,985 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:53,986 INFO | BERT LAYER\n",
      "2021-05-27 16:55:53,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,987 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:53,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:53,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:53,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,011 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,019 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,044 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,051 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,064 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,071 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,072 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  95%|| 544/574 [00:59<00:03,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,087 INFO | INITIAL\n",
      "2021-05-27 16:55:54,088 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,093 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,094 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,095 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,096 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,097 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,099 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,105 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,106 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,106 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,113 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,114 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,121 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,126 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,127 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,134 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,160 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,168 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,186 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  95%|| 545/574 [00:59<00:03,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,198 INFO | INITIAL\n",
      "2021-05-27 16:55:54,198 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,203 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,204 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,205 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,206 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,207 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,207 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,235 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,242 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,242 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,268 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,279 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,292 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,295 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  95%|| 546/574 [00:59<00:03,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,308 INFO | INITIAL\n",
      "2021-05-27 16:55:54,309 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,316 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,317 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,318 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,318 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,319 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,327 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,339 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,340 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,348 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,348 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,348 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,370 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,370 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,388 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,401 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,402 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  95%|| 547/574 [00:59<00:02,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,413 INFO | INITIAL\n",
      "2021-05-27 16:55:54,413 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,419 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,419 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,420 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,420 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,421 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,431 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,438 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,466 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,474 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,496 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,503 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,511 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,512 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,512 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  95%|| 548/574 [00:59<00:02,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,525 INFO | INITIAL\n",
      "2021-05-27 16:55:54,526 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,533 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,533 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,535 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,535 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,536 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,537 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,547 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,555 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,562 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,569 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,584 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,584 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,585 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,592 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,593 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,626 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,627 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,628 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  96%|| 549/574 [00:59<00:02,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,639 INFO | INITIAL\n",
      "2021-05-27 16:55:54,639 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,646 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,647 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,648 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,648 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,649 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,657 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,674 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,698 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,720 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,727 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,737 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  96%|| 550/574 [00:59<00:02,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,751 INFO | INITIAL\n",
      "2021-05-27 16:55:54,751 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,759 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,759 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,760 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,761 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,762 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,764 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,771 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,772 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,778 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,791 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,805 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,806 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,814 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,814 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,815 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,821 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,821 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,822 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,822 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,828 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,842 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,843 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,843 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,844 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  96%|| 551/574 [01:00<00:02,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,855 INFO | INITIAL\n",
      "2021-05-27 16:55:54,855 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,862 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,863 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,864 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,864 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,865 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,873 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,874 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,875 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,890 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,891 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,930 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,937 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,944 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,945 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,951 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,952 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,952 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  96%|| 552/574 [01:00<00:02,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:54,965 INFO | INITIAL\n",
      "2021-05-27 16:55:54,966 INFO | (50, 200)\n",
      "2021-05-27 16:55:54,971 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:54,972 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,973 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:54,974 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:54,975 INFO | BERT LAYER\n",
      "2021-05-27 16:55:54,975 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:54,993 INFO | (200, 512)\n",
      "2021-05-27 16:55:54,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:54,994 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,001 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,008 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,033 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,040 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,056 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,065 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,066 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  96%|| 553/574 [01:00<00:02,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,076 INFO | INITIAL\n",
      "2021-05-27 16:55:55,076 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,084 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,084 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,085 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,086 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,086 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,087 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,093 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,094 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,094 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,095 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,100 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,100 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,101 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,101 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,106 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,107 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,107 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,113 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,114 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,114 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,121 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,128 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,129 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,130 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,151 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,158 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,159 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,165 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,167 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  97%|| 554/574 [01:00<00:02,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,177 INFO | INITIAL\n",
      "2021-05-27 16:55:55,177 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,182 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,183 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,184 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,184 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,185 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,193 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,205 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,249 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,255 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,256 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,264 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,270 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  97%|| 555/574 [01:00<00:02,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,283 INFO | INITIAL\n",
      "2021-05-27 16:55:55,284 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,290 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,291 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,292 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,293 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,294 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,295 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,297 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,308 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,315 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,321 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,321 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,322 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,322 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,327 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,328 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,328 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,334 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,335 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,341 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,341 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,342 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,342 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,349 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,349 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,350 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,350 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,356 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,356 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,357 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,363 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,364 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,365 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,387 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  97%|| 556/574 [01:00<00:01,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,399 INFO | INITIAL\n",
      "2021-05-27 16:55:55,399 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,404 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,404 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,405 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,406 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,406 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,407 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,423 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,436 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,453 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,461 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,462 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,468 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,469 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,475 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,476 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,490 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  97%|| 557/574 [01:00<00:01,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,501 INFO | INITIAL\n",
      "2021-05-27 16:55:55,501 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,508 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,509 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,510 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,511 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,512 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,514 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,522 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,528 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,529 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,536 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,543 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,544 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,544 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,552 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,558 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,565 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,572 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,572 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,573 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,598 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  97%|| 558/574 [01:00<00:01,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,609 INFO | INITIAL\n",
      "2021-05-27 16:55:55,610 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,619 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,620 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,621 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,622 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,623 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,623 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,624 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,625 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,631 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,631 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,632 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,632 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,638 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,643 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,644 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,662 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,662 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,662 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,663 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,685 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,692 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,698 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,707 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  97%|| 559/574 [01:00<00:01,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,716 INFO | INITIAL\n",
      "2021-05-27 16:55:55,717 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,723 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,723 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,726 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,726 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,727 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,728 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,729 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,729 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,736 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,736 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,737 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,746 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,747 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,761 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,767 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,783 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,789 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,790 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,804 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,812 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,812 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,813 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,814 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  98%|| 560/574 [01:01<00:01,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,828 INFO | INITIAL\n",
      "2021-05-27 16:55:55,829 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,834 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,835 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,836 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,836 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,837 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,838 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,839 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,846 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,873 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,882 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,891 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,892 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,899 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,905 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,906 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,913 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,919 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,920 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,920 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  98%|| 561/574 [01:01<00:01,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:55,931 INFO | INITIAL\n",
      "2021-05-27 16:55:55,932 INFO | (50, 200)\n",
      "2021-05-27 16:55:55,936 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:55,936 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,938 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:55,938 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:55,939 INFO | BERT LAYER\n",
      "2021-05-27 16:55:55,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,940 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,941 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,948 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,954 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,954 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,955 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,979 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,979 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,980 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,986 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,987 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,987 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:55,995 INFO | (200, 512)\n",
      "2021-05-27 16:55:55,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:55,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,002 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,008 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,018 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,025 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,026 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  98%|| 562/574 [01:01<00:01,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,036 INFO | INITIAL\n",
      "2021-05-27 16:55:56,037 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,043 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,044 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,045 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,046 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,047 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,047 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,047 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,048 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,058 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,059 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,073 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,083 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,103 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,109 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,110 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,110 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,127 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,137 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  98%|| 563/574 [01:01<00:01,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,152 INFO | INITIAL\n",
      "2021-05-27 16:55:56,152 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,157 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,158 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,160 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,160 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,161 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,163 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,171 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,178 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,179 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,191 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,192 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,200 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,208 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,218 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,224 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,231 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,231 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,238 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,245 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  98%|| 564/574 [01:01<00:01,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,255 INFO | INITIAL\n",
      "2021-05-27 16:55:56,255 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,261 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,261 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,263 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,263 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,264 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,265 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,266 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,266 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,272 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,273 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,283 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,291 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,313 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,314 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,320 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,324 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,344 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,345 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  98%|| 565/574 [01:01<00:00,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,356 INFO | INITIAL\n",
      "2021-05-27 16:55:56,356 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,363 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,363 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,364 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,365 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,366 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,367 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,378 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,408 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,434 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,441 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,441 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,447 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,448 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,449 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  99%|| 566/574 [01:01<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,460 INFO | INITIAL\n",
      "2021-05-27 16:55:56,461 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,468 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,468 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,470 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,470 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,471 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,488 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,510 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,533 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,558 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  99%|| 567/574 [01:01<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,569 INFO | INITIAL\n",
      "2021-05-27 16:55:56,570 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,575 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,577 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,579 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,579 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,580 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,580 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,581 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,587 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,594 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,595 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,602 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,611 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,621 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,629 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,630 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,635 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,636 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,636 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,637 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,642 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,642 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,643 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,665 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  99%|| 568/574 [01:01<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,676 INFO | INITIAL\n",
      "2021-05-27 16:55:56,676 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,683 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,684 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,686 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,687 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,688 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,689 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,691 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,714 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,715 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,715 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,716 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,722 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,723 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,723 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,730 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,731 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,737 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,738 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,744 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,745 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,753 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,754 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,761 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,769 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,776 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  99%|| 569/574 [01:01<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,787 INFO | INITIAL\n",
      "2021-05-27 16:55:56,787 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,792 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,792 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,794 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,794 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,794 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,796 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,797 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,797 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,809 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,816 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,817 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,825 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,834 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,835 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,849 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,855 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,856 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,868 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,868 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,875 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,877 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  99%|| 570/574 [01:02<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,887 INFO | INITIAL\n",
      "2021-05-27 16:55:56,888 INFO | (50, 200)\n",
      "2021-05-27 16:55:56,893 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:56,894 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,895 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:56,895 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:56,896 INFO | BERT LAYER\n",
      "2021-05-27 16:55:56,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,897 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,898 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,904 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,905 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,914 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,920 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,921 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,936 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,941 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,949 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,950 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,956 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,963 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,970 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:56,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:56,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:56,976 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% :  99%|| 571/574 [01:02<00:00,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:56,989 INFO | INITIAL\n",
      "2021-05-27 16:55:56,989 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,000 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,000 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,002 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,002 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,003 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,005 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,012 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,020 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,020 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,021 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,027 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,041 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,042 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,048 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,049 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,054 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,055 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,061 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,062 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,070 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,077 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,078 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,085 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,086 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,086 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,087 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% : 100%|| 572/574 [01:02<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,099 INFO | INITIAL\n",
      "2021-05-27 16:55:57,099 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,105 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,105 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,107 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,107 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,108 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,108 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,109 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,115 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,116 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,122 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,123 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,128 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,129 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,153 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,154 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,161 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,162 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,162 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,169 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,170 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,176 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,177 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,177 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,182 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,183 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,190 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,191 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% : 100%|| 573/574 [01:02<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,201 INFO | INITIAL\n",
      "2021-05-27 16:55:57,201 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,207 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,208 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,210 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,210 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,211 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,214 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,214 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,215 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,215 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,234 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,239 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,240 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,241 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,247 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,248 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,248 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,254 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,262 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,263 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,269 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,276 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,277 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,285 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,286 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,292 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,292 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,293 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,293 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,299 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,300 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,301 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000% : 100%|| 574/574 [01:02<00:00,  9.18it/s]\n",
      "Epoch: 000, Loss: 0.000, Accuracy: 0.000%:   0%|          | 0/574 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,314 INFO | INITIAL\n",
      "2021-05-27 16:55:57,315 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,320 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,321 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,322 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,322 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,323 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,324 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,324 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,331 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,338 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,353 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,371 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,372 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,379 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,380 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,392 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,393 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,398 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,399 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,405 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,405 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   0%|          | 1/574 [00:00<00:59,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,419 INFO | INITIAL\n",
      "2021-05-27 16:55:57,419 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,425 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,425 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,427 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,427 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,428 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,428 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,430 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,430 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,438 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,439 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,440 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,440 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,449 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,450 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,457 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,480 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,482 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,489 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,489 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,490 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,496 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,497 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,504 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,505 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,512 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,512 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,513 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,513 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,519 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,520 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,520 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   0%|          | 2/574 [00:00<01:02,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,532 INFO | INITIAL\n",
      "2021-05-27 16:55:57,532 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,537 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,537 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,539 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,539 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,540 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,541 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,542 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,551 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,566 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,567 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,573 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,574 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,590 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,604 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,618 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,619 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,620 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,628 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   1%|          | 3/574 [00:00<01:01,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,638 INFO | INITIAL\n",
      "2021-05-27 16:55:57,638 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,645 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,646 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,647 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,647 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,648 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,649 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,650 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,657 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,666 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,667 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,682 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,689 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,690 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,690 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,697 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,697 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,698 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,698 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,711 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,733 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   1%|          | 4/574 [00:00<01:01,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,747 INFO | INITIAL\n",
      "2021-05-27 16:55:57,748 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,755 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,756 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,757 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,757 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,758 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,759 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,760 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,761 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,769 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,774 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,781 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,788 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,789 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,789 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,795 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,803 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,811 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,818 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,828 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,842 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,842 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,843 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,843 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   1%|          | 5/574 [00:00<01:01,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,853 INFO | INITIAL\n",
      "2021-05-27 16:55:57,853 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,858 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,859 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,860 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,860 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,861 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,862 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,863 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,869 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,888 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,889 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,896 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,902 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,903 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,910 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,925 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,932 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,933 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,939 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,939 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,940 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,945 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,946 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,946 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,947 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   1%|          | 6/574 [00:00<01:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:57,957 INFO | INITIAL\n",
      "2021-05-27 16:55:57,958 INFO | (50, 200)\n",
      "2021-05-27 16:55:57,967 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:57,968 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,969 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:57,970 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:57,971 INFO | BERT LAYER\n",
      "2021-05-27 16:55:57,971 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,972 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,981 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,982 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,988 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,989 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,995 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:57,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:57,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:57,996 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,003 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,004 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,009 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,010 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,010 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,016 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,016 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,017 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,017 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,024 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,031 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,032 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,037 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,038 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,039 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,048 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,050 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,057 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,057 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,058 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,058 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   1%|          | 7/574 [00:00<01:01,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,070 INFO | INITIAL\n",
      "2021-05-27 16:55:58,071 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,076 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,076 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,078 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,078 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,079 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,080 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,081 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,088 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,096 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,113 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,121 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,127 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,135 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,143 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,150 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,150 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,151 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,157 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,157 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,158 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,158 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,164 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,166 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   1%|         | 8/574 [00:00<01:01,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,176 INFO | INITIAL\n",
      "2021-05-27 16:55:58,177 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,182 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,183 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,184 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,185 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,185 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,185 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,186 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,188 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,196 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,203 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,204 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,212 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,213 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,221 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,222 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,229 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,236 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,237 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,244 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,245 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,250 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,251 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,251 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,257 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,266 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,267 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,267 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,274 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,275 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   2%|         | 9/574 [00:00<01:01,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,289 INFO | INITIAL\n",
      "2021-05-27 16:55:58,290 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,297 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,298 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,299 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,299 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,300 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,301 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,302 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,309 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,315 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,316 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,323 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,329 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,330 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,336 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,337 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,345 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,361 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,362 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,368 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,369 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,375 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,381 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,382 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,382 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,383 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   2%|         | 10/574 [00:01<01:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,392 INFO | INITIAL\n",
      "2021-05-27 16:55:58,392 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,398 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,399 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,400 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,400 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,401 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,402 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,402 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,403 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,409 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,410 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,415 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,416 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,416 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,417 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,424 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,425 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,435 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,436 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,445 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,445 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,446 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,454 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,456 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,463 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,472 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,473 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,481 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,483 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,491 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,507 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,509 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   2%|         | 11/574 [00:01<01:03,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,520 INFO | INITIAL\n",
      "2021-05-27 16:55:58,520 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,525 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,526 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,527 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,528 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,528 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,529 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,529 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,530 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,530 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,531 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,539 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,540 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,547 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,548 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,559 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,568 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,569 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,574 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,575 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,576 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,582 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,583 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,588 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,588 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,589 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,596 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,597 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,603 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,608 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,609 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,610 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,619 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,619 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   2%|         | 12/574 [00:01<01:03,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,631 INFO | INITIAL\n",
      "2021-05-27 16:55:58,631 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,636 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,637 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,638 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,638 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,639 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,639 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,640 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,647 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,653 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,654 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,660 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,661 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,668 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,669 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,675 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,676 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,683 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,691 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,693 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,699 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,700 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,707 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,714 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,720 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,720 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,721 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   2%|         | 12/574 [00:01<01:03,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,730 INFO | INITIAL\n",
      "2021-05-27 16:55:58,731 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,736 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,736 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,737 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,738 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,738 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,740 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,740 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,741 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,750 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,757 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,765 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,768 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,776 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,784 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,785 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,791 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,792 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,799 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,806 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,807 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,807 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,818 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,826 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,827 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,833 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,833 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   2%|         | 14/574 [00:01<01:01,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,844 INFO | INITIAL\n",
      "2021-05-27 16:55:58,844 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,849 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,850 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,851 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,851 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,852 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,854 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,861 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,867 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,874 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,876 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,881 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,883 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,892 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,893 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,893 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,900 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,901 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,909 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,915 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,916 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,921 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,922 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,922 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,927 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,928 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,929 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,936 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   3%|         | 15/574 [00:01<01:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:58,947 INFO | INITIAL\n",
      "2021-05-27 16:55:58,948 INFO | (50, 200)\n",
      "2021-05-27 16:55:58,954 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:58,955 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,956 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:58,957 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:58,958 INFO | BERT LAYER\n",
      "2021-05-27 16:55:58,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,959 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,961 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,968 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,969 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,976 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,976 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,977 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,983 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,984 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,991 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,992 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:58,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:58,999 INFO | (200, 512)\n",
      "2021-05-27 16:55:58,999 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,000 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,006 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,006 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,013 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,014 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,021 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,021 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,022 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,028 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,029 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,035 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,036 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,043 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,044 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   3%|         | 16/574 [00:01<01:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,056 INFO | INITIAL\n",
      "2021-05-27 16:55:59,056 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,063 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,064 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,065 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,066 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,067 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,067 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,068 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,075 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,076 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,076 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,082 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,089 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,090 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,097 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,098 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,104 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,105 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,112 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,112 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,113 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,119 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,120 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,128 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,129 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,136 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,137 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,144 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,145 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,152 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,153 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   3%|         | 17/574 [00:01<01:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,165 INFO | INITIAL\n",
      "2021-05-27 16:55:59,165 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,170 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,171 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,172 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,173 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,173 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,174 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,175 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,176 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,183 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,184 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,184 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,191 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,192 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,192 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,198 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,199 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,206 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,209 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,216 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,217 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,225 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,226 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,232 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,233 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,238 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,239 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,239 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,240 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,246 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,247 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,252 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,253 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,257 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,258 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,259 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   3%|         | 18/574 [00:01<00:59,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,269 INFO | INITIAL\n",
      "2021-05-27 16:55:59,269 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,274 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,275 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,277 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,277 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,278 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,278 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,279 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,281 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,282 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,288 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,289 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,297 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,298 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,299 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,305 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,306 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,312 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,318 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,319 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,324 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,325 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,326 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,332 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,333 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,339 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,339 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,340 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,346 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,346 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,347 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,347 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,354 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,354 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,355 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,363 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,364 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,365 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   3%|         | 19/574 [00:02<00:59,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,376 INFO | INITIAL\n",
      "2021-05-27 16:55:59,377 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,383 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,383 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,384 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,385 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,385 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,385 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,386 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,386 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,387 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,394 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,394 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,395 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,395 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,400 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,401 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,406 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,407 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,414 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,415 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,421 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,422 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,429 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,437 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,443 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,451 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,452 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,458 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,459 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,465 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,471 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,471 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   3%|         | 20/574 [00:02<00:59,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,481 INFO | INITIAL\n",
      "2021-05-27 16:55:59,482 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,488 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,488 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,490 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,490 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,491 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,492 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,493 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,494 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,501 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,502 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,508 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,508 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,509 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,509 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,518 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,518 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,519 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,525 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,527 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,534 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,535 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,541 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,542 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,543 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,549 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,549 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,550 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,556 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,557 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,563 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,564 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,570 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,577 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,578 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   4%|         | 21/574 [00:02<00:59,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,590 INFO | INITIAL\n",
      "2021-05-27 16:55:59,590 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,597 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,598 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,599 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,599 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,600 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,600 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,601 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,602 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,608 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,609 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,617 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,618 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,625 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,626 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,626 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,627 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,633 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,634 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,634 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,641 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,641 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,643 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,649 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,650 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,651 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,657 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,657 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,658 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,663 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,664 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,664 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,670 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,671 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,677 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,684 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,685 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   4%|         | 22/574 [00:02<00:58,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,695 INFO | INITIAL\n",
      "2021-05-27 16:55:59,696 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,701 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,701 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,702 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,703 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,704 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,704 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,705 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,706 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,712 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,713 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,718 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,719 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,725 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,726 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,732 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,733 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,739 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,739 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,740 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,740 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,747 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,748 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,748 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,749 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,755 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,756 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,762 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,763 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,769 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,770 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,775 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,775 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,776 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,777 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,782 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,783 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   4%|         | 22/574 [00:02<00:58,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,792 INFO | INITIAL\n",
      "2021-05-27 16:55:59,792 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,797 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,798 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,799 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,799 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,800 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,800 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,801 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,802 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,808 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,808 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,809 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,810 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,819 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,820 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,820 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,828 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,829 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,830 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,836 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,836 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,837 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,837 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,844 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,845 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,845 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,852 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,853 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,859 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,860 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,865 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,866 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,871 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,871 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,871 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,872 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,878 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,879 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,886 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,887 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   4%|         | 24/574 [00:02<00:57,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:55:59,900 INFO | INITIAL\n",
      "2021-05-27 16:55:59,900 INFO | (50, 200)\n",
      "2021-05-27 16:55:59,905 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:55:59,905 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,906 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:55:59,907 INFO | (50, 200, 512)\n",
      "2021-05-27 16:55:59,908 INFO | BERT LAYER\n",
      "2021-05-27 16:55:59,908 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,911 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,912 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,918 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,919 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,926 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,927 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,934 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,935 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,942 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,943 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,951 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,952 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,957 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,958 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,964 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,965 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,966 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,971 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,972 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,972 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,973 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,978 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,979 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,979 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,980 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,985 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,986 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:55:59,992 INFO | (200, 512)\n",
      "2021-05-27 16:55:59,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:55:59,993 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   4%|         | 25/574 [00:02<00:57,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,005 INFO | INITIAL\n",
      "2021-05-27 16:56:00,006 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,012 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,012 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,013 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,014 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,015 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,015 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,016 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,016 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,023 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,023 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,024 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,024 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,031 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,031 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,032 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,033 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,037 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,038 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,038 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,039 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,045 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,046 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,046 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,052 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,053 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,053 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,059 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,060 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,060 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,061 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,067 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,068 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,074 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,075 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,075 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,076 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,083 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,084 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,092 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,093 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,100 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,100 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 26/574 [00:02<00:57,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,112 INFO | INITIAL\n",
      "2021-05-27 16:56:00,112 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,118 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,118 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,120 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,120 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,121 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,121 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,121 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,122 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,122 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,122 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,130 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,130 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,137 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,137 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,145 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,154 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,158 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,165 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,166 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,174 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,174 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,175 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,176 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,181 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,182 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,182 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,188 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,189 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,210 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,210 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 27/574 [00:02<00:58,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,223 INFO | INITIAL\n",
      "2021-05-27 16:56:00,223 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,230 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,231 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,232 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,233 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,233 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,235 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,236 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,243 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,244 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,252 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,253 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,253 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,261 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,262 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,267 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,268 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,273 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,282 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,289 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,295 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,296 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,302 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,303 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,311 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,313 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,321 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,322 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 28/574 [00:03<00:58,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,333 INFO | INITIAL\n",
      "2021-05-27 16:56:00,333 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,338 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,338 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,340 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,340 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,341 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,341 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,342 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,342 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,343 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,344 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,351 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,351 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,360 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,367 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,375 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,376 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,393 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,399 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,400 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,420 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,421 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,421 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,421 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,427 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,428 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,428 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 29/574 [00:03<00:58,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,439 INFO | INITIAL\n",
      "2021-05-27 16:56:00,440 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,446 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,446 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,448 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,448 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,449 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,449 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,450 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,451 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,456 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,458 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,467 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,475 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,476 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,483 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,484 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,492 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,492 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,493 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,493 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,506 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,507 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,513 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,514 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,514 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,515 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,520 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,521 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,528 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,528 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,535 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,536 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 30/574 [00:03<00:58,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,550 INFO | INITIAL\n",
      "2021-05-27 16:56:00,550 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,556 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,556 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,558 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,559 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,560 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,560 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,561 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,562 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,567 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,568 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,568 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,568 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,574 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,575 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,575 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,576 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,581 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,582 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,588 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,588 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,589 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,596 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,597 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,604 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,611 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,612 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,613 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,620 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,621 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,629 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,630 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,630 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,631 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,638 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,639 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,645 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,646 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 31/574 [00:03<00:58,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,655 INFO | INITIAL\n",
      "2021-05-27 16:56:00,656 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,661 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,661 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,662 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,663 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,664 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,664 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,664 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,664 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,665 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,665 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,670 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,671 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,677 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,677 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,678 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,684 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,684 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,685 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,690 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,690 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,691 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,691 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,698 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,699 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,699 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,699 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,705 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,706 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,713 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,713 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,720 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,721 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,721 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,727 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,727 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,728 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,733 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,733 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,734 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,739 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,739 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,740 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   5%|         | 31/574 [00:03<00:58,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,751 INFO | INITIAL\n",
      "2021-05-27 16:56:00,752 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,758 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,758 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,760 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,760 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,761 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,761 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,762 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,762 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,763 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,770 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,771 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,771 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,780 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,788 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,789 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,789 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,796 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,797 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,802 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,803 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,810 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,811 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,819 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,819 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,825 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,826 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,832 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,832 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,839 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,848 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   6%|         | 33/574 [00:03<00:56,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,861 INFO | INITIAL\n",
      "2021-05-27 16:56:00,862 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,867 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,867 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,869 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,869 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,869 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,870 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,870 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,871 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,871 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,871 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,879 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,887 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,894 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,901 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,902 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,909 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,909 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,910 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,917 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,918 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,923 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,924 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,924 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,925 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,933 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,935 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,940 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,940 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,941 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,941 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,947 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,948 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,955 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,955 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   6%|         | 34/574 [00:03<00:56,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:00,965 INFO | INITIAL\n",
      "2021-05-27 16:56:00,966 INFO | (50, 200)\n",
      "2021-05-27 16:56:00,971 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:00,971 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,973 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:00,973 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:00,975 INFO | BERT LAYER\n",
      "2021-05-27 16:56:00,976 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,978 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,984 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:00,992 INFO | (200, 512)\n",
      "2021-05-27 16:56:00,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:00,994 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,000 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,001 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,008 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,009 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,016 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,017 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,023 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,024 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,030 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,031 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,036 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,037 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,044 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,050 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,051 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,056 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,057 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   6%|         | 35/574 [00:03<00:56,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,067 INFO | INITIAL\n",
      "2021-05-27 16:56:01,067 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,073 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,073 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,074 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,075 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,076 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,077 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,077 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,078 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,079 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,088 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,088 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,094 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,096 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,101 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,102 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,102 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,103 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,108 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,109 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,114 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,115 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,116 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,122 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,123 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,130 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,130 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,136 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,136 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,136 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,142 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,143 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,150 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,150 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,159 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,160 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   6%|         | 36/574 [00:03<00:56,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,172 INFO | INITIAL\n",
      "2021-05-27 16:56:01,173 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,180 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,181 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,182 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,183 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,184 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,184 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,185 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,185 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,191 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,192 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,192 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,198 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,198 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,199 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,199 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,204 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,205 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,206 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,212 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,212 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,220 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,227 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,228 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,236 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,237 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,244 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,245 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,252 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,253 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,253 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,260 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,261 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,267 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,268 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   6%|         | 37/574 [00:03<00:56,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,280 INFO | INITIAL\n",
      "2021-05-27 16:56:01,280 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,285 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,286 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,288 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,288 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,289 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,289 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,290 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,290 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,291 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,292 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,298 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,299 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,299 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,306 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,306 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,309 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,317 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,318 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,325 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,326 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,333 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,338 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,338 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,339 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,339 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,346 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,346 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,353 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,354 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,359 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,360 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,360 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,365 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,366 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,372 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,372 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   7%|         | 38/574 [00:04<00:56,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,384 INFO | INITIAL\n",
      "2021-05-27 16:56:01,385 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,392 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,393 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,394 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,394 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,395 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,396 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,396 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,397 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,403 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,403 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,404 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,404 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,421 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,421 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,422 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,429 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,429 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,430 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,436 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,437 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,437 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,437 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,445 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,446 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,451 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,452 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,452 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,458 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,458 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,460 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,467 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,473 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,473 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,479 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,480 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,480 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   7%|         | 39/574 [00:04<00:56,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,492 INFO | INITIAL\n",
      "2021-05-27 16:56:01,493 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,499 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,499 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,500 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,501 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,501 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,502 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,502 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,503 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,510 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,511 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,515 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,517 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,523 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,524 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,531 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,531 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,532 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,536 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,537 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,537 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,537 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,553 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,554 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,565 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,571 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,572 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,578 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,579 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,585 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,586 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,591 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,592 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,593 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   7%|         | 40/574 [00:04<00:57,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,602 INFO | INITIAL\n",
      "2021-05-27 16:56:01,602 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,607 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,608 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,609 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,610 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,611 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,611 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,611 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,612 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,620 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,621 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,621 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,622 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,629 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,630 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,631 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,638 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,639 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,646 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,646 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,647 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,647 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,652 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,653 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,653 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,654 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,659 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,660 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,661 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,666 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,667 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,673 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,674 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,680 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,680 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,688 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,694 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,695 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   7%|         | 41/574 [00:04<00:56,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,708 INFO | INITIAL\n",
      "2021-05-27 16:56:01,709 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,717 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,717 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,719 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,719 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,720 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,720 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,721 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,722 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,729 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,729 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,730 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,730 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,735 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,736 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,742 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,749 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,750 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,756 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,758 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,763 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,764 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,765 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,770 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,771 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,772 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,780 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,784 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,791 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,793 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,799 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,800 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,800 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,806 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,807 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,807 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,807 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   7%|         | 42/574 [00:04<00:57,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,820 INFO | INITIAL\n",
      "2021-05-27 16:56:01,820 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,826 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,827 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,828 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,828 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,829 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,830 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,830 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,831 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,836 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,836 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,837 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,837 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,843 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,844 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,845 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,852 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,853 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,859 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,861 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,867 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,868 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,874 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,875 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,881 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,881 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,882 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,889 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,890 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,897 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,897 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,898 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,898 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,904 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,905 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,906 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,912 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,912 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   7%|         | 43/574 [00:04<00:56,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:01,923 INFO | INITIAL\n",
      "2021-05-27 16:56:01,923 INFO | (50, 200)\n",
      "2021-05-27 16:56:01,931 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:01,932 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,933 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:01,934 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:01,934 INFO | BERT LAYER\n",
      "2021-05-27 16:56:01,935 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,936 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,936 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,943 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,944 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,950 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,951 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,957 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,958 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,964 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,964 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,970 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,971 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,983 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,983 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,984 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,990 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,991 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,997 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:01,997 INFO | (200, 512)\n",
      "2021-05-27 16:56:01,998 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:01,998 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,005 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,006 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,012 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,013 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   8%|         | 44/574 [00:04<00:55,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,024 INFO | INITIAL\n",
      "2021-05-27 16:56:02,024 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,031 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,031 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,033 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,033 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,034 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,034 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,035 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,035 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,041 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,042 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,047 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,048 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,048 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,049 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,055 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,056 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,063 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,064 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,071 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,072 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,079 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,080 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,080 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,088 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,089 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,097 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,097 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,098 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,104 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,105 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,111 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,117 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,118 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   8%|         | 45/574 [00:04<00:55,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,129 INFO | INITIAL\n",
      "2021-05-27 16:56:02,130 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,134 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,135 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,136 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,136 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,137 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,137 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,138 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,138 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,139 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,139 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,146 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,146 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,153 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,154 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,160 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,161 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,162 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,169 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,179 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,194 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,195 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,202 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,208 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,209 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,209 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,210 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,215 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,215 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,216 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,224 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,225 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   8%|         | 46/574 [00:04<00:55,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,235 INFO | INITIAL\n",
      "2021-05-27 16:56:02,236 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,242 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,243 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,245 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,246 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,247 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,248 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,249 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,250 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,257 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,258 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,264 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,264 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,265 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,270 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,271 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,271 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,277 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,278 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,279 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,286 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,295 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,308 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,309 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,316 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,317 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,324 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,324 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,325 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,325 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,331 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,332 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   8%|         | 47/574 [00:05<00:55,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,342 INFO | INITIAL\n",
      "2021-05-27 16:56:02,343 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,348 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,349 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,350 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,351 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,352 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,353 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,354 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,354 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,361 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,362 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,369 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,375 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,376 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,386 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,386 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,393 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,399 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,411 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,412 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,418 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,419 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,426 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,426 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,432 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,433 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   8%|         | 48/574 [00:05<00:55,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,444 INFO | INITIAL\n",
      "2021-05-27 16:56:02,444 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,451 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,451 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,453 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,453 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,454 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,454 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,455 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,456 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,463 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,463 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,464 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,472 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,472 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,473 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,473 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,480 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,481 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,496 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,497 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,497 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,503 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,504 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,511 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,511 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,512 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,518 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,519 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,526 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,532 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,533 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,537 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,538 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,538 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,539 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   9%|         | 49/574 [00:05<00:54,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,549 INFO | INITIAL\n",
      "2021-05-27 16:56:02,549 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,556 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,557 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,559 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,560 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,562 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,563 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,564 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,564 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,570 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,571 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,571 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,572 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,578 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,578 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,584 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,584 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,585 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,585 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,591 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,592 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,592 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,597 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,598 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,598 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,598 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,604 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,610 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,610 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,616 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,624 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,625 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,632 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,641 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,642 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   9%|         | 50/574 [00:05<00:55,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,655 INFO | INITIAL\n",
      "2021-05-27 16:56:02,656 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,664 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,665 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,667 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,667 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,668 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,669 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,670 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,670 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,671 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,672 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,678 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,679 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,680 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,688 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,689 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,696 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,698 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,704 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,704 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,705 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,705 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,711 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,711 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,713 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,718 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,718 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,719 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,726 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,727 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,735 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,736 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,752 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,752 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,753 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,760 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,760 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,761 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   9%|         | 51/574 [00:05<00:56,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,770 INFO | INITIAL\n",
      "2021-05-27 16:56:02,771 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,776 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,777 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,778 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,778 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,779 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,779 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,780 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,780 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,781 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,781 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,787 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,787 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,788 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,794 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,795 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,800 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,801 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,808 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,809 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,816 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,817 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,825 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,826 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,832 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,833 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,838 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,839 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,839 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,852 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,853 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,858 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,859 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   9%|         | 51/574 [00:05<00:56,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,868 INFO | INITIAL\n",
      "2021-05-27 16:56:02,869 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,874 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,875 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,876 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,876 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,877 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,879 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,887 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,897 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,898 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,905 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,905 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,906 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,912 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,913 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,919 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,920 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,927 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,928 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,933 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,934 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,939 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,940 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,947 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,948 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,956 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,957 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,963 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,964 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   9%|         | 53/574 [00:05<00:55,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:02,978 INFO | INITIAL\n",
      "2021-05-27 16:56:02,979 INFO | (50, 200)\n",
      "2021-05-27 16:56:02,985 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:02,985 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,986 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:02,987 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:02,987 INFO | BERT LAYER\n",
      "2021-05-27 16:56:02,988 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,989 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,990 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,990 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:02,997 INFO | (200, 512)\n",
      "2021-05-27 16:56:02,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:02,998 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,004 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,005 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,011 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,012 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,012 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,013 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,019 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,033 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,034 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,041 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,042 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,050 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,051 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,059 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,060 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,065 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,066 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,067 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,072 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,073 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :   9%|         | 54/574 [00:05<00:55,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,084 INFO | INITIAL\n",
      "2021-05-27 16:56:03,085 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,091 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,091 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,093 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,093 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,094 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,095 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,095 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,096 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,096 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,096 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,103 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,104 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,111 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,118 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,119 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,125 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,127 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,143 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,150 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,151 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,151 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,152 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,158 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,158 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,159 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,165 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,165 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,166 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,178 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,179 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  10%|         | 55/574 [00:05<00:54,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,189 INFO | INITIAL\n",
      "2021-05-27 16:56:03,189 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,195 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,196 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,197 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,198 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,199 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,199 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,200 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,200 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,206 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,207 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,207 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,208 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,214 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,215 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,215 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,222 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,223 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,229 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,230 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,230 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,236 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,236 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,237 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,237 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,243 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,245 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,250 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,256 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,256 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,262 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,263 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,270 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,277 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,278 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  10%|         | 55/574 [00:05<00:54,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,288 INFO | INITIAL\n",
      "2021-05-27 16:56:03,289 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,294 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,295 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,296 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,298 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,299 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,300 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,300 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,301 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,308 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,309 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,314 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,316 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,317 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,323 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,324 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,331 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,337 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,338 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,344 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,345 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,353 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,366 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,367 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,376 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,380 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,388 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,388 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,388 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  10%|         | 57/574 [00:06<00:54,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,401 INFO | INITIAL\n",
      "2021-05-27 16:56:03,401 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,406 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,406 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,408 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,409 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,410 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,410 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,411 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,417 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,418 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,419 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,425 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,426 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,433 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,433 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,434 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,434 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,440 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,441 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,442 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,442 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,451 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,452 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,458 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,458 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,460 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,467 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,467 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,468 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,468 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,475 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,476 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,483 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,483 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,484 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,490 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,491 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,491 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,492 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,498 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,499 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  10%|         | 58/574 [00:06<00:54,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,510 INFO | INITIAL\n",
      "2021-05-27 16:56:03,510 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,516 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,517 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,518 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,518 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,519 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,519 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,520 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,520 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,520 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,521 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,527 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,527 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,529 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,535 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,536 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,543 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,543 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,544 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,545 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,552 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,553 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,559 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,560 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,560 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,561 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,566 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,567 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,568 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,573 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,574 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,580 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,582 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,587 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,588 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,594 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,594 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,595 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,601 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,602 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  10%|         | 59/574 [00:06<00:54,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,614 INFO | INITIAL\n",
      "2021-05-27 16:56:03,614 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,620 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,620 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,622 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,622 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,623 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,623 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,624 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,625 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,633 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,639 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,639 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,640 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,640 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,647 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,648 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,654 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,654 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,660 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,661 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,668 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,668 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,669 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,674 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,682 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,683 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,688 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,689 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,689 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,697 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,698 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,704 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,704 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  10%|         | 60/574 [00:06<00:53,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,715 INFO | INITIAL\n",
      "2021-05-27 16:56:03,716 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,721 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,721 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,722 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,723 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,723 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,725 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,726 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,727 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,733 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,738 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,738 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,739 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,745 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,745 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,751 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,751 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,756 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,757 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,757 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,758 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,766 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,767 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,772 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,773 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,773 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,774 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,783 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,791 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,793 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,798 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,799 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,804 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,804 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,804 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  11%|         | 61/574 [00:06<00:53,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,816 INFO | INITIAL\n",
      "2021-05-27 16:56:03,816 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,820 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,821 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,822 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,822 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,823 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,824 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,825 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,825 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,826 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,826 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,832 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,832 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,833 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,833 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,839 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,841 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,862 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,863 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,869 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,870 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,879 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,886 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,887 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,896 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,903 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,903 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,910 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,911 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,911 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  11%|         | 62/574 [00:06<00:53,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:03,921 INFO | INITIAL\n",
      "2021-05-27 16:56:03,921 INFO | (50, 200)\n",
      "2021-05-27 16:56:03,926 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:03,927 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,928 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:03,929 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:03,930 INFO | BERT LAYER\n",
      "2021-05-27 16:56:03,930 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,931 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,931 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,932 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,932 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,936 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,937 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,937 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,938 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,945 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,945 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,951 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,952 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,958 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,959 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,966 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,967 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,969 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,975 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,976 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,984 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,984 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,990 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:03,990 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:03,991 INFO | (200, 512)\n",
      "2021-05-27 16:56:03,999 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,000 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,000 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,001 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,007 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,008 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,008 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,014 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,015 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  11%|         | 63/574 [00:06<00:53,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,024 INFO | INITIAL\n",
      "2021-05-27 16:56:04,025 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,031 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,032 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,034 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,034 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,035 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,035 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,036 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,037 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,043 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,044 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,045 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,053 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,053 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,054 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,061 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,062 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,070 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,071 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,076 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,077 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,077 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,078 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,083 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,084 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,084 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,084 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,090 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,090 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,091 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,091 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,099 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,099 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,099 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,104 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,105 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,105 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,105 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,111 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,119 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,120 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  11%|         | 64/574 [00:06<00:53,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,132 INFO | INITIAL\n",
      "2021-05-27 16:56:04,132 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,137 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,138 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,139 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,142 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,143 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,144 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,145 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,146 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,153 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,153 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,154 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,154 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,161 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,161 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,162 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,163 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,179 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,186 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,194 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,194 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,201 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,201 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,202 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,202 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,208 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,209 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,214 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,215 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,215 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,221 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,221 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,230 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,231 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,231 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,232 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  11%|        | 65/574 [00:06<00:54,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,244 INFO | INITIAL\n",
      "2021-05-27 16:56:04,245 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,251 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,251 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,253 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,253 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,254 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,254 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,255 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,256 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,264 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,265 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,271 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,271 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,272 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,272 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,279 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,279 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,280 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,280 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,286 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,292 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,293 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,293 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,308 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,310 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,316 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,316 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,316 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,323 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,324 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,331 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,337 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,338 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  11%|        | 66/574 [00:07<01:08,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,444 INFO | INITIAL\n",
      "2021-05-27 16:56:04,444 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,450 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,450 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,452 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,452 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,453 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,454 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,454 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,455 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,455 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,456 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,462 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,463 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,468 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,469 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,474 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,475 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,481 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,481 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,494 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,495 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,496 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,496 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,502 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,503 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,510 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,511 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,518 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,519 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,519 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,525 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,527 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,528 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,534 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,534 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,535 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  12%|        | 67/574 [00:07<01:03,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,545 INFO | INITIAL\n",
      "2021-05-27 16:56:04,545 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,550 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,550 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,552 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,553 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,553 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,553 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,554 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,554 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,561 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,569 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,569 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,569 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,575 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,576 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,582 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,583 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,589 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,590 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,596 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,597 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,604 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,614 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,621 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,622 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,622 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,623 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,630 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,631 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,638 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,638 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  12%|        | 68/574 [00:07<01:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,650 INFO | INITIAL\n",
      "2021-05-27 16:56:04,650 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,655 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,655 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,657 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,658 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,659 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,660 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,660 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,660 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,661 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,667 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,668 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,674 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,680 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,695 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,697 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,703 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,703 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,704 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,704 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,711 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,711 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,712 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,712 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,718 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,719 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,725 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,726 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,734 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,735 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,741 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,742 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  12%|        | 69/574 [00:07<00:57,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,752 INFO | INITIAL\n",
      "2021-05-27 16:56:04,753 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,758 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,759 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,761 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,762 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,763 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,763 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,764 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,766 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,773 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,774 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,775 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,783 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,783 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,784 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,784 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,790 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,791 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,792 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,798 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,798 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,799 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,799 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,805 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,806 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,813 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,813 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,814 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,814 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,820 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,820 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,821 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,821 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,827 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,828 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,828 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,829 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,836 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,836 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,837 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,837 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,844 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,844 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,845 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,845 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,851 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,852 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,852 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  12%|        | 70/574 [00:07<00:57,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,865 INFO | INITIAL\n",
      "2021-05-27 16:56:04,865 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,870 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,871 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,872 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:04,879 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:04,885 INFO | BERT LAYER\n",
      "2021-05-27 16:56:04,886 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,892 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,893 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,903 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,904 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,911 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,912 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,913 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,918 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,919 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,926 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,927 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,933 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,933 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,934 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,934 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,939 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,940 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,946 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,947 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,952 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,953 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,959 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,960 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,960 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,961 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,969 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,970 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:04,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:04,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:04,978 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  12%|        | 71/574 [00:07<00:58,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:04,989 INFO | INITIAL\n",
      "2021-05-27 16:56:04,990 INFO | (50, 200)\n",
      "2021-05-27 16:56:04,999 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:04,999 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,001 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,001 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,002 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,002 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,003 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,003 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,003 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,004 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,011 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,012 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,017 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,017 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,018 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,025 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,033 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,034 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,034 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,035 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,041 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,042 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,042 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,050 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,051 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,051 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,057 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,058 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,058 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,065 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,066 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,072 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,073 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,080 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,087 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,087 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,088 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,089 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  13%|        | 72/574 [00:07<00:58,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,105 INFO | INITIAL\n",
      "2021-05-27 16:56:05,105 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,113 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,113 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,115 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,115 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,116 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,117 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,117 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,117 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,119 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,126 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,127 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,127 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,132 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,133 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,133 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,134 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,139 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,140 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,141 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,148 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,149 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,155 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,155 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,163 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,164 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,178 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,181 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,197 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,204 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,205 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,206 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  13%|        | 73/574 [00:07<00:58,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,221 INFO | INITIAL\n",
      "2021-05-27 16:56:05,221 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,228 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,228 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,230 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,231 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,232 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,233 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,234 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,235 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,236 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,242 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,242 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,243 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,251 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,252 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,259 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,260 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,266 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,266 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,276 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,277 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,282 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,282 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,283 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,283 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,288 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,289 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,289 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,290 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,296 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,297 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,297 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,304 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,304 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,305 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,305 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,313 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,314 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,320 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,320 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,321 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,321 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  13%|        | 74/574 [00:08<00:57,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,333 INFO | INITIAL\n",
      "2021-05-27 16:56:05,334 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,339 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,340 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,341 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,342 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,343 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,343 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,345 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,345 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,360 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,369 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,376 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,377 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,377 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,383 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,384 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,384 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,393 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,399 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,412 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,419 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,420 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,426 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,427 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,427 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  13%|        | 75/574 [00:08<00:55,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,438 INFO | INITIAL\n",
      "2021-05-27 16:56:05,439 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,444 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,445 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,446 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,447 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,448 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,448 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,449 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,450 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,457 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,459 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,466 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,467 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,468 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,475 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,476 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,482 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,483 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,488 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,489 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,497 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,498 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,503 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,504 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,504 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,504 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,510 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,511 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,519 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,524 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,526 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,533 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,533 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,534 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  13%|        | 76/574 [00:08<00:55,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,546 INFO | INITIAL\n",
      "2021-05-27 16:56:05,546 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,552 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,552 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,554 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,554 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,555 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,555 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,556 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,556 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,558 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,566 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,567 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,567 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,575 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,576 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,583 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,584 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,590 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,591 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,596 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,597 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,602 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,609 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,609 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,610 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,610 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,619 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,628 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,629 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,637 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,637 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,638 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,638 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,645 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,646 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,646 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,647 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  13%|        | 77/574 [00:08<00:55,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,661 INFO | INITIAL\n",
      "2021-05-27 16:56:05,662 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,667 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,668 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,669 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,670 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,670 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,671 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,671 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,672 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,672 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,672 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,680 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,680 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,686 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,687 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,693 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,694 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,694 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,695 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,703 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,703 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,710 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,711 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,712 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,718 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,718 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,719 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,724 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,724 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,725 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,726 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,733 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,740 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,740 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,741 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,742 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,748 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,749 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,755 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,756 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  14%|        | 78/574 [00:08<00:55,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,770 INFO | INITIAL\n",
      "2021-05-27 16:56:05,770 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,776 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,777 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,778 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,779 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,780 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,781 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,783 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,790 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,792 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,794 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,801 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,802 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,808 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,809 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,810 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,816 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,817 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,822 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,822 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,823 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,823 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,830 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,831 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,839 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,853 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,861 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,862 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,868 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,869 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  14%|        | 79/574 [00:08<00:54,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,880 INFO | INITIAL\n",
      "2021-05-27 16:56:05,880 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,885 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,886 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,887 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,888 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,888 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,889 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,889 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,890 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,896 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,897 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,897 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,898 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,903 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,904 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,904 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,904 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,910 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,911 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,912 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,912 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,918 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,918 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,919 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,927 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,928 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,928 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,935 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,936 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,943 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,944 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,950 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,951 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,956 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,957 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,964 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,965 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,965 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,971 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,972 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,972 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  14%|        | 80/574 [00:08<00:53,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:05,983 INFO | INITIAL\n",
      "2021-05-27 16:56:05,984 INFO | (50, 200)\n",
      "2021-05-27 16:56:05,989 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:05,990 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,992 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:05,992 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:05,993 INFO | BERT LAYER\n",
      "2021-05-27 16:56:05,994 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:05,995 INFO | (200, 512)\n",
      "2021-05-27 16:56:05,996 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:05,996 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,002 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,004 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,009 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,009 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,011 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,017 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,018 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,027 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,027 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,035 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,036 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,045 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,046 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,052 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,052 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,059 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,059 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,060 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,061 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,067 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,067 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,068 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,074 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,075 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,082 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  14%|        | 81/574 [00:08<00:53,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,094 INFO | INITIAL\n",
      "2021-05-27 16:56:06,095 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,102 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,103 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,104 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,105 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,106 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,107 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,108 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,109 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,117 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,118 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,123 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,125 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,131 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,132 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,137 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,138 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,138 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,138 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,145 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,145 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,146 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,146 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,152 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,152 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,153 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,153 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,159 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,162 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,169 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,170 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,170 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,170 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,177 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,178 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,178 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,178 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,184 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,185 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,185 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,186 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,194 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,195 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  14%|        | 82/574 [00:08<00:54,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,208 INFO | INITIAL\n",
      "2021-05-27 16:56:06,209 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,215 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,215 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,217 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,217 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,218 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,220 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,228 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,229 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,237 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,238 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,247 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,247 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,253 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,254 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,254 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,255 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,261 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,261 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,262 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,262 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,276 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,282 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,294 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,295 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,302 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  14%|        | 83/574 [00:08<00:53,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,314 INFO | INITIAL\n",
      "2021-05-27 16:56:06,314 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,319 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,319 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,321 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,321 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,322 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,322 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,323 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,324 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,331 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,332 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,333 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,340 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,341 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,348 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,349 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,355 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,355 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,355 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,356 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,362 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,363 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,371 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,372 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,379 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,380 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,380 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,380 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,387 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,387 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,387 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,389 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,396 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,396 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,397 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,403 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,403 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,409 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,410 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  15%|        | 84/574 [00:09<00:53,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,421 INFO | INITIAL\n",
      "2021-05-27 16:56:06,421 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,427 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,428 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,430 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,430 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,431 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,432 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,434 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,435 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,442 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,443 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,443 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,444 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,449 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,449 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,450 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,450 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,455 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,456 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,462 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,463 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,463 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,463 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,469 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,470 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,470 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,471 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,477 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,477 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,478 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,478 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,484 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,485 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,490 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,490 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,491 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,491 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,501 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,509 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,510 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,519 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  15%|        | 85/574 [00:09<00:53,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,532 INFO | INITIAL\n",
      "2021-05-27 16:56:06,532 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,537 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,537 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,539 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,539 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,540 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,540 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,541 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,541 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,542 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,548 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,549 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,554 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,554 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,555 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,555 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,560 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,561 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,561 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,569 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,570 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,576 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,576 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,583 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,584 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,593 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,593 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,599 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,600 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,600 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,601 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,606 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,607 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,607 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,610 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,618 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,624 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,625 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  15%|        | 86/574 [00:09<00:52,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,639 INFO | INITIAL\n",
      "2021-05-27 16:56:06,639 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,645 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,646 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,647 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,648 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,648 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,649 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,650 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,651 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,657 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,657 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,658 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,658 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,666 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,667 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,673 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,688 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,696 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,697 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,706 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,708 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,715 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,715 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,716 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,717 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,726 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,729 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,736 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,736 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,745 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  15%|        | 87/574 [00:09<00:54,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,755 INFO | INITIAL\n",
      "2021-05-27 16:56:06,756 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,764 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,764 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,766 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,767 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,767 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,768 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,768 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,768 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,769 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,770 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,777 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,777 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,778 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,785 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,785 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,792 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,793 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,800 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,800 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,801 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,807 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,808 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,808 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,809 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,816 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,817 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,823 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,823 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,824 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,825 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,831 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,832 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,840 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,841 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,841 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,847 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,848 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,848 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,849 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,855 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  15%|        | 88/574 [00:09<00:53,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,867 INFO | INITIAL\n",
      "2021-05-27 16:56:06,867 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,874 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,874 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,876 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,876 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,877 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,877 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,878 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,879 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,879 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,886 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,887 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,887 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,896 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,897 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,905 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,905 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,906 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,913 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,914 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,914 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,914 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,921 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,922 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,928 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,929 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,935 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,935 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,937 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,942 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,944 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,949 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,950 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,955 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,956 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,962 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,963 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  16%|        | 89/574 [00:09<00:53,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:06,975 INFO | INITIAL\n",
      "2021-05-27 16:56:06,976 INFO | (50, 200)\n",
      "2021-05-27 16:56:06,981 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:06,982 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,983 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:06,984 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:06,984 INFO | BERT LAYER\n",
      "2021-05-27 16:56:06,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,985 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,986 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,986 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,993 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:06,994 INFO | (200, 512)\n",
      "2021-05-27 16:56:06,994 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:06,995 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,001 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,002 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,003 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,010 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,011 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,019 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,019 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,024 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,025 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,025 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,032 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,034 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,039 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,040 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,040 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,041 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,047 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,047 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,047 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,048 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,054 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,055 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,061 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,061 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,062 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,062 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,068 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,068 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,069 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,069 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  16%|        | 90/574 [00:09<00:52,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,081 INFO | INITIAL\n",
      "2021-05-27 16:56:07,082 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,087 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,087 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,089 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,089 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,091 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,092 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,092 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,093 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,093 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,094 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,100 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,101 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,109 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,109 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,110 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,116 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,117 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,117 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,118 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,123 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,124 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,124 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,125 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,131 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,132 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,132 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,133 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,140 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,141 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,141 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,149 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,150 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,156 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,156 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,157 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,157 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,166 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,167 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,175 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,176 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,176 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,177 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,183 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,184 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,184 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,185 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  16%|        | 91/574 [00:09<00:53,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,199 INFO | INITIAL\n",
      "2021-05-27 16:56:07,199 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,205 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,205 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,207 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,208 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,209 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,210 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,211 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,211 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,212 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,212 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,220 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,227 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,228 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,235 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,236 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,236 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,237 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,244 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,244 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,245 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,245 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,252 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,259 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,259 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,260 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,261 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,268 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,278 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,278 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,279 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,286 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,296 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,297 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,298 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,307 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,307 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,308 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,309 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  16%|        | 92/574 [00:10<00:55,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,321 INFO | INITIAL\n",
      "2021-05-27 16:56:07,321 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,328 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,328 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,330 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,330 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,331 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,331 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,333 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,340 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,341 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,349 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,349 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,349 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,350 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,356 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,357 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,358 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,358 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,369 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,378 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,379 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,385 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,386 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,391 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,393 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,399 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,407 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,414 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,419 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,420 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  16%|        | 93/574 [00:10<00:54,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,432 INFO | INITIAL\n",
      "2021-05-27 16:56:07,432 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,439 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,441 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,442 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,443 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,444 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,445 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,445 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,446 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,447 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,453 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,454 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,454 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,454 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,462 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,462 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,463 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,468 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,469 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,469 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,469 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,475 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,475 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,476 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,476 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,489 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,490 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,490 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,496 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,497 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,498 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,506 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,507 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,514 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,515 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,523 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,523 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,524 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,524 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,531 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,532 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  16%|        | 94/574 [00:10<00:53,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,542 INFO | INITIAL\n",
      "2021-05-27 16:56:07,542 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,548 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,548 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,550 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,550 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,551 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,551 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,552 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,553 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,559 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,560 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,565 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,566 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,572 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,573 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,573 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,574 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,579 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,580 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,580 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,581 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,586 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,586 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,587 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,594 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,595 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,601 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,602 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,615 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,615 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,616 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,624 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,625 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,633 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,634 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,641 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,643 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  17%|        | 95/574 [00:10<00:53,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,653 INFO | INITIAL\n",
      "2021-05-27 16:56:07,653 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,660 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,661 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,664 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,664 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,665 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,665 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,666 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,668 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,676 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,683 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,684 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,685 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,691 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,692 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,700 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,701 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,708 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,708 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,709 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,709 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,716 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,717 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,723 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,724 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,725 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,731 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,738 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,739 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,747 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,747 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,754 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,754 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,754 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,755 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  17%|        | 96/574 [00:10<00:53,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,765 INFO | INITIAL\n",
      "2021-05-27 16:56:07,766 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,773 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,774 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,775 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,776 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,777 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,777 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,778 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,779 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,784 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,785 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,785 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,786 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,792 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,793 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,794 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,794 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,801 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,801 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,802 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,804 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,812 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,812 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,819 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,820 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,827 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,828 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,834 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,835 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,841 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,842 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,842 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,848 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,848 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,849 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,854 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,855 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,855 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,861 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,861 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,862 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  17%|        | 97/574 [00:10<00:52,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,874 INFO | INITIAL\n",
      "2021-05-27 16:56:07,874 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,880 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,881 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,882 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:07,883 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:07,884 INFO | BERT LAYER\n",
      "2021-05-27 16:56:07,885 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,886 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,887 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,896 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,904 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,905 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,906 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,907 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,914 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,915 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,916 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,925 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,926 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,926 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,933 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,934 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,942 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,943 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,949 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,950 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,950 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,951 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,955 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,956 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,956 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,957 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,963 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,963 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,964 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,964 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,970 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,971 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,971 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,972 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,978 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:07,979 INFO | (200, 512)\n",
      "2021-05-27 16:56:07,979 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:07,980 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  17%|        | 98/574 [00:10<00:53,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:07,990 INFO | INITIAL\n",
      "2021-05-27 16:56:07,991 INFO | (50, 200)\n",
      "2021-05-27 16:56:07,998 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:07,999 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,002 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,003 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,004 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,004 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,005 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,005 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,006 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,013 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,013 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,014 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,014 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,022 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,022 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,029 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,029 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,030 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,030 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,036 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,037 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,038 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,045 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,046 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,052 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,052 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,053 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,060 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,060 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,061 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,061 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,067 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,068 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,068 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,069 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,075 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,076 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,076 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,076 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,082 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,082 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,083 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,083 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,090 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,091 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,092 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  17%|        | 99/574 [00:10<00:53,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,105 INFO | INITIAL\n",
      "2021-05-27 16:56:08,106 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,113 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,114 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,115 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,116 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,117 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,118 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,118 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,119 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,120 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,126 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,127 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,127 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,128 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,136 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,136 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,142 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,142 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,143 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,148 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,149 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,149 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,149 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,155 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,156 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,162 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,163 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,163 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,179 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,185 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,186 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,186 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,192 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,193 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,193 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,194 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,199 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,200 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,200 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  17%|        | 100/574 [00:10<00:53,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,213 INFO | INITIAL\n",
      "2021-05-27 16:56:08,214 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,219 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,220 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,221 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,221 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,222 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,223 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,224 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,225 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,235 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,244 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,244 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,251 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,252 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,258 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,258 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,259 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,259 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,266 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,266 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,267 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,267 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,273 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,280 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,280 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,286 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,287 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,309 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,310 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,311 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  18%|        | 101/574 [00:11<00:52,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,322 INFO | INITIAL\n",
      "2021-05-27 16:56:08,322 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,330 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,331 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,332 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,333 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,334 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,334 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,335 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,335 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,335 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,344 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,345 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,352 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,353 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,354 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,361 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,361 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,362 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,362 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,369 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,372 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,378 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,379 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,379 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,380 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,386 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,391 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,392 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,399 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,411 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,418 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,419 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  18%|        | 102/574 [00:11<00:51,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,430 INFO | INITIAL\n",
      "2021-05-27 16:56:08,430 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,437 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,437 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,439 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,440 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,441 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,442 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,442 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,443 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,444 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,451 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,451 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,452 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,458 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,459 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,459 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,473 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,474 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,480 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,481 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,481 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,486 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,487 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,487 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,493 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,494 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,501 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,507 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,508 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,509 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,515 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,516 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,516 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,517 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,526 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  18%|        | 103/574 [00:11<00:51,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,537 INFO | INITIAL\n",
      "2021-05-27 16:56:08,539 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,546 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,546 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,548 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,548 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,549 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,550 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,551 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,552 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,558 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,558 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,559 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,565 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,566 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,572 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,573 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,573 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,573 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,580 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,580 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,581 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,581 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,587 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,587 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,588 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,594 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,594 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,595 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,595 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,604 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,613 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,614 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,621 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,622 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,622 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,622 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,628 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,629 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,629 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,630 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,636 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,637 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,637 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,638 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  18%|        | 104/574 [00:11<00:51,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,648 INFO | INITIAL\n",
      "2021-05-27 16:56:08,649 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,654 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,654 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,656 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,656 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,657 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,657 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,658 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,659 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,666 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,666 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,667 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,667 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,672 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,673 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,673 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,674 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,679 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,680 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,680 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,688 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,689 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,689 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,696 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,697 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,697 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,697 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,705 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,705 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,706 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,706 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,712 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,713 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,713 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,714 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,719 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,720 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,726 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,726 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,727 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,732 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,733 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,733 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,739 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,739 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,739 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,740 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  18%|        | 105/574 [00:11<00:50,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,750 INFO | INITIAL\n",
      "2021-05-27 16:56:08,750 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,755 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,756 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,757 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,757 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,758 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,758 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,759 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,760 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,765 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,766 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,766 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,767 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,774 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,774 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,775 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,788 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,788 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,788 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,789 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,795 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,796 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,796 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,797 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,802 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,803 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,810 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,810 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,815 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,816 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,816 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,821 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,822 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,822 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,822 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,829 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,829 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,829 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,830 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,835 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,835 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,836 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,836 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  18%|        | 105/574 [00:11<00:50,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,848 INFO | INITIAL\n",
      "2021-05-27 16:56:08,849 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,854 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,854 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,856 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,856 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,857 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,857 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,857 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,858 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,858 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,859 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,867 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,868 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,869 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,869 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,876 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,876 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,877 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,884 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,884 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,885 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,885 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,891 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,892 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,892 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,893 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,899 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,899 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,900 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,900 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,907 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,907 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,908 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,908 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,915 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,916 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,916 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,917 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,922 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,922 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,923 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,923 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,930 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,931 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,931 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,932 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,937 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,938 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,938 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,938 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,944 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,945 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,945 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,945 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  19%|        | 107/574 [00:11<00:49,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:08,955 INFO | INITIAL\n",
      "2021-05-27 16:56:08,956 INFO | (50, 200)\n",
      "2021-05-27 16:56:08,961 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:08,962 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,963 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:08,964 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:08,964 INFO | BERT LAYER\n",
      "2021-05-27 16:56:08,965 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,965 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,965 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,966 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,967 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,972 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,973 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,973 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,974 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,980 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,981 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,987 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,987 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,988 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,988 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:08,995 INFO | (200, 512)\n",
      "2021-05-27 16:56:08,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:08,995 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,002 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,002 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,002 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,003 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,010 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,010 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,011 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,011 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,017 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,018 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,018 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,025 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,025 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,026 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,032 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,033 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,033 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,034 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,040 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,040 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,041 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,048 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,049 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,049 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,050 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  19%|        | 108/574 [00:11<00:49,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,061 INFO | INITIAL\n",
      "2021-05-27 16:56:09,062 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,067 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,067 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,069 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,070 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,070 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,071 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,072 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,073 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,082 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,089 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,090 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,096 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,097 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,103 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,105 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,113 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,120 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,121 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,127 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,128 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,136 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,142 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,142 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,143 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,150 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,151 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,156 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,157 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  19%|        | 109/574 [00:11<00:49,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,168 INFO | INITIAL\n",
      "2021-05-27 16:56:09,169 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,176 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,177 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,178 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,179 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,180 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,180 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,181 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,181 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,182 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,187 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,195 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,202 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,210 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,211 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,217 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,217 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,217 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,223 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,224 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,224 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,225 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,235 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,243 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,243 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,244 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,244 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,250 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,250 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,251 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,257 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,258 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,258 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,259 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,266 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,266 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,266 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  19%|        | 110/574 [00:11<00:49,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,278 INFO | INITIAL\n",
      "2021-05-27 16:56:09,279 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,284 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,284 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,285 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,286 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,287 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,294 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,295 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,295 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,296 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,302 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,303 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,310 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,311 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,318 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,319 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,327 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,328 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,329 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,334 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,336 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,337 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,337 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,344 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,344 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,345 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,345 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,350 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,351 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,357 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,357 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,358 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,358 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,364 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,364 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,365 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,365 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,371 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,372 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,372 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,372 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  19%|        | 111/574 [00:12<00:49,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,383 INFO | INITIAL\n",
      "2021-05-27 16:56:09,383 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,388 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,389 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,390 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,390 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,391 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,392 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,393 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,400 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,401 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,401 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,408 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,408 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,409 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,410 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,417 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,418 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,418 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,425 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,427 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,434 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,434 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,435 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,436 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,443 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,445 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,450 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,450 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,451 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,451 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,456 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,457 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,457 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,458 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,465 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,465 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,471 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,472 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,480 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  20%|        | 112/574 [00:12<00:49,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,489 INFO | INITIAL\n",
      "2021-05-27 16:56:09,490 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,497 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,497 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,498 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,498 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,499 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,500 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,501 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,501 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,508 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,509 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,509 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,510 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,519 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,526 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,526 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,527 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,527 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,536 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,537 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,543 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,544 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,544 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,545 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,551 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,551 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,552 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,552 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,558 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,558 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,559 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,565 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,566 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,574 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,575 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,581 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,581 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,582 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,582 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,587 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,588 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,588 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,589 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  20%|        | 113/574 [00:12<00:49,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,600 INFO | INITIAL\n",
      "2021-05-27 16:56:09,601 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,606 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,606 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,608 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,608 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,609 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,610 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,610 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,611 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,611 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,617 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,618 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,618 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,625 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,626 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,632 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,633 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,633 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,640 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,641 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,641 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,642 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,648 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,649 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,649 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,649 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,656 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,656 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,656 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,657 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,662 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,663 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,663 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,664 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,670 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,670 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,676 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,677 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,677 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,682 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,683 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,683 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,684 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,691 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,691 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,692 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,692 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  20%|        | 114/574 [00:12<00:49,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,705 INFO | INITIAL\n",
      "2021-05-27 16:56:09,706 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,712 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,712 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,714 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,714 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,715 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,716 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,717 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,717 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,724 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,724 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,725 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,731 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,732 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,738 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,739 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,745 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,751 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,752 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,758 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,758 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,759 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,759 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,764 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,765 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,772 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,773 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,773 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,774 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,781 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,781 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,791 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,793 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,793 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,799 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,800 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,801 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,801 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  20%|        | 115/574 [00:12<00:49,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,816 INFO | INITIAL\n",
      "2021-05-27 16:56:09,816 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,821 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,821 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,822 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,823 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,824 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,824 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,824 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,825 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,825 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,826 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,831 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,831 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,832 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,832 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,839 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,839 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,840 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,840 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,853 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,859 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,859 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,860 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,860 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,866 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,866 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,867 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,867 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,873 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,873 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,879 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,880 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,880 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,881 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,886 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,887 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,896 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,903 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,904 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  20%|        | 116/574 [00:12<00:48,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:09,918 INFO | INITIAL\n",
      "2021-05-27 16:56:09,919 INFO | (50, 200)\n",
      "2021-05-27 16:56:09,924 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:09,924 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,926 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:09,926 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:09,927 INFO | BERT LAYER\n",
      "2021-05-27 16:56:09,927 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,928 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,928 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,929 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,934 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,935 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,935 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,935 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,941 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,942 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,942 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,943 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,949 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,949 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,955 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,955 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,961 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,961 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,962 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,962 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,968 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,969 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,969 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,969 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,976 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,976 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,977 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,982 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,983 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,988 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,989 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:09,996 INFO | (200, 512)\n",
      "2021-05-27 16:56:09,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:09,997 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,004 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,006 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  20%|        | 116/574 [00:12<00:48,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,017 INFO | INITIAL\n",
      "2021-05-27 16:56:10,018 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,023 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,023 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,025 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,025 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,026 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,026 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,027 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,028 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,034 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,034 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,035 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,036 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,044 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,050 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,051 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,057 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,058 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,064 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,065 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,066 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,070 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,071 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,071 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,071 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,077 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,077 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,078 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,078 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,084 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,085 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,085 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,086 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,092 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,093 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,099 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,100 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,100 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,101 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,108 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,110 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,111 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  21%|        | 118/574 [00:12<00:48,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,132 INFO | INITIAL\n",
      "2021-05-27 16:56:10,133 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,138 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,139 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,140 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,141 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,142 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,142 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,143 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,143 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,151 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,152 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,158 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,159 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,159 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,160 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,166 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,166 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,167 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,167 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,174 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,174 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,175 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,181 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,182 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,182 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,183 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,190 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,190 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,191 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,192 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,197 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,198 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,198 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,198 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,205 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,206 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,207 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,221 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,222 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,222 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,223 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,228 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,229 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,229 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,229 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  21%|        | 119/574 [00:12<00:48,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,240 INFO | INITIAL\n",
      "2021-05-27 16:56:10,240 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,247 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,247 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,249 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,249 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,250 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,251 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,252 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,252 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,260 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,261 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,267 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,268 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,274 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,275 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,282 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,296 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,297 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,304 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,304 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,305 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,312 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,313 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,313 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,314 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,319 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,320 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,320 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,321 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,326 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,327 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,328 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,330 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,335 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,336 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,337 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  21%|        | 120/574 [00:13<00:48,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,348 INFO | INITIAL\n",
      "2021-05-27 16:56:10,348 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,354 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,355 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,356 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,356 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,357 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,358 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,360 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,367 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,367 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,368 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,377 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,377 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,378 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,383 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,384 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,391 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,392 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,393 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,393 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,398 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,398 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,407 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,412 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,412 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,418 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,418 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,419 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,419 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,424 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,425 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,425 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,426 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,431 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,432 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,440 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,441 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,441 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  21%|        | 121/574 [00:13<00:48,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,453 INFO | INITIAL\n",
      "2021-05-27 16:56:10,453 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,459 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,460 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,462 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,463 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,464 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,464 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,465 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,474 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,474 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,475 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,475 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,481 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,488 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,494 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,495 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,495 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,495 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,502 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,502 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,503 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,503 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,510 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,511 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,511 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,511 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,517 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,518 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,531 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,531 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,532 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,532 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,538 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,539 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,545 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,546 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,546 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,546 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  21%|       | 122/574 [00:13<00:47,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,557 INFO | INITIAL\n",
      "2021-05-27 16:56:10,557 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,564 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,565 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,566 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,566 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,567 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,568 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,568 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,569 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,570 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,576 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,577 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,577 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,578 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,583 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,584 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,589 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,590 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,591 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,596 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,597 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,597 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,597 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,603 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,603 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,604 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,604 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,611 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,611 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,612 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,619 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,619 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,620 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,620 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,627 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,627 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,628 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,628 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,634 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,635 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,636 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,644 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,645 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,645 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,646 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,653 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,654 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  21%|       | 123/574 [00:13<00:48,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,666 INFO | INITIAL\n",
      "2021-05-27 16:56:10,666 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,671 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,672 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,673 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,674 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,675 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,676 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,676 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,677 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,684 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,685 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,693 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,694 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,699 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,700 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,700 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,700 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,706 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,707 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,707 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,708 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,713 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,714 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,714 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,715 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,721 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,721 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,722 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,722 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,728 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,728 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,729 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,729 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,738 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,739 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,746 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,746 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,747 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,747 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,753 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,753 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,753 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,754 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,759 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,759 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,760 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  22%|       | 124/574 [00:13<00:47,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,771 INFO | INITIAL\n",
      "2021-05-27 16:56:10,771 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,777 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,778 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,779 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,780 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,781 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,781 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,782 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,783 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,789 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,791 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,797 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,798 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,798 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,798 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,805 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,805 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,806 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,806 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,811 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,812 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,812 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,813 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,818 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,818 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,819 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,819 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,826 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,826 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,827 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,827 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,833 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,833 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,834 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,834 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,841 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,842 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,843 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,843 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,849 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,850 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,850 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,855 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,856 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,856 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,856 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,862 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,862 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,863 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,863 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  22%|       | 125/574 [00:13<00:47,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,873 INFO | INITIAL\n",
      "2021-05-27 16:56:10,873 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,879 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,879 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,880 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,881 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,881 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,882 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,882 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,883 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,883 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,888 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,889 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,889 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,901 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,902 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,902 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,902 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,909 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,909 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,910 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,916 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,917 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,925 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,926 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,932 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,933 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,933 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,933 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,939 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,939 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,940 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,940 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,946 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,946 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,947 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,947 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,952 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,952 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,953 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,953 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,958 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,959 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,959 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,960 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  22%|       | 125/574 [00:13<00:47,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:10,969 INFO | INITIAL\n",
      "2021-05-27 16:56:10,969 INFO | (50, 200)\n",
      "2021-05-27 16:56:10,976 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:10,977 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,978 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:10,978 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:10,979 INFO | BERT LAYER\n",
      "2021-05-27 16:56:10,980 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,980 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,981 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,981 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,982 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,988 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,989 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,989 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,990 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,996 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:10,997 INFO | (200, 512)\n",
      "2021-05-27 16:56:10,997 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:10,998 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,004 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,005 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,005 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,006 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,012 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,013 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,013 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,013 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,018 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,019 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,020 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,020 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,027 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,027 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,028 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,028 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,036 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,037 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,037 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,047 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,047 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,048 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,048 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,054 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,055 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,055 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,056 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,062 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,062 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,063 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,063 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,069 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,070 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,070 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,070 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  22%|       | 127/574 [00:13<00:46,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,082 INFO | INITIAL\n",
      "2021-05-27 16:56:11,082 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,087 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,087 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,089 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,089 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,090 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,090 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,091 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,091 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,092 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,092 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,098 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,098 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,098 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,099 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,105 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,106 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,106 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,107 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,115 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,115 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,115 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,116 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,122 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,122 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,123 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,123 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,129 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,130 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,130 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,131 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,136 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,137 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,137 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,137 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,143 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,149 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,150 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,150 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,150 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,155 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,156 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,156 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,156 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,163 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,164 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,165 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,170 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,171 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,172 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  22%|       | 128/574 [00:13<00:46,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,183 INFO | INITIAL\n",
      "2021-05-27 16:56:11,184 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,189 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,190 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,191 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,192 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,193 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,194 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,195 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,205 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,206 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,206 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,213 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,220 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,221 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,221 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,221 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,227 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,227 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,228 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,228 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,233 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,242 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,242 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,243 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,248 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,248 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,249 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,249 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,254 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,254 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,255 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,255 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,260 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,261 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,261 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,262 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,268 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,268 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,269 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,275 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,276 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,277 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  22%|       | 129/574 [00:13<00:46,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,288 INFO | INITIAL\n",
      "2021-05-27 16:56:11,289 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,297 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,297 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,299 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,299 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,300 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,310 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,310 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,311 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,311 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,317 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,318 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,318 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,318 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,325 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,326 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,332 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,333 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,333 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,339 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,340 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,340 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,340 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,346 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,347 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,347 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,347 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,353 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,353 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,353 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,354 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,360 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,361 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,361 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,362 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,369 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,369 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,370 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,370 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,378 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,379 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,386 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  23%|       | 130/574 [00:14<00:46,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,397 INFO | INITIAL\n",
      "2021-05-27 16:56:11,397 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,402 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,402 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,403 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,404 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,404 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,405 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,406 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,414 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,415 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,420 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,420 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,421 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,428 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,428 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,429 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,435 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,435 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,436 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,436 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,444 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,447 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,448 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,448 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,455 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,456 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,456 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,456 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,464 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,464 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,465 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,470 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,470 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,471 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,485 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,486 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,486 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,486 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,493 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,493 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,494 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,494 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  23%|       | 131/574 [00:14<00:47,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,510 INFO | INITIAL\n",
      "2021-05-27 16:56:11,510 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,516 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,517 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,518 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,519 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,520 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,520 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,521 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,521 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,521 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,522 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,528 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,528 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,528 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,529 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,534 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,535 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,535 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,535 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,543 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,544 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,550 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,550 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,551 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,551 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,557 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,558 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,559 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,559 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,565 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,565 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,566 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,566 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,574 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,574 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,575 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,575 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,582 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,582 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,583 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,583 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,589 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,589 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,589 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,590 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,595 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,596 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,596 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,596 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,602 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,602 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,603 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,603 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  23%|       | 132/574 [00:14<00:47,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,613 INFO | INITIAL\n",
      "2021-05-27 16:56:11,614 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,619 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,620 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,621 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,622 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,622 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,623 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,624 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,625 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,633 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,633 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,634 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,642 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,643 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,644 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,644 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,651 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,651 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,652 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,652 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,658 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,659 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,659 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,665 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,666 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,666 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,667 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,673 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,673 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,674 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,674 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,680 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,681 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,681 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,688 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,695 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,695 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,696 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,696 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,702 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,703 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,703 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,704 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,711 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,711 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,711 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,712 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  23%|       | 133/574 [00:14<00:47,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,723 INFO | INITIAL\n",
      "2021-05-27 16:56:11,723 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,730 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,731 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,732 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,733 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,734 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,734 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,735 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,735 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,736 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,736 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,743 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,743 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,744 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,749 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,750 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,750 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,751 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,757 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,758 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,758 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,759 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,764 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,765 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,765 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,766 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,771 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,772 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,772 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,772 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,779 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,780 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,780 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,781 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,786 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,787 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,793 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,794 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,797 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,803 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,804 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,810 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,810 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,811 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,817 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,817 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,817 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,818 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  23%|       | 134/574 [00:14<00:47,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,828 INFO | INITIAL\n",
      "2021-05-27 16:56:11,829 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,834 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,834 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,835 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,836 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,837 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,837 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,845 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,846 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,852 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,852 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,853 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,858 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,858 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,859 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,860 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,865 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,866 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,868 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,869 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,874 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,875 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,875 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,876 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,882 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,883 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,895 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,896 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,896 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,897 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,903 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,904 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,912 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,913 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,919 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,920 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,920 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,921 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 135/574 [00:14<00:46,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:11,932 INFO | INITIAL\n",
      "2021-05-27 16:56:11,932 INFO | (50, 200)\n",
      "2021-05-27 16:56:11,937 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:11,938 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,941 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:11,941 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:11,942 INFO | BERT LAYER\n",
      "2021-05-27 16:56:11,942 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,943 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,943 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,944 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,944 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,950 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,951 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,956 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,956 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,957 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,958 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,963 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,964 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,970 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,970 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,977 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,978 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,984 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,991 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:11,992 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:11,993 INFO | (200, 512)\n",
      "2021-05-27 16:56:11,999 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,001 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,001 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,008 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,009 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,015 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,016 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,022 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,022 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 136/574 [00:14<00:45,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,033 INFO | INITIAL\n",
      "2021-05-27 16:56:12,033 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,039 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,039 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,041 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,041 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,043 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,044 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,044 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,045 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,045 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,051 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,052 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,052 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,052 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,058 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,059 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,059 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,060 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,066 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,066 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,066 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,067 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,073 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,073 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,074 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,074 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,081 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,082 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,082 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,089 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,089 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,090 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,090 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,097 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,097 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,103 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,104 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,111 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,111 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,118 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,118 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,118 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,119 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,125 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,125 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,126 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,126 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 137/574 [00:14<00:45,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,136 INFO | INITIAL\n",
      "2021-05-27 16:56:12,137 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,142 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,142 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,144 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,145 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,145 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,146 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,146 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,146 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,147 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,147 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,154 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,155 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,155 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,155 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,162 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,163 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,164 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,179 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,179 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,180 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,187 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,195 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,195 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,204 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,211 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,212 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,218 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,224 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,225 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,225 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,226 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,231 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,232 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,232 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,233 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 138/574 [00:14<00:45,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,245 INFO | INITIAL\n",
      "2021-05-27 16:56:12,246 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,252 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,253 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,254 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,254 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,255 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,255 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,256 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,257 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,257 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,258 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,265 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,265 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,265 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,266 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,272 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,272 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,273 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,274 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,280 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,281 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,295 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,295 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,296 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,296 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,303 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,303 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,303 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,304 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,311 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,312 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,312 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,313 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,318 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,319 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,326 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,327 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,327 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,333 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,335 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,342 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,343 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,343 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,344 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 139/574 [00:15<00:46,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,353 INFO | INITIAL\n",
      "2021-05-27 16:56:12,353 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,359 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,359 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,360 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,361 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,362 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,362 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,362 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,363 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,363 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,364 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,370 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,370 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,371 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,371 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,377 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,378 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,378 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,378 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,384 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,384 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,390 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,390 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,391 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,391 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,397 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,397 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,398 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,398 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,404 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,404 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,405 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,414 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,414 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,415 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,421 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,421 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,422 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,422 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,428 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,429 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,429 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,430 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,435 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,436 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,436 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,437 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,443 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,444 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,444 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,445 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 140/574 [00:15<00:45,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,456 INFO | INITIAL\n",
      "2021-05-27 16:56:12,456 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,461 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,462 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,463 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,463 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,464 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,464 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,464 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,465 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,465 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,472 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,472 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,472 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,478 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,479 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,485 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,486 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,491 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,491 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,492 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,492 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,498 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,498 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,499 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,499 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,505 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,506 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,506 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,514 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,515 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,522 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,522 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,522 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,523 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,529 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,529 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,530 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,530 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,535 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,536 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,536 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,536 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,542 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,543 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,543 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,543 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  24%|       | 140/574 [00:15<00:45,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,552 INFO | INITIAL\n",
      "2021-05-27 16:56:12,553 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,558 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,559 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,560 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,561 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,562 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,563 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,563 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,564 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,569 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,570 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,570 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,571 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,577 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,578 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,578 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,578 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,585 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,585 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,586 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,586 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,592 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,592 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,593 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,593 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,600 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,600 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,601 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,601 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,607 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,608 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,608 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,609 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,616 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,623 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,623 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,624 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,624 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,631 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,631 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,632 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,639 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,639 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,647 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,648 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  25%|       | 142/574 [00:15<00:44,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,658 INFO | INITIAL\n",
      "2021-05-27 16:56:12,658 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,665 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,665 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,667 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,667 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,668 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,669 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,669 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,669 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,670 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,670 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,677 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,678 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,678 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,679 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,686 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,686 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,686 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,687 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,694 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,695 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,700 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,701 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,701 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,702 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,707 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,708 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,709 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,709 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,716 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,716 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,717 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,717 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,723 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,724 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,724 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,725 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,730 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,731 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,731 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,732 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,737 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,738 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,738 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,738 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,744 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,745 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,746 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,750 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,751 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,751 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,752 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  25%|       | 143/574 [00:15<00:44,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,763 INFO | INITIAL\n",
      "2021-05-27 16:56:12,763 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,768 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,769 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,771 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,771 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,772 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,773 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,773 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,774 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,775 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,776 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,782 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,782 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,783 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,783 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,789 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,790 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,790 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,791 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,796 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,797 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,797 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,797 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,803 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,804 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,809 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,810 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,810 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,811 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,816 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,816 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,816 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,817 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,821 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,822 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,822 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,823 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,829 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,829 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,830 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,830 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,836 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,837 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,837 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,846 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,847 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,847 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,853 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,854 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,854 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,855 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  25%|       | 144/574 [00:15<00:44,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,865 INFO | INITIAL\n",
      "2021-05-27 16:56:12,866 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,870 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,871 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,872 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,873 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,874 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,874 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,875 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,875 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,876 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,877 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,882 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,882 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,882 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,883 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,887 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,888 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,888 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,889 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,894 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,895 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,902 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,902 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,903 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,904 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,912 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,913 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,913 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,914 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,920 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,921 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,921 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,922 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,928 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,929 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,929 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,930 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,936 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,936 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,936 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,937 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,942 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,942 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,943 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,943 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,950 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,950 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,951 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,951 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,957 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,958 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,958 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,958 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  25%|       | 145/574 [00:15<00:44,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:12,970 INFO | INITIAL\n",
      "2021-05-27 16:56:12,971 INFO | (50, 200)\n",
      "2021-05-27 16:56:12,978 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:12,978 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,980 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:12,980 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:12,981 INFO | BERT LAYER\n",
      "2021-05-27 16:56:12,982 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,982 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,982 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,983 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,983 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,989 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,990 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,991 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:12,991 INFO | (200, 512)\n",
      "2021-05-27 16:56:12,998 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:12,999 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,000 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,000 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,007 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,008 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,009 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,015 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,016 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,022 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,023 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,023 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,028 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,029 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,029 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,030 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,035 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,035 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,036 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,037 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,043 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,044 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,049 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,050 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,050 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,051 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,056 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,056 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,057 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,057 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,064 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,064 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  25%|       | 146/574 [00:15<00:44,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,076 INFO | INITIAL\n",
      "2021-05-27 16:56:13,077 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,083 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,083 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,085 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,085 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,086 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,086 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,086 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,087 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,087 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,087 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,094 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,095 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,102 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,103 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,113 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,113 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,120 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,120 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,127 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,128 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,135 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,136 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,136 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,143 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,144 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,144 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,145 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,151 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,152 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,152 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,152 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,159 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,160 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,160 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,165 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,166 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,166 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,166 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,173 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,173 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,173 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,174 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  26%|       | 147/574 [00:15<00:45,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,186 INFO | INITIAL\n",
      "2021-05-27 16:56:13,186 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,191 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,192 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,193 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,194 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,195 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,195 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,196 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,197 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,203 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,204 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,204 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,210 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,211 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,211 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,212 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,218 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,218 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,219 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,226 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,227 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,227 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,228 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,233 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,233 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,234 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,242 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,242 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,243 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,243 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,249 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,250 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,250 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,251 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,255 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,256 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,256 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,257 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,262 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,263 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,263 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,263 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,269 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,269 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,270 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,270 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,276 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,276 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,277 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,277 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  26%|       | 148/574 [00:15<00:44,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,288 INFO | INITIAL\n",
      "2021-05-27 16:56:13,288 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,294 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,294 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,296 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,296 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,297 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,297 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,298 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,298 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,298 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,299 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,305 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,306 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,307 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,307 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,315 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,315 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,315 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,316 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,322 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,323 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,323 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,323 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,329 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,330 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,330 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,331 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,336 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,336 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,336 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,337 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,343 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,343 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,344 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,344 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,351 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,351 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,352 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,352 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,358 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,358 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,359 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,359 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,366 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,367 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,374 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,374 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,375 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,376 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,383 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,384 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  26%|       | 149/574 [00:16<00:44,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,395 INFO | INITIAL\n",
      "2021-05-27 16:56:13,396 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,401 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,401 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,403 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,403 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,404 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,405 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,406 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,407 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,407 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,413 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,413 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,413 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,414 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,419 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,419 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,420 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,420 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,425 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,426 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,426 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,427 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,432 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,433 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,433 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,433 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,439 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,439 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,440 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,449 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,449 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,457 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,457 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,458 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,458 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,465 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,466 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,466 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,467 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,473 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,473 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,474 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,474 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,481 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,481 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,482 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,487 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,487 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,488 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,488 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  26%|       | 150/574 [00:16<00:44,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,498 INFO | INITIAL\n",
      "2021-05-27 16:56:13,499 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,504 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,504 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,506 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,506 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,507 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,508 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,509 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,509 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,510 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,510 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,517 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,526 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,526 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,533 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,534 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,540 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,541 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,541 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,542 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,548 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,549 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,549 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,555 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,555 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,555 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,556 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,562 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,562 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,563 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,563 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,568 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,569 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,569 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,569 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,575 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,576 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,576 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,577 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,583 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,584 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,584 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,585 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,590 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,590 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,591 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,591 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  26%|       | 151/574 [00:16<00:44,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,602 INFO | INITIAL\n",
      "2021-05-27 16:56:13,602 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,608 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,608 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,610 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,611 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,612 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,612 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,612 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,613 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,613 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,614 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,621 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,622 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,623 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,623 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,630 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,630 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,631 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,632 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,638 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,638 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,639 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,640 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,647 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,647 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,648 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,648 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,653 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,653 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,654 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,654 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,661 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,661 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,661 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,662 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,668 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,669 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,669 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,674 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,675 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,676 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,681 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,682 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,682 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,682 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,687 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,688 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,688 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,689 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,694 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,695 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,695 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,696 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  26%|       | 152/574 [00:16<00:43,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,705 INFO | INITIAL\n",
      "2021-05-27 16:56:13,706 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,714 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,715 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,716 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,717 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,718 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,718 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,719 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,719 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,720 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,726 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,727 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,728 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,728 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,734 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,736 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,741 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,742 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,742 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,743 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,748 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,749 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,749 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,750 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,755 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,755 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,756 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,756 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,762 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,763 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,764 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,764 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,769 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,770 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,770 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,771 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,776 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,777 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,778 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,780 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,785 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,786 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,786 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,787 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,794 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,796 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,803 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,803 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,804 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  27%|       | 153/574 [00:16<00:44,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,818 INFO | INITIAL\n",
      "2021-05-27 16:56:13,818 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,824 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,825 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,826 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,827 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,828 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,829 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,830 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,830 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,831 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,831 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,837 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,838 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,838 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,849 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,849 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,849 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,850 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,856 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,857 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,857 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,858 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,864 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,865 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,866 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,866 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,872 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,872 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,873 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,874 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,880 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,881 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,881 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,882 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,889 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,889 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,890 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,890 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,898 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,898 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,899 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,899 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,906 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,907 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,907 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,908 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,916 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,917 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,917 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,918 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,924 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,924 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,925 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,926 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  27%|       | 154/574 [00:16<00:46,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:13,938 INFO | INITIAL\n",
      "2021-05-27 16:56:13,938 INFO | (50, 200)\n",
      "2021-05-27 16:56:13,944 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:13,944 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,946 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:13,946 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:13,947 INFO | BERT LAYER\n",
      "2021-05-27 16:56:13,948 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,948 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,948 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,949 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,949 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,955 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,956 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,962 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,962 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,963 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,963 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,969 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,970 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,970 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,970 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,977 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,978 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,978 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,978 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,984 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,985 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,985 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,992 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:13,992 INFO | (200, 512)\n",
      "2021-05-27 16:56:13,993 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:13,993 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,001 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,002 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,008 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,008 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,009 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,015 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,016 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,016 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,017 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,022 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,022 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,023 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,030 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,030 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,031 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,031 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  27%|       | 155/574 [00:16<00:45,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,043 INFO | INITIAL\n",
      "2021-05-27 16:56:14,044 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,050 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,051 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,052 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,053 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,054 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,054 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,055 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,055 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,056 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,056 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,063 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,064 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,065 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,065 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,072 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,073 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,073 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,074 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,082 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,088 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,089 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,089 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,090 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,096 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,097 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,097 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,098 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,103 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,104 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,104 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,105 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,111 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,112 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,113 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,120 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,120 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,121 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,121 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,127 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,128 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,133 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,134 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,134 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,140 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,141 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,142 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,144 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  27%|       | 156/574 [00:16<00:45,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,154 INFO | INITIAL\n",
      "2021-05-27 16:56:14,154 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,160 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,160 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,161 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,162 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,163 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,163 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,164 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,164 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,164 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,165 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,171 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,171 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,172 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,172 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,180 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,181 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,181 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,186 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,187 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,193 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,194 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,194 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,195 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,200 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,200 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,200 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,201 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,207 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,207 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,208 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,208 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,213 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,214 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,214 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,219 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,219 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,220 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,220 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,225 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,226 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,226 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,227 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,232 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,233 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,233 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,234 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,240 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,241 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,241 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,242 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  27%|       | 156/574 [00:16<00:45,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,253 INFO | INITIAL\n",
      "2021-05-27 16:56:14,254 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,259 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,259 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,261 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,261 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,262 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,262 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,263 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,263 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,264 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,264 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,270 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,270 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,271 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,271 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,278 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,278 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,279 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,279 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,285 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,286 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,286 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,293 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,301 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,302 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,302 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,309 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,310 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,310 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,311 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,318 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,318 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,319 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,319 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,325 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,325 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,326 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,327 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,333 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,333 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,334 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,334 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,340 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,340 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,341 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,341 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,347 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,347 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,347 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,348 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 158/574 [00:17<00:44,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,357 INFO | INITIAL\n",
      "2021-05-27 16:56:14,358 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,364 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,364 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,366 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,366 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,367 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,368 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,368 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,369 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,369 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,375 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,376 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,376 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,377 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,384 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,385 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,385 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,386 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,393 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,396 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,399 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,400 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,406 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,407 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,408 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,408 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,414 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,415 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,415 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,416 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,422 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,423 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,423 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,423 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,431 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,431 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,432 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,432 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,438 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,438 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,439 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,445 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,446 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,446 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,447 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,452 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,453 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,453 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,453 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,461 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,461 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,461 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,462 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 159/574 [00:17<00:44,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,473 INFO | INITIAL\n",
      "2021-05-27 16:56:14,474 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,479 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,480 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,481 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,481 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,482 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,482 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,483 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,484 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,484 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,484 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,489 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,490 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,491 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,491 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,497 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,498 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,498 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,499 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,505 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,506 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,507 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,507 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,514 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,515 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,515 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,516 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,522 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,523 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,523 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,523 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,533 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,533 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,539 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,539 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,540 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,541 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,548 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,549 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,550 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,550 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,556 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,557 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,557 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,558 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,564 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,565 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,565 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,566 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,573 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,573 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,574 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,574 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 160/574 [00:17<00:45,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,586 INFO | INITIAL\n",
      "2021-05-27 16:56:14,587 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,593 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,594 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,596 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,596 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,597 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,598 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,598 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,599 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,600 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,600 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,605 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,606 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,606 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,607 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,615 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,616 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,617 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,617 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,624 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,625 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,625 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,626 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,633 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,633 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,634 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,634 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,641 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,642 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,642 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,642 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,650 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,650 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,651 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,651 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,658 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,659 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,660 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,660 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,667 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,667 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,668 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,668 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,675 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,675 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,676 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,676 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,684 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,684 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,685 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,685 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,692 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,693 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,693 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,694 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 161/574 [00:17<00:46,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,705 INFO | INITIAL\n",
      "2021-05-27 16:56:14,705 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,712 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,713 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,715 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,716 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,717 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,717 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,717 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,718 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,719 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,719 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,725 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,725 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,727 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,727 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,734 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,734 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,735 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,735 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,742 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,743 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,743 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,744 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,751 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,752 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,752 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,753 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,758 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,759 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,760 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,760 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,767 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,768 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,768 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,769 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,778 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,778 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,779 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,779 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,786 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,787 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,787 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,788 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,794 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,795 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,795 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,796 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,802 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,802 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,803 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,803 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,810 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,811 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,811 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,812 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 162/574 [00:17<00:46,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,823 INFO | INITIAL\n",
      "2021-05-27 16:56:14,823 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,830 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,831 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,832 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,832 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,833 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,834 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,834 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,834 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,835 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,836 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,844 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,844 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,845 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,846 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,852 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,852 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,853 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,853 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,860 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,861 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,862 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,862 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,869 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,870 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,870 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,870 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,877 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,877 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,878 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,878 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,885 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,886 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,886 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,886 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,893 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,894 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,894 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,895 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,900 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,901 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,901 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,902 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,908 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,909 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,910 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,912 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,919 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,919 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,919 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,920 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,926 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,927 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,927 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,928 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 163/574 [00:17<00:46,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:14,938 INFO | INITIAL\n",
      "2021-05-27 16:56:14,938 INFO | (50, 200)\n",
      "2021-05-27 16:56:14,944 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:14,944 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,946 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:14,946 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:14,947 INFO | BERT LAYER\n",
      "2021-05-27 16:56:14,947 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,947 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,948 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,948 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,948 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,954 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,954 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,955 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,955 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,960 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,961 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,961 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,962 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,967 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,967 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,968 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,968 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,973 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,974 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,974 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,975 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,981 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,981 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,982 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,982 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,987 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,988 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,988 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,988 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,994 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:14,994 INFO | (200, 512)\n",
      "2021-05-27 16:56:14,995 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:14,995 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,000 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,001 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,001 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,002 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,008 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,009 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,009 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,010 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,014 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,015 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,015 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,015 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,021 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,021 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,022 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,022 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  28%|       | 163/574 [00:17<00:46,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:15,032 INFO | INITIAL\n",
      "2021-05-27 16:56:15,032 INFO | (50, 200)\n",
      "2021-05-27 16:56:15,037 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:15,037 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,039 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:15,040 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,041 INFO | BERT LAYER\n",
      "2021-05-27 16:56:15,042 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,042 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,043 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,044 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,044 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,050 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,051 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,054 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,054 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,062 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,063 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,064 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,064 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,071 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,072 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,072 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,073 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,080 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,080 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,081 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,081 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,086 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,086 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,087 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,087 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,094 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,095 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,095 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,096 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,102 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,102 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,103 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,103 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,110 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,111 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,111 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,112 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,119 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,120 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,120 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,121 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,127 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,128 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,128 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,128 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,134 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,135 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,135 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,136 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  29%|       | 165/574 [00:17<00:45,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:15,149 INFO | INITIAL\n",
      "2021-05-27 16:56:15,150 INFO | (50, 200)\n",
      "2021-05-27 16:56:15,155 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:15,155 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,157 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:15,158 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,158 INFO | BERT LAYER\n",
      "2021-05-27 16:56:15,159 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,159 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,160 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,161 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,161 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,168 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,169 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,169 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,170 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,178 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,178 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,179 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,180 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,187 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,187 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,188 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,188 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,195 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,196 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,196 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,202 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,202 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,203 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,203 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,209 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,209 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,210 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,210 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,216 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,216 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,216 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,217 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,222 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,223 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,223 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,223 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,230 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,230 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,230 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,231 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,237 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,237 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,238 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,238 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,246 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,246 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,247 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,247 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  29%|       | 166/574 [00:17<00:44,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:15,256 INFO | INITIAL\n",
      "2021-05-27 16:56:15,257 INFO | (50, 200)\n",
      "2021-05-27 16:56:15,263 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:15,264 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,265 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:15,266 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,266 INFO | BERT LAYER\n",
      "2021-05-27 16:56:15,267 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,267 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,267 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,268 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,268 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,273 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,274 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,274 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,275 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,281 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,281 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,282 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,282 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,287 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,287 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,288 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,288 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,293 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,294 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,294 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,300 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,300 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,300 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,301 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,308 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,309 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,309 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,310 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,316 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,317 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,317 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,317 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,323 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,323 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,324 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,324 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,330 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,331 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,331 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,332 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,337 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,338 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,338 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,338 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,345 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,346 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,346 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,347 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  29%|       | 166/574 [00:18<00:44,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:15,355 INFO | INITIAL\n",
      "2021-05-27 16:56:15,356 INFO | (50, 200)\n",
      "2021-05-27 16:56:15,361 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:15,362 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,363 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:15,363 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,364 INFO | BERT LAYER\n",
      "2021-05-27 16:56:15,364 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,365 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,365 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,366 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,366 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,372 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,373 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,374 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,374 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,382 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,382 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,383 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,383 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,388 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,389 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,389 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,389 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,396 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,396 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,397 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,397 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,402 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,403 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,403 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,404 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,410 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,410 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,411 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,411 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,416 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,417 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,417 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,418 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,423 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,423 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,424 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,424 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,430 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,430 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,431 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,431 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,437 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,438 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,439 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,440 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,448 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,448 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,449 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,449 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  29%|       | 168/574 [00:18<00:43,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 16:56:15,461 INFO | INITIAL\n",
      "2021-05-27 16:56:15,461 INFO | (50, 200)\n",
      "2021-05-27 16:56:15,467 INFO | POST EMBEDDING LAYER\n",
      "2021-05-27 16:56:15,467 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,469 INFO | POST POSITIONAL ENCODING\n",
      "2021-05-27 16:56:15,469 INFO | (50, 200, 512)\n",
      "2021-05-27 16:56:15,470 INFO | BERT LAYER\n",
      "2021-05-27 16:56:15,470 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,471 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,471 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,471 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,472 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,477 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,478 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,478 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,479 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,484 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,485 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,485 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,485 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,491 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,491 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,492 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,492 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,499 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,499 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,500 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,500 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,506 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,507 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,508 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,509 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,516 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,517 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,517 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,518 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,524 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,524 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,525 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,525 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,532 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,532 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,533 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,533 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,538 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,539 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,539 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,540 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,546 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,546 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,547 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,547 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,552 INFO | BERT LAYER LOOP\n",
      "2021-05-27 16:56:15,553 INFO | (200, 512)\n",
      "2021-05-27 16:56:15,554 INFO | MULTIHEADED ATTENTION\n",
      "2021-05-27 16:56:15,554 INFO | (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.000, Accuracy: 0.000% :  29%|       | 168/574 [00:18<00:44,  9.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-89e243f4dc47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         with writer.as_default():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mRs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#attentions.append((Rs, acc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0;31m# with tf.summary.record_if(True):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-92ca48338eeb>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(log_batch, labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mRs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimus_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         a_s = add_att_layer([Rs, Rs])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#         y = softmax(a_s * Rs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-bdef2dbee5fc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tuple, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# BERT for Log Sequence Embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mbert_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Encoder Block Hidden Layers for Log Sequence Representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2acd74dcbb32>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BERT LAYER LOOP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-ceecd4e940f0>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# (4) - Add & Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mfeed_forward_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_forward_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m       \u001b[0;31m# Calculate the moments on the last axis (layer activations).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m       \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mmoments\u001b[0;34m(x, axes, shift, name, keep_dims, keepdims)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;31m# Compute true mean while keeping the dims for proper broadcasting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0;31m# sample variance, not unbiased variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;31m# Note: stop_gradient does not change the gradient that gets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_mean\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   2368\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   2369\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m       gen_math_ops.mean(\n\u001b[0m\u001b[1;32m   2371\u001b[0m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m           name=name))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   5770\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5772\u001b[0;31m       return mean_eager_fallback(\n\u001b[0m\u001b[1;32m   5773\u001b[0m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n\u001b[1;32m   5774\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmean_eager_fallback\u001b[0;34m(input, axis, keep_dims, name, ctx)\u001b[0m\n\u001b[1;32m   5799\u001b[0m   \u001b[0mkeep_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5800\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5801\u001b[0;31m   \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5802\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tidx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_autopacking_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m   \u001b[0;34m\"\"\"Tensor conversion function that automatically packs arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mas_ref\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_should_not_autopack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m   \u001b[0minferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dtype_from_nested_lists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_should_not_autopack\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m   1506\u001b[0m   \u001b[0;31m# pylint: disable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m   \u001b[0;31m# TODO(slebedev): add nest.all?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_NON_AUTOPACKABLE_TYPES\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m   \u001b[0;31m# pylint: enable=unidiomatic-typecheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/_collections_abc.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attentions = []\n",
    "\n",
    "for epoch in range(t_config.epoch):\n",
    "\n",
    "    start = time.time()\n",
    "    epoch_loss.reset_states()\n",
    "    epoch_accuracy.reset_states()\n",
    "    dataset_iter = iter(batched_dataset)\n",
    "\n",
    "    t = tqdm(range(n_iter), desc=\"Epoch: {:03d}, Loss: {:.3f}, Accuracy: {:.3%}\".format(0, 0, 0), position=0, leave=True)\n",
    "    for _ in t:\n",
    "        batch = next(dataset_iter)\n",
    "        log_batch = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "        # Returns Eager Tensor for Predictions\n",
    "#         tf.summary.trace_on()\n",
    "#         tf.profiler.experimental.start(SOURCE + t_config.logdir)\n",
    "\n",
    "#         with writer.as_default():\n",
    "        Rs, acc = train_step(log_batch, labels)\n",
    "        #attentions.append((Rs, acc))\n",
    "          # with tf.summary.record_if(True):\n",
    "\n",
    "#             tf.summary.trace_export(\n",
    "#               name = \"training_trace\",\n",
    "#               step=0,\n",
    "#               profiler_outdir=SOURCE + t_config.logdir\n",
    "#             )\n",
    "\n",
    "#         tf.profiler.experimental.stop()\n",
    "#         tf.summary.trace_off()\n",
    "\n",
    "#         checkpoint.step.assign_add(1)\n",
    "\n",
    "#         if int(checkpoint.step) % 10 == 0:\n",
    "#             save_path = checkpoint_manager.save()\n",
    "\n",
    "        t.set_description(desc=\"Epoch: {:03d}, Loss: {:.3f}, Accuracy: {:.3%} \".format(epoch,\n",
    "                                                                    epoch_loss.result(),\n",
    "                                                                    epoch_accuracy.result()))\n",
    "        t.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ITSJA5hWASDn",
    "0JtgL-iQkqj2"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "LongRunTransformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
